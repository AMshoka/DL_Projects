{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRPZ5NFp3HJA"
   },
   "source": [
    "\n",
    "*  **Name: AmirHossein Mohammadi**\n",
    "*  **Std number: 99201081**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4d3Sv6jKB0f"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XaThfleMJyis"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pds\n",
    "from torch.utils.data import DataLoader,TensorDataset,random_split\n",
    "from tqdm.auto import tqdm\n",
    "from IPython import display\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zL7sxjIeKOke"
   },
   "source": [
    "# Load Data with data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PJuD50jIKAbg"
   },
   "outputs": [],
   "source": [
    "n = 3762\n",
    "image=[]\n",
    "cw = os.getcwd().replace(os.sep, '/')\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "for i in range(n):\n",
    "    image.append(np.array(Image.open(cw+\"/Tumor/Brain_Tumor/Image\" + str(i+1) + \".jpg\").resize((48,48))))\n",
    "\n",
    "temp = pds.read_csv(cw+\"/Tumor/Brain_Tumor.csv\",index_col=None, header=None).to_numpy()\n",
    "\n",
    "temp = temp[1:,1]\n",
    "targets = np.zeros((n,1),dtype=int)\n",
    "targets = []\n",
    "for i in range(n):\n",
    "    targets.append(int(temp[i]))\n",
    "\n",
    "data = np.array(image)\n",
    "data = data/255\n",
    "tem_dataset=data\n",
    "data = torch.from_numpy(data).permute((0,3,2,1))\n",
    "data = data.float()\n",
    "label=targets\n",
    "targets = torch.tensor(targets)\n",
    "dataset = TensorDataset(data,targets)\n",
    "batch_size = 4\n",
    "val_size = int(np.ceil(len(dataset)*0.2))\n",
    "train_size = len(dataset) - val_size \n",
    "\n",
    "train_data,test_data = random_split(dataset,[train_size,val_size])\n",
    "train_loader = DataLoader(train_data,batch_size = batch_size,shuffle=True)\n",
    "test_loader = DataLoader(test_data,batch_size = batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3qAKondLIu6"
   },
   "source": [
    "# Data Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NSjwTNQUKoVl",
    "outputId": "613ff7b9-0e32-4545-ab5c-9430d2e69c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet Dimention:\n",
      "[3, 48, 48]\n",
      "Dataset Size:\n",
      "3762\n",
      "Num_classes:\n",
      "2\n",
      "Class Info:\n",
      "{0: 2079, 1: 1683}\n",
      "Train data size:\n",
      "3009\n",
      "Validation data size:\n",
      "753\n",
      "Features Type:\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "Class Type:\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(\"DataSet Dimention:\")\n",
    "print(list(dataset[0][0].shape))\n",
    "print(\"Dataset Size:\")\n",
    "print(len(dataset))\n",
    "print(\"Num_classes:\")\n",
    "print(len({i:label.count(i) for i in label}))\n",
    "print(\"Class Info:\")\n",
    "print({i:label.count(i) for i in label})\n",
    "print(\"Train data size:\")\n",
    "print(train_size)\n",
    "print(\"Validation data size:\")\n",
    "print(val_size)\n",
    "print(\"Features Type:\")\n",
    "print(type(dataset[1]))\n",
    "print(type(dataset[1][1]))\n",
    "print(\"Class Type:\")\n",
    "print(type(targets[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88AwPxNtLOit"
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "VUOEdd7PLLhW",
    "outputId": "e6c3f3a1-3cdd-44c9-c607-b0e07b5cb916"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_list=random.sample(range(0, 3762), 4)\n",
    "plt.figure(figsize=(16, 8))\n",
    "for i in range(4):\n",
    "    plt.subplot(140 + 1 + (i))\n",
    "    plt.imshow(tem_dataset[rand_list[i]])\n",
    "    if (label[rand_list[i]]==1):\n",
    "        plt.title('have tumor')\n",
    "    if (label[rand_list[i]]==0):\n",
    "        plt.title('have no tumor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJbiEHGELUqv"
   },
   "source": [
    "# Use CPU OR GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T4fG2pWiLRJx",
    "outputId": "75a5419a-2dc4-4a3e-e623-8665ead844ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Available: cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "     dev=cuda0 = torch.device('cuda:0')\n",
    "else:\n",
    "    dev=cuda0 = torch.device('cpu')\n",
    "print(\"Print Available: \"+str(dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlLfh7qeLb8N"
   },
   "source": [
    "# Create Helper Class for Training, Testing and Plot Loss Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "JpLx0fwGLZVd"
   },
   "outputs": [],
   "source": [
    "class Helper_FC_CNN:\n",
    "        \n",
    "    def Train_FC_CNN(self, model, train_loader, test_loader, opt, epch):\n",
    "        print(\"Training Phase is Starting:\")\n",
    "        test_acc=[]\n",
    "        loss_train_all = []\n",
    "        loss_test_all=[]\n",
    "        \n",
    "        for i in range(1, epch+1):\n",
    "            loss_train_single = []\n",
    "            model.train()\n",
    "            print(\"******************Epoch(\"+str(i)+\"):***********************\")\n",
    "            temp=1\n",
    "            for X_features, label in train_loader:        \n",
    "                X_features, label = X_features.to(dev), label.to(dev)        \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_features)\n",
    "                loss = model.get_loss(outputs, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_train_single.append(loss.item())\n",
    "                print(\"Batch \"+str(temp))\n",
    "                print(\"Loss for Batch(\"+str(temp)+\"): \"+str(loss.item()))\n",
    "                temp=temp+1\n",
    "            loss_train_all.append(np.mean(loss_train_single))\n",
    "            print(\"Avg Loss for \"+str(temp)+\" Batches\"+str(np.mean(loss_train_single)))\n",
    "            print(\"Epoch(\"+str(i)+\") Finished\")\n",
    "            tmp_tst_loss, tmp_tst_acc=self.Test_FC_CNN(model,test_loader)\n",
    "            loss_test_all.append(tmp_tst_loss)\n",
    "            test_acc.append(tmp_tst_acc)\n",
    "            \n",
    "        return loss_train_all, loss_test_all, test_acc\n",
    "        \n",
    "    def plot_loss(self, loss_train_all,status,epch):\n",
    "        plt.title(status)\n",
    "        plt.plot(range(1, epch+1), loss_train_all)\n",
    "        plt.ylabel(status)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def Test_FC_CNN(self, model, data_loader):\n",
    "        y_true, y_pred = [], []\n",
    "        test_loss=[]\n",
    "        with torch.no_grad():                \n",
    "            for X_features, label in data_loader:         \n",
    "                X_features, label = X_features.to(dev), label.to(dev)\n",
    "                outputs = model(X_features)\n",
    "                loss = model.get_loss(outputs, label)\n",
    "                test_loss.append(loss.item())\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                y_true += label.detach().cpu().numpy().tolist()\n",
    "                y_pred += np.argmax(outputs, axis=-1).tolist()\n",
    "        print(\"**********************************************\")\n",
    "        print(\"Avg Test Loss:\")\n",
    "        print(np.mean(test_loss))\n",
    "        print(\"Test Accuracy:\")\n",
    "        print(accuracy_score(y_true, y_pred))\n",
    "        print(\"**********************************************\")\n",
    "        return np.mean(test_loss), accuracy_score(y_true, y_pred)\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlshlV4SLgE_"
   },
   "source": [
    "# Define Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zlWicivNLiV6"
   },
   "outputs": [],
   "source": [
    "class FullyConnectedNN(nn.Module):\n",
    "    def __init__(self):\n",
    "            super(FullyConnectedNN, self).__init__()\n",
    "            \n",
    "            self.Fully_Connected_layers=nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3*48*48,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4,2)\n",
    "            )\n",
    "            self.cross_entropy = nn.CrossEntropyLoss()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        y_pred=self.Fully_Connected_layers(x)\n",
    "        return y_pred\n",
    "\n",
    "    def get_loss(self, y_pred, y_true):\n",
    "        loss=self.cross_entropy(y_pred,y_true)\n",
    "        return loss\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUZi9OHlLl_o"
   },
   "source": [
    "# Print Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rNTXDzMLnvz",
    "outputId": "062d7d1e-9904-4b6e-c437-1a49ec1d21ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture is:\n",
      "FullyConnectedNN(\n",
      "  (Fully_Connected_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=6912, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=512, out_features=4, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=4, out_features=2, bias=True)\n",
      "  )\n",
      "  (cross_entropy): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Linear_model=FullyConnectedNN()\n",
    "Linear_model.to(dev)\n",
    "print(\"Model Architecture is:\")\n",
    "print(Linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFackTBfL4Uv"
   },
   "source": [
    "# Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "skuIy40pLpfT"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(Linear_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-Lqg-a9MDcO"
   },
   "source": [
    "# Create Object from Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "gG0MTJkcL_xs"
   },
   "outputs": [],
   "source": [
    "linear_helper_model=Helper_FC_CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-II7pUBMO6t"
   },
   "source": [
    "# Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PUV7K5EcMTg4",
    "outputId": "f184c333-3274-4e87-be7b-a681c96b8098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "Loss for Batch(530): 0.00385101861320436\n",
      "Batch 531\n",
      "Loss for Batch(531): 0.00010340268636355177\n",
      "Batch 532\n",
      "Loss for Batch(532): 0.10590080916881561\n",
      "Batch 533\n",
      "Loss for Batch(533): 0.009981103241443634\n",
      "Batch 534\n",
      "Loss for Batch(534): 0.32089582085609436\n",
      "Batch 535\n",
      "Loss for Batch(535): 0.0005111240316182375\n",
      "Batch 536\n",
      "Loss for Batch(536): 0.033118490129709244\n",
      "Batch 537\n",
      "Loss for Batch(537): 0.02423308603465557\n",
      "Batch 538\n",
      "Loss for Batch(538): 0.0264107845723629\n",
      "Batch 539\n",
      "Loss for Batch(539): 4.213734428049065e-05\n",
      "Batch 540\n",
      "Loss for Batch(540): 0.32179200649261475\n",
      "Batch 541\n",
      "Loss for Batch(541): 0.0005197392893023789\n",
      "Batch 542\n",
      "Loss for Batch(542): 0.013696352019906044\n",
      "Batch 543\n",
      "Loss for Batch(543): 0.594851016998291\n",
      "Batch 544\n",
      "Loss for Batch(544): 0.0035746432840824127\n",
      "Batch 545\n",
      "Loss for Batch(545): 0.13443243503570557\n",
      "Batch 546\n",
      "Loss for Batch(546): 0.03767078369855881\n",
      "Batch 547\n",
      "Loss for Batch(547): 0.002553864847868681\n",
      "Batch 548\n",
      "Loss for Batch(548): 0.0015810144832357764\n",
      "Batch 549\n",
      "Loss for Batch(549): 0.166743203997612\n",
      "Batch 550\n",
      "Loss for Batch(550): 0.06059470772743225\n",
      "Batch 551\n",
      "Loss for Batch(551): 0.00653740344569087\n",
      "Batch 552\n",
      "Loss for Batch(552): 0.019584715366363525\n",
      "Batch 553\n",
      "Loss for Batch(553): 0.09959294646978378\n",
      "Batch 554\n",
      "Loss for Batch(554): 0.00010789758380269632\n",
      "Batch 555\n",
      "Loss for Batch(555): 0.02495909295976162\n",
      "Batch 556\n",
      "Loss for Batch(556): 0.000205761578399688\n",
      "Batch 557\n",
      "Loss for Batch(557): 0.0333990640938282\n",
      "Batch 558\n",
      "Loss for Batch(558): 0.011297845281660557\n",
      "Batch 559\n",
      "Loss for Batch(559): 0.006666804198175669\n",
      "Batch 560\n",
      "Loss for Batch(560): 0.01936044916510582\n",
      "Batch 561\n",
      "Loss for Batch(561): 0.7383337020874023\n",
      "Batch 562\n",
      "Loss for Batch(562): 0.5652217864990234\n",
      "Batch 563\n",
      "Loss for Batch(563): 0.019247110933065414\n",
      "Batch 564\n",
      "Loss for Batch(564): 0.02304670587182045\n",
      "Batch 565\n",
      "Loss for Batch(565): 0.0014361863723024726\n",
      "Batch 566\n",
      "Loss for Batch(566): 0.0011978789698332548\n",
      "Batch 567\n",
      "Loss for Batch(567): 0.0042569260112941265\n",
      "Batch 568\n",
      "Loss for Batch(568): 0.04734935238957405\n",
      "Batch 569\n",
      "Loss for Batch(569): 0.007919174619019032\n",
      "Batch 570\n",
      "Loss for Batch(570): 0.0007173602934926748\n",
      "Batch 571\n",
      "Loss for Batch(571): 0.07839231193065643\n",
      "Batch 572\n",
      "Loss for Batch(572): 0.0005583898746408522\n",
      "Batch 573\n",
      "Loss for Batch(573): 0.05429729074239731\n",
      "Batch 574\n",
      "Loss for Batch(574): 0.0008741325000301003\n",
      "Batch 575\n",
      "Loss for Batch(575): 0.0013582177925854921\n",
      "Batch 576\n",
      "Loss for Batch(576): 0.037022046744823456\n",
      "Batch 577\n",
      "Loss for Batch(577): 0.035676226019859314\n",
      "Batch 578\n",
      "Loss for Batch(578): 0.0023792791180312634\n",
      "Batch 579\n",
      "Loss for Batch(579): 0.002880498068407178\n",
      "Batch 580\n",
      "Loss for Batch(580): 0.06107017397880554\n",
      "Batch 581\n",
      "Loss for Batch(581): 0.0007945954566821456\n",
      "Batch 582\n",
      "Loss for Batch(582): 0.0030297499615699053\n",
      "Batch 583\n",
      "Loss for Batch(583): 0.01213466003537178\n",
      "Batch 584\n",
      "Loss for Batch(584): 0.13346220552921295\n",
      "Batch 585\n",
      "Loss for Batch(585): 0.1130610853433609\n",
      "Batch 586\n",
      "Loss for Batch(586): 0.202903613448143\n",
      "Batch 587\n",
      "Loss for Batch(587): 0.013340089470148087\n",
      "Batch 588\n",
      "Loss for Batch(588): 0.055573925375938416\n",
      "Batch 589\n",
      "Loss for Batch(589): 0.2838217616081238\n",
      "Batch 590\n",
      "Loss for Batch(590): 0.0004228710022289306\n",
      "Batch 591\n",
      "Loss for Batch(591): 0.012094499543309212\n",
      "Batch 592\n",
      "Loss for Batch(592): 0.03254581242799759\n",
      "Batch 593\n",
      "Loss for Batch(593): 0.00752995302900672\n",
      "Batch 594\n",
      "Loss for Batch(594): 0.5522335171699524\n",
      "Batch 595\n",
      "Loss for Batch(595): 1.4671250581741333\n",
      "Batch 596\n",
      "Loss for Batch(596): 0.0002291717246407643\n",
      "Batch 597\n",
      "Loss for Batch(597): 0.19010306894779205\n",
      "Batch 598\n",
      "Loss for Batch(598): 0.00023174969828687608\n",
      "Batch 599\n",
      "Loss for Batch(599): 0.004321526736021042\n",
      "Batch 600\n",
      "Loss for Batch(600): 0.001702422508969903\n",
      "Batch 601\n",
      "Loss for Batch(601): 0.16052736341953278\n",
      "Batch 602\n",
      "Loss for Batch(602): 0.0029757567681372166\n",
      "Batch 603\n",
      "Loss for Batch(603): 0.013228246942162514\n",
      "Batch 604\n",
      "Loss for Batch(604): 0.20337684452533722\n",
      "Batch 605\n",
      "Loss for Batch(605): 0.09551534056663513\n",
      "Batch 606\n",
      "Loss for Batch(606): 0.019410796463489532\n",
      "Batch 607\n",
      "Loss for Batch(607): 0.09692063927650452\n",
      "Batch 608\n",
      "Loss for Batch(608): 0.42184484004974365\n",
      "Batch 609\n",
      "Loss for Batch(609): 0.005886538419872522\n",
      "Batch 610\n",
      "Loss for Batch(610): 0.01319774892181158\n",
      "Batch 611\n",
      "Loss for Batch(611): 0.0011658068979158998\n",
      "Batch 612\n",
      "Loss for Batch(612): 0.0032925214618444443\n",
      "Batch 613\n",
      "Loss for Batch(613): 0.00960584543645382\n",
      "Batch 614\n",
      "Loss for Batch(614): 0.04230792075395584\n",
      "Batch 615\n",
      "Loss for Batch(615): 0.021154243499040604\n",
      "Batch 616\n",
      "Loss for Batch(616): 0.013804389163851738\n",
      "Batch 617\n",
      "Loss for Batch(617): 0.001268017920665443\n",
      "Batch 618\n",
      "Loss for Batch(618): 0.011018496006727219\n",
      "Batch 619\n",
      "Loss for Batch(619): 0.000697784242220223\n",
      "Batch 620\n",
      "Loss for Batch(620): 0.0033642263151705265\n",
      "Batch 621\n",
      "Loss for Batch(621): 0.00012320875248406082\n",
      "Batch 622\n",
      "Loss for Batch(622): 0.026413511484861374\n",
      "Batch 623\n",
      "Loss for Batch(623): 0.021098854020237923\n",
      "Batch 624\n",
      "Loss for Batch(624): 0.030345285311341286\n",
      "Batch 625\n",
      "Loss for Batch(625): 0.008009891957044601\n",
      "Batch 626\n",
      "Loss for Batch(626): 0.011902740225195885\n",
      "Batch 627\n",
      "Loss for Batch(627): 0.053437478840351105\n",
      "Batch 628\n",
      "Loss for Batch(628): 0.027746817097067833\n",
      "Batch 629\n",
      "Loss for Batch(629): 0.005521081387996674\n",
      "Batch 630\n",
      "Loss for Batch(630): 0.032778650522232056\n",
      "Batch 631\n",
      "Loss for Batch(631): 0.014261635951697826\n",
      "Batch 632\n",
      "Loss for Batch(632): 0.0008869862649589777\n",
      "Batch 633\n",
      "Loss for Batch(633): 0.01184588111937046\n",
      "Batch 634\n",
      "Loss for Batch(634): 0.00025762023869901896\n",
      "Batch 635\n",
      "Loss for Batch(635): 0.0037245973944664\n",
      "Batch 636\n",
      "Loss for Batch(636): 0.003856521099805832\n",
      "Batch 637\n",
      "Loss for Batch(637): 0.049602385610342026\n",
      "Batch 638\n",
      "Loss for Batch(638): 0.1366647481918335\n",
      "Batch 639\n",
      "Loss for Batch(639): 0.00397722190245986\n",
      "Batch 640\n",
      "Loss for Batch(640): 0.0004325474437791854\n",
      "Batch 641\n",
      "Loss for Batch(641): 0.003412656718865037\n",
      "Batch 642\n",
      "Loss for Batch(642): 0.01849237084388733\n",
      "Batch 643\n",
      "Loss for Batch(643): 0.0016124306712299585\n",
      "Batch 644\n",
      "Loss for Batch(644): 0.008702549152076244\n",
      "Batch 645\n",
      "Loss for Batch(645): 0.07781665027141571\n",
      "Batch 646\n",
      "Loss for Batch(646): 0.04378242418169975\n",
      "Batch 647\n",
      "Loss for Batch(647): 0.13758158683776855\n",
      "Batch 648\n",
      "Loss for Batch(648): 0.00494621554389596\n",
      "Batch 649\n",
      "Loss for Batch(649): 0.0013634363422170281\n",
      "Batch 650\n",
      "Loss for Batch(650): 0.002745692851021886\n",
      "Batch 651\n",
      "Loss for Batch(651): 0.14738327264785767\n",
      "Batch 652\n",
      "Loss for Batch(652): 0.0025745234452188015\n",
      "Batch 653\n",
      "Loss for Batch(653): 0.004099284298717976\n",
      "Batch 654\n",
      "Loss for Batch(654): 0.0014524710131809115\n",
      "Batch 655\n",
      "Loss for Batch(655): 0.0046282364055514336\n",
      "Batch 656\n",
      "Loss for Batch(656): 0.0003627822152338922\n",
      "Batch 657\n",
      "Loss for Batch(657): 0.0025295219384133816\n",
      "Batch 658\n",
      "Loss for Batch(658): 0.006533588282763958\n",
      "Batch 659\n",
      "Loss for Batch(659): 0.002729560947045684\n",
      "Batch 660\n",
      "Loss for Batch(660): 0.04274558648467064\n",
      "Batch 661\n",
      "Loss for Batch(661): 0.02232881635427475\n",
      "Batch 662\n",
      "Loss for Batch(662): 0.01760903187096119\n",
      "Batch 663\n",
      "Loss for Batch(663): 0.014237587340176105\n",
      "Batch 664\n",
      "Loss for Batch(664): 0.00025521026691421866\n",
      "Batch 665\n",
      "Loss for Batch(665): 0.010612291283905506\n",
      "Batch 666\n",
      "Loss for Batch(666): 0.004158437717705965\n",
      "Batch 667\n",
      "Loss for Batch(667): 0.1851978898048401\n",
      "Batch 668\n",
      "Loss for Batch(668): 0.0015865801833570004\n",
      "Batch 669\n",
      "Loss for Batch(669): 0.063262939453125\n",
      "Batch 670\n",
      "Loss for Batch(670): 0.0058112055994570255\n",
      "Batch 671\n",
      "Loss for Batch(671): 1.1491564512252808\n",
      "Batch 672\n",
      "Loss for Batch(672): 0.00048254436114802957\n",
      "Batch 673\n",
      "Loss for Batch(673): 2.2052810891182162e-05\n",
      "Batch 674\n",
      "Loss for Batch(674): 0.4328642189502716\n",
      "Batch 675\n",
      "Loss for Batch(675): 0.010714069940149784\n",
      "Batch 676\n",
      "Loss for Batch(676): 0.017581911757588387\n",
      "Batch 677\n",
      "Loss for Batch(677): 0.23800797760486603\n",
      "Batch 678\n",
      "Loss for Batch(678): 0.03059486858546734\n",
      "Batch 679\n",
      "Loss for Batch(679): 0.03341618552803993\n",
      "Batch 680\n",
      "Loss for Batch(680): 0.011094900779426098\n",
      "Batch 681\n",
      "Loss for Batch(681): 0.0006907250499352813\n",
      "Batch 682\n",
      "Loss for Batch(682): 0.002590668387711048\n",
      "Batch 683\n",
      "Loss for Batch(683): 0.038242559880018234\n",
      "Batch 684\n",
      "Loss for Batch(684): 0.0007543706451542675\n",
      "Batch 685\n",
      "Loss for Batch(685): 0.0336274616420269\n",
      "Batch 686\n",
      "Loss for Batch(686): 0.0037448888178914785\n",
      "Batch 687\n",
      "Loss for Batch(687): 0.008290555328130722\n",
      "Batch 688\n",
      "Loss for Batch(688): 0.001889452338218689\n",
      "Batch 689\n",
      "Loss for Batch(689): 0.04335760325193405\n",
      "Batch 690\n",
      "Loss for Batch(690): 0.011075719259679317\n",
      "Batch 691\n",
      "Loss for Batch(691): 0.032890014350414276\n",
      "Batch 692\n",
      "Loss for Batch(692): 0.018330348655581474\n",
      "Batch 693\n",
      "Loss for Batch(693): 0.0004369193920865655\n",
      "Batch 694\n",
      "Loss for Batch(694): 0.0004254855739418417\n",
      "Batch 695\n",
      "Loss for Batch(695): 0.009714015759527683\n",
      "Batch 696\n",
      "Loss for Batch(696): 0.05013549327850342\n",
      "Batch 697\n",
      "Loss for Batch(697): 0.004146476276218891\n",
      "Batch 698\n",
      "Loss for Batch(698): 0.0006031772354617715\n",
      "Batch 699\n",
      "Loss for Batch(699): 0.029497064650058746\n",
      "Batch 700\n",
      "Loss for Batch(700): 0.00992223434150219\n",
      "Batch 701\n",
      "Loss for Batch(701): 0.004729233682155609\n",
      "Batch 702\n",
      "Loss for Batch(702): 0.011004745960235596\n",
      "Batch 703\n",
      "Loss for Batch(703): 0.0006766583537682891\n",
      "Batch 704\n",
      "Loss for Batch(704): 0.0003899807343259454\n",
      "Batch 705\n",
      "Loss for Batch(705): 0.03628867492079735\n",
      "Batch 706\n",
      "Loss for Batch(706): 0.004588652402162552\n",
      "Batch 707\n",
      "Loss for Batch(707): 0.01318423543125391\n",
      "Batch 708\n",
      "Loss for Batch(708): 0.0006263565737754107\n",
      "Batch 709\n",
      "Loss for Batch(709): 0.003233638359233737\n",
      "Batch 710\n",
      "Loss for Batch(710): 0.0006394363008439541\n",
      "Batch 711\n",
      "Loss for Batch(711): 0.10518119484186172\n",
      "Batch 712\n",
      "Loss for Batch(712): 0.06329677253961563\n",
      "Batch 713\n",
      "Loss for Batch(713): 0.010083101689815521\n",
      "Batch 714\n",
      "Loss for Batch(714): 0.00035934383049607277\n",
      "Batch 715\n",
      "Loss for Batch(715): 0.003932626452296972\n",
      "Batch 716\n",
      "Loss for Batch(716): 0.0055044605396687984\n",
      "Batch 717\n",
      "Loss for Batch(717): 0.008594225160777569\n",
      "Batch 718\n",
      "Loss for Batch(718): 0.04165398329496384\n",
      "Batch 719\n",
      "Loss for Batch(719): 0.001646536635234952\n",
      "Batch 720\n",
      "Loss for Batch(720): 0.11326435953378677\n",
      "Batch 721\n",
      "Loss for Batch(721): 0.027972744777798653\n",
      "Batch 722\n",
      "Loss for Batch(722): 0.0011161081492900848\n",
      "Batch 723\n",
      "Loss for Batch(723): 0.012768101878464222\n",
      "Batch 724\n",
      "Loss for Batch(724): 0.0062537966296076775\n",
      "Batch 725\n",
      "Loss for Batch(725): 0.0013315621763467789\n",
      "Batch 726\n",
      "Loss for Batch(726): 0.00848948024213314\n",
      "Batch 727\n",
      "Loss for Batch(727): 0.01435075607150793\n",
      "Batch 728\n",
      "Loss for Batch(728): 0.008331220597028732\n",
      "Batch 729\n",
      "Loss for Batch(729): 0.0016344194300472736\n",
      "Batch 730\n",
      "Loss for Batch(730): 0.007879038341343403\n",
      "Batch 731\n",
      "Loss for Batch(731): 0.015380270779132843\n",
      "Batch 732\n",
      "Loss for Batch(732): 0.0012866836041212082\n",
      "Batch 733\n",
      "Loss for Batch(733): 0.0019709032494574785\n",
      "Batch 734\n",
      "Loss for Batch(734): 0.26011112332344055\n",
      "Batch 735\n",
      "Loss for Batch(735): 0.08486728370189667\n",
      "Batch 736\n",
      "Loss for Batch(736): 0.24236901104450226\n",
      "Batch 737\n",
      "Loss for Batch(737): 0.20045927166938782\n",
      "Batch 738\n",
      "Loss for Batch(738): 0.1134311705827713\n",
      "Batch 739\n",
      "Loss for Batch(739): 0.005120537243783474\n",
      "Batch 740\n",
      "Loss for Batch(740): 0.033652618527412415\n",
      "Batch 741\n",
      "Loss for Batch(741): 5.3105424740351737e-05\n",
      "Batch 742\n",
      "Loss for Batch(742): 0.030274225398898125\n",
      "Batch 743\n",
      "Loss for Batch(743): 0.26171010732650757\n",
      "Batch 744\n",
      "Loss for Batch(744): 0.024282321333885193\n",
      "Batch 745\n",
      "Loss for Batch(745): 0.046018682420253754\n",
      "Batch 746\n",
      "Loss for Batch(746): 0.0012959386222064495\n",
      "Batch 747\n",
      "Loss for Batch(747): 0.02716747485101223\n",
      "Batch 748\n",
      "Loss for Batch(748): 0.16335928440093994\n",
      "Batch 749\n",
      "Loss for Batch(749): 0.011948894709348679\n",
      "Batch 750\n",
      "Loss for Batch(750): 0.0017927137669175863\n",
      "Batch 751\n",
      "Loss for Batch(751): 0.19554321467876434\n",
      "Batch 752\n",
      "Loss for Batch(752): 0.03890231251716614\n",
      "Batch 753\n",
      "Loss for Batch(753): 0.013084269128739834\n",
      "Avg Loss for 754 Batches0.05632556695892437\n",
      "Epoch(97) Finished\n",
      "**********************************************\n",
      "Avg Test Loss:\n",
      "0.2270557943721691\n",
      "Test Accuracy:\n",
      "0.9229747675962815\n",
      "**********************************************\n",
      "******************Epoch(98):***********************\n",
      "Batch 1\n",
      "Loss for Batch(1): 0.0001497750054113567\n",
      "Batch 2\n",
      "Loss for Batch(2): 0.009046629071235657\n",
      "Batch 3\n",
      "Loss for Batch(3): 0.11863259226083755\n",
      "Batch 4\n",
      "Loss for Batch(4): 0.07751748710870743\n",
      "Batch 5\n",
      "Loss for Batch(5): 0.003920587711036205\n",
      "Batch 6\n",
      "Loss for Batch(6): 0.002509665209800005\n",
      "Batch 7\n",
      "Loss for Batch(7): 0.027521349489688873\n",
      "Batch 8\n",
      "Loss for Batch(8): 0.030325280502438545\n",
      "Batch 9\n",
      "Loss for Batch(9): 0.0010451548732817173\n",
      "Batch 10\n",
      "Loss for Batch(10): 0.009938567876815796\n",
      "Batch 11\n",
      "Loss for Batch(11): 0.0024276585318148136\n",
      "Batch 12\n",
      "Loss for Batch(12): 0.003280114848166704\n",
      "Batch 13\n",
      "Loss for Batch(13): 0.03197695314884186\n",
      "Batch 14\n",
      "Loss for Batch(14): 0.003946946933865547\n",
      "Batch 15\n",
      "Loss for Batch(15): 0.01220625452697277\n",
      "Batch 16\n",
      "Loss for Batch(16): 0.2162216603755951\n",
      "Batch 17\n",
      "Loss for Batch(17): 0.010243055410683155\n",
      "Batch 18\n",
      "Loss for Batch(18): 0.0912381187081337\n",
      "Batch 19\n",
      "Loss for Batch(19): 0.05887245386838913\n",
      "Batch 20\n",
      "Loss for Batch(20): 0.001222326885908842\n",
      "Batch 21\n",
      "Loss for Batch(21): 0.004537192638963461\n",
      "Batch 22\n",
      "Loss for Batch(22): 0.18534880876541138\n",
      "Batch 23\n",
      "Loss for Batch(23): 0.006652193143963814\n",
      "Batch 24\n",
      "Loss for Batch(24): 0.30956700444221497\n",
      "Batch 25\n",
      "Loss for Batch(25): 0.007579543627798557\n",
      "Batch 26\n",
      "Loss for Batch(26): 0.045170124620199203\n",
      "Batch 27\n",
      "Loss for Batch(27): 0.0011142375878989697\n",
      "Batch 28\n",
      "Loss for Batch(28): 0.019538704305887222\n",
      "Batch 29\n",
      "Loss for Batch(29): 0.046566855162382126\n",
      "Batch 30\n",
      "Loss for Batch(30): 0.06025765463709831\n",
      "Batch 31\n",
      "Loss for Batch(31): 0.014943331480026245\n",
      "Batch 32\n",
      "Loss for Batch(32): 0.0459359772503376\n",
      "Batch 33\n",
      "Loss for Batch(33): 0.009448067285120487\n",
      "Batch 34\n",
      "Loss for Batch(34): 0.02427685260772705\n",
      "Batch 35\n",
      "Loss for Batch(35): 0.019002031534910202\n",
      "Batch 36\n",
      "Loss for Batch(36): 0.012560890056192875\n",
      "Batch 37\n",
      "Loss for Batch(37): 5.548947228817269e-05\n",
      "Batch 38\n",
      "Loss for Batch(38): 0.0005695061990991235\n",
      "Batch 39\n",
      "Loss for Batch(39): 0.032192349433898926\n",
      "Batch 40\n",
      "Loss for Batch(40): 0.026491543278098106\n",
      "Batch 41\n",
      "Loss for Batch(41): 0.02573539689183235\n",
      "Batch 42\n",
      "Loss for Batch(42): 0.00900976825505495\n",
      "Batch 43\n",
      "Loss for Batch(43): 0.04405594617128372\n",
      "Batch 44\n",
      "Loss for Batch(44): 0.009797988459467888\n",
      "Batch 45\n",
      "Loss for Batch(45): 0.06925930082798004\n",
      "Batch 46\n",
      "Loss for Batch(46): 0.015159369446337223\n",
      "Batch 47\n",
      "Loss for Batch(47): 0.002027214039117098\n",
      "Batch 48\n",
      "Loss for Batch(48): 0.0013023853534832597\n",
      "Batch 49\n",
      "Loss for Batch(49): 0.34851765632629395\n",
      "Batch 50\n",
      "Loss for Batch(50): 0.1265200823545456\n",
      "Batch 51\n",
      "Loss for Batch(51): 0.03803073614835739\n",
      "Batch 52\n",
      "Loss for Batch(52): 0.0007440518238581717\n",
      "Batch 53\n",
      "Loss for Batch(53): 0.33289116621017456\n",
      "Batch 54\n",
      "Loss for Batch(54): 0.004940313287079334\n",
      "Batch 55\n",
      "Loss for Batch(55): 0.010361801832914352\n",
      "Batch 56\n",
      "Loss for Batch(56): 0.014069038443267345\n",
      "Batch 57\n",
      "Loss for Batch(57): 0.008857755921781063\n",
      "Batch 58\n",
      "Loss for Batch(58): 0.017124492675065994\n",
      "Batch 59\n",
      "Loss for Batch(59): 0.00478338822722435\n",
      "Batch 60\n",
      "Loss for Batch(60): 4.0530999285692815e-06\n",
      "Batch 61\n",
      "Loss for Batch(61): 0.0028256112709641457\n",
      "Batch 62\n",
      "Loss for Batch(62): 0.016059860587120056\n",
      "Batch 63\n",
      "Loss for Batch(63): 0.001993931131437421\n",
      "Batch 64\n",
      "Loss for Batch(64): 0.07384871691465378\n",
      "Batch 65\n",
      "Loss for Batch(65): 0.00366932712495327\n",
      "Batch 66\n",
      "Loss for Batch(66): 0.004875935148447752\n",
      "Batch 67\n",
      "Loss for Batch(67): 0.009211888536810875\n",
      "Batch 68\n",
      "Loss for Batch(68): 0.0022819035220891237\n",
      "Batch 69\n",
      "Loss for Batch(69): 0.0032112859189510345\n",
      "Batch 70\n",
      "Loss for Batch(70): 0.0494801364839077\n",
      "Batch 71\n",
      "Loss for Batch(71): 0.0005007438594475389\n",
      "Batch 72\n",
      "Loss for Batch(72): 0.06633792817592621\n",
      "Batch 73\n",
      "Loss for Batch(73): 0.21504917740821838\n",
      "Batch 74\n",
      "Loss for Batch(74): 0.019530050456523895\n",
      "Batch 75\n",
      "Loss for Batch(75): 0.00013739893620368093\n",
      "Batch 76\n",
      "Loss for Batch(76): 0.14202456176280975\n",
      "Batch 77\n",
      "Loss for Batch(77): 0.010104959830641747\n",
      "Batch 78\n",
      "Loss for Batch(78): 0.33631664514541626\n",
      "Batch 79\n",
      "Loss for Batch(79): 0.016172656789422035\n",
      "Batch 80\n",
      "Loss for Batch(80): 0.011910423636436462\n",
      "Batch 81\n",
      "Loss for Batch(81): 0.04368295893073082\n",
      "Batch 82\n",
      "Loss for Batch(82): 0.17683018743991852\n",
      "Batch 83\n",
      "Loss for Batch(83): 0.005558227188885212\n",
      "Batch 84\n",
      "Loss for Batch(84): 0.001567979110404849\n",
      "Batch 85\n",
      "Loss for Batch(85): 0.04735083505511284\n",
      "Batch 86\n",
      "Loss for Batch(86): 0.05506868660449982\n",
      "Batch 87\n",
      "Loss for Batch(87): 0.0066451565362513065\n",
      "Batch 88\n",
      "Loss for Batch(88): 0.00030741459340788424\n",
      "Batch 89\n",
      "Loss for Batch(89): 0.36763739585876465\n",
      "Batch 90\n",
      "Loss for Batch(90): 0.08074638992547989\n",
      "Batch 91\n",
      "Loss for Batch(91): 0.017200952395796776\n",
      "Batch 92\n",
      "Loss for Batch(92): 0.00040244057890959084\n",
      "Batch 93\n",
      "Loss for Batch(93): 0.018656928092241287\n",
      "Batch 94\n",
      "Loss for Batch(94): 0.016768474131822586\n",
      "Batch 95\n",
      "Loss for Batch(95): 0.00769685348495841\n",
      "Batch 96\n",
      "Loss for Batch(96): 0.007171653211116791\n",
      "Batch 97\n",
      "Loss for Batch(97): 0.054012078791856766\n",
      "Batch 98\n",
      "Loss for Batch(98): 0.02693181112408638\n",
      "Batch 99\n",
      "Loss for Batch(99): 0.01540630217641592\n",
      "Batch 100\n",
      "Loss for Batch(100): 0.041058629751205444\n",
      "Batch 101\n",
      "Loss for Batch(101): 0.006060655694454908\n",
      "Batch 102\n",
      "Loss for Batch(102): 0.006837577559053898\n",
      "Batch 103\n",
      "Loss for Batch(103): 0.09535551816225052\n",
      "Batch 104\n",
      "Loss for Batch(104): 0.03703760728240013\n",
      "Batch 105\n",
      "Loss for Batch(105): 0.08891047537326813\n",
      "Batch 106\n",
      "Loss for Batch(106): 0.03090319223701954\n",
      "Batch 107\n",
      "Loss for Batch(107): 0.04789241775870323\n",
      "Batch 108\n",
      "Loss for Batch(108): 0.018229801207780838\n",
      "Batch 109\n",
      "Loss for Batch(109): 0.0028642783872783184\n",
      "Batch 110\n",
      "Loss for Batch(110): 0.16713829338550568\n",
      "Batch 111\n",
      "Loss for Batch(111): 0.002758450573310256\n",
      "Batch 112\n",
      "Loss for Batch(112): 0.27382078766822815\n",
      "Batch 113\n",
      "Loss for Batch(113): 0.015177705325186253\n",
      "Batch 114\n",
      "Loss for Batch(114): 0.4403301179409027\n",
      "Batch 115\n",
      "Loss for Batch(115): 0.000628066249191761\n",
      "Batch 116\n",
      "Loss for Batch(116): 0.007673926651477814\n",
      "Batch 117\n",
      "Loss for Batch(117): 0.2082342654466629\n",
      "Batch 118\n",
      "Loss for Batch(118): 0.3067893385887146\n",
      "Batch 119\n",
      "Loss for Batch(119): 0.002786041470244527\n",
      "Batch 120\n",
      "Loss for Batch(120): 0.32907381653785706\n",
      "Batch 121\n",
      "Loss for Batch(121): 0.17231278121471405\n",
      "Batch 122\n",
      "Loss for Batch(122): 0.18744292855262756\n",
      "Batch 123\n",
      "Loss for Batch(123): 0.007338791619986296\n",
      "Batch 124\n",
      "Loss for Batch(124): 0.0045906417071819305\n",
      "Batch 125\n",
      "Loss for Batch(125): 0.051798392087221146\n",
      "Batch 126\n",
      "Loss for Batch(126): 0.009062926284968853\n",
      "Batch 127\n",
      "Loss for Batch(127): 0.3711097240447998\n",
      "Batch 128\n",
      "Loss for Batch(128): 0.027147000655531883\n",
      "Batch 129\n",
      "Loss for Batch(129): 0.0003094904823228717\n",
      "Batch 130\n",
      "Loss for Batch(130): 0.0075703877955675125\n",
      "Batch 131\n",
      "Loss for Batch(131): 0.007134642917662859\n",
      "Batch 132\n",
      "Loss for Batch(132): 0.04420366883277893\n",
      "Batch 133\n",
      "Loss for Batch(133): 0.010967830196022987\n",
      "Batch 134\n",
      "Loss for Batch(134): 0.022048886865377426\n",
      "Batch 135\n",
      "Loss for Batch(135): 0.0008041708497330546\n",
      "Batch 136\n",
      "Loss for Batch(136): 0.15890929102897644\n",
      "Batch 137\n",
      "Loss for Batch(137): 0.024987176060676575\n",
      "Batch 138\n",
      "Loss for Batch(138): 0.005539532285183668\n",
      "Batch 139\n",
      "Loss for Batch(139): 0.06974326074123383\n",
      "Batch 140\n",
      "Loss for Batch(140): 0.04041131213307381\n",
      "Batch 141\n",
      "Loss for Batch(141): 0.0019487615209072828\n",
      "Batch 142\n",
      "Loss for Batch(142): 0.019657712429761887\n",
      "Batch 143\n",
      "Loss for Batch(143): 0.0037156513426452875\n",
      "Batch 144\n",
      "Loss for Batch(144): 0.005488777998834848\n",
      "Batch 145\n",
      "Loss for Batch(145): 0.0008210956584662199\n",
      "Batch 146\n",
      "Loss for Batch(146): 0.3176020383834839\n",
      "Batch 147\n",
      "Loss for Batch(147): 0.045297395437955856\n",
      "Batch 148\n",
      "Loss for Batch(148): 0.01252460852265358\n",
      "Batch 149\n",
      "Loss for Batch(149): 0.17504437267780304\n",
      "Batch 150\n",
      "Loss for Batch(150): 0.017147991806268692\n",
      "Batch 151\n",
      "Loss for Batch(151): 0.0007638238603249192\n",
      "Batch 152\n",
      "Loss for Batch(152): 0.1092706099152565\n",
      "Batch 153\n",
      "Loss for Batch(153): 0.0002816411724779755\n",
      "Batch 154\n",
      "Loss for Batch(154): 0.048413895070552826\n",
      "Batch 155\n",
      "Loss for Batch(155): 0.006464920938014984\n",
      "Batch 156\n",
      "Loss for Batch(156): 0.10376535356044769\n",
      "Batch 157\n",
      "Loss for Batch(157): 0.006890561431646347\n",
      "Batch 158\n",
      "Loss for Batch(158): 0.05828147754073143\n",
      "Batch 159\n",
      "Loss for Batch(159): 0.007061704993247986\n",
      "Batch 160\n",
      "Loss for Batch(160): 0.0265982486307621\n",
      "Batch 161\n",
      "Loss for Batch(161): 0.05458963289856911\n",
      "Batch 162\n",
      "Loss for Batch(162): 0.04782624542713165\n",
      "Batch 163\n",
      "Loss for Batch(163): 0.03056924417614937\n",
      "Batch 164\n",
      "Loss for Batch(164): 0.0002942085266113281\n",
      "Batch 165\n",
      "Loss for Batch(165): 0.004996425937861204\n",
      "Batch 166\n",
      "Loss for Batch(166): 0.010802115313708782\n",
      "Batch 167\n",
      "Loss for Batch(167): 0.002049028407782316\n",
      "Batch 168\n",
      "Loss for Batch(168): 0.023246414959430695\n",
      "Batch 169\n",
      "Loss for Batch(169): 0.21952030062675476\n",
      "Batch 170\n",
      "Loss for Batch(170): 0.013500276021659374\n",
      "Batch 171\n",
      "Loss for Batch(171): 0.2206392139196396\n",
      "Batch 172\n",
      "Loss for Batch(172): 0.03431102633476257\n",
      "Batch 173\n",
      "Loss for Batch(173): 0.016428891569375992\n",
      "Batch 174\n",
      "Loss for Batch(174): 0.07807305455207825\n",
      "Batch 175\n",
      "Loss for Batch(175): 0.029758106917142868\n",
      "Batch 176\n",
      "Loss for Batch(176): 0.0015892924275249243\n",
      "Batch 177\n",
      "Loss for Batch(177): 0.00018590298714116216\n",
      "Batch 178\n",
      "Loss for Batch(178): 0.0057068741880357265\n",
      "Batch 179\n",
      "Loss for Batch(179): 0.007765938062220812\n",
      "Batch 180\n",
      "Loss for Batch(180): 0.0020956776570528746\n",
      "Batch 181\n",
      "Loss for Batch(181): 0.016490746289491653\n",
      "Batch 182\n",
      "Loss for Batch(182): 0.09611037373542786\n",
      "Batch 183\n",
      "Loss for Batch(183): 0.007012233138084412\n",
      "Batch 184\n",
      "Loss for Batch(184): 0.00437247846275568\n",
      "Batch 185\n",
      "Loss for Batch(185): 0.022236185148358345\n",
      "Batch 186\n",
      "Loss for Batch(186): 0.011790826916694641\n",
      "Batch 187\n",
      "Loss for Batch(187): 0.0014750462723895907\n",
      "Batch 188\n",
      "Loss for Batch(188): 0.0357624813914299\n",
      "Batch 189\n",
      "Loss for Batch(189): 0.003395700827240944\n",
      "Batch 190\n",
      "Loss for Batch(190): 0.05875541269779205\n",
      "Batch 191\n",
      "Loss for Batch(191): 0.006598008796572685\n",
      "Batch 192\n",
      "Loss for Batch(192): 0.6283959746360779\n",
      "Batch 193\n",
      "Loss for Batch(193): 0.026581112295389175\n",
      "Batch 194\n",
      "Loss for Batch(194): 0.007321596145629883\n",
      "Batch 195\n",
      "Loss for Batch(195): 0.0027634217403829098\n",
      "Batch 196\n",
      "Loss for Batch(196): 0.02107403054833412\n",
      "Batch 197\n",
      "Loss for Batch(197): 0.02518627792596817\n",
      "Batch 198\n",
      "Loss for Batch(198): 0.1174749955534935\n",
      "Batch 199\n",
      "Loss for Batch(199): 0.0012263477547094226\n",
      "Batch 200\n",
      "Loss for Batch(200): 0.0006014302489347756\n",
      "Batch 201\n",
      "Loss for Batch(201): 0.00037411946686916053\n",
      "Batch 202\n",
      "Loss for Batch(202): 0.13774430751800537\n",
      "Batch 203\n",
      "Loss for Batch(203): 0.01959117501974106\n",
      "Batch 204\n",
      "Loss for Batch(204): 0.0017244501505047083\n",
      "Batch 205\n",
      "Loss for Batch(205): 0.49612393975257874\n",
      "Batch 206\n",
      "Loss for Batch(206): 0.48773324489593506\n",
      "Batch 207\n",
      "Loss for Batch(207): 0.00206186855211854\n",
      "Batch 208\n",
      "Loss for Batch(208): 0.04465539753437042\n",
      "Batch 209\n",
      "Loss for Batch(209): 0.00041708245407789946\n",
      "Batch 210\n",
      "Loss for Batch(210): 0.018042828887701035\n",
      "Batch 211\n",
      "Loss for Batch(211): 0.004412089940160513\n",
      "Batch 212\n",
      "Loss for Batch(212): 0.0269126296043396\n",
      "Batch 213\n",
      "Loss for Batch(213): 0.004413945134729147\n",
      "Batch 214\n",
      "Loss for Batch(214): 0.0026232965756207705\n",
      "Batch 215\n",
      "Loss for Batch(215): 0.0007631953922100365\n",
      "Batch 216\n",
      "Loss for Batch(216): 0.13824182748794556\n",
      "Batch 217\n",
      "Loss for Batch(217): 0.019905289635062218\n",
      "Batch 218\n",
      "Loss for Batch(218): 0.08336646109819412\n",
      "Batch 219\n",
      "Loss for Batch(219): 0.1148383691906929\n",
      "Batch 220\n",
      "Loss for Batch(220): 0.04193967580795288\n",
      "Batch 221\n",
      "Loss for Batch(221): 0.03615792840719223\n",
      "Batch 222\n",
      "Loss for Batch(222): 0.0026857363991439342\n",
      "Batch 223\n",
      "Loss for Batch(223): 0.001706420793198049\n",
      "Batch 224\n",
      "Loss for Batch(224): 0.002653171308338642\n",
      "Batch 225\n",
      "Loss for Batch(225): 0.0011073453351855278\n",
      "Batch 226\n",
      "Loss for Batch(226): 0.0033200830221176147\n",
      "Batch 227\n",
      "Loss for Batch(227): 0.01670595444738865\n",
      "Batch 228\n",
      "Loss for Batch(228): 0.08234541863203049\n",
      "Batch 229\n",
      "Loss for Batch(229): 0.07285704463720322\n",
      "Batch 230\n",
      "Loss for Batch(230): 0.48671749234199524\n",
      "Batch 231\n",
      "Loss for Batch(231): 0.20105552673339844\n",
      "Batch 232\n",
      "Loss for Batch(232): 0.01958058588206768\n",
      "Batch 233\n",
      "Loss for Batch(233): 0.0007361634634435177\n",
      "Batch 234\n",
      "Loss for Batch(234): 0.05391532555222511\n",
      "Batch 235\n",
      "Loss for Batch(235): 0.03818270191550255\n",
      "Batch 236\n",
      "Loss for Batch(236): 0.12775415182113647\n",
      "Batch 237\n",
      "Loss for Batch(237): 0.37998080253601074\n",
      "Batch 238\n",
      "Loss for Batch(238): 0.001561049371957779\n",
      "Batch 239\n",
      "Loss for Batch(239): 0.0331127867102623\n",
      "Batch 240\n",
      "Loss for Batch(240): 0.014993712306022644\n",
      "Batch 241\n",
      "Loss for Batch(241): 0.22748932242393494\n",
      "Batch 242\n",
      "Loss for Batch(242): 0.00111477542668581\n",
      "Batch 243\n",
      "Loss for Batch(243): 0.0663946121931076\n",
      "Batch 244\n",
      "Loss for Batch(244): 0.062254272401332855\n",
      "Batch 245\n",
      "Loss for Batch(245): 0.07621022313833237\n",
      "Batch 246\n",
      "Loss for Batch(246): 0.02016443759202957\n",
      "Batch 247\n",
      "Loss for Batch(247): 0.02062906138598919\n",
      "Batch 248\n",
      "Loss for Batch(248): 0.00018930115038529038\n",
      "Batch 249\n",
      "Loss for Batch(249): 0.010434272699058056\n",
      "Batch 250\n",
      "Loss for Batch(250): 0.006003490649163723\n",
      "Batch 251\n",
      "Loss for Batch(251): 0.03223339468240738\n",
      "Batch 252\n",
      "Loss for Batch(252): 0.0015086265048012137\n",
      "Batch 253\n",
      "Loss for Batch(253): 0.06490647792816162\n",
      "Batch 254\n",
      "Loss for Batch(254): 0.005530457943677902\n",
      "Batch 255\n",
      "Loss for Batch(255): 0.0010480298660695553\n",
      "Batch 256\n",
      "Loss for Batch(256): 0.05621014162898064\n",
      "Batch 257\n",
      "Loss for Batch(257): 0.0015607629902660847\n",
      "Batch 258\n",
      "Loss for Batch(258): 0.010636730119585991\n",
      "Batch 259\n",
      "Loss for Batch(259): 0.15290319919586182\n",
      "Batch 260\n",
      "Loss for Batch(260): 0.021414145827293396\n",
      "Batch 261\n",
      "Loss for Batch(261): 0.04501775652170181\n",
      "Batch 262\n",
      "Loss for Batch(262): 0.02510000579059124\n",
      "Batch 263\n",
      "Loss for Batch(263): 0.00189657649025321\n",
      "Batch 264\n",
      "Loss for Batch(264): 0.004210298880934715\n",
      "Batch 265\n",
      "Loss for Batch(265): 0.0006875786930322647\n",
      "Batch 266\n",
      "Loss for Batch(266): 0.011728990823030472\n",
      "Batch 267\n",
      "Loss for Batch(267): 0.04991104453802109\n",
      "Batch 268\n",
      "Loss for Batch(268): 0.06752066314220428\n",
      "Batch 269\n",
      "Loss for Batch(269): 0.0016737707192078233\n",
      "Batch 270\n",
      "Loss for Batch(270): 0.031250420957803726\n",
      "Batch 271\n",
      "Loss for Batch(271): 0.06454603374004364\n",
      "Batch 272\n",
      "Loss for Batch(272): 0.04972387105226517\n",
      "Batch 273\n",
      "Loss for Batch(273): 0.12844546139240265\n",
      "Batch 274\n",
      "Loss for Batch(274): 0.06838482618331909\n",
      "Batch 275\n",
      "Loss for Batch(275): 0.0030802981927990913\n",
      "Batch 276\n",
      "Loss for Batch(276): 0.012218987569212914\n",
      "Batch 277\n",
      "Loss for Batch(277): 0.06291678547859192\n",
      "Batch 278\n",
      "Loss for Batch(278): 0.4261494576931\n",
      "Batch 279\n",
      "Loss for Batch(279): 0.0009060043375939131\n",
      "Batch 280\n",
      "Loss for Batch(280): 0.0004094373434782028\n",
      "Batch 281\n",
      "Loss for Batch(281): 0.0014750913251191378\n",
      "Batch 282\n",
      "Loss for Batch(282): 0.0012044738978147507\n",
      "Batch 283\n",
      "Loss for Batch(283): 0.02551327459514141\n",
      "Batch 284\n",
      "Loss for Batch(284): 0.0002047316957032308\n",
      "Batch 285\n",
      "Loss for Batch(285): 0.0013816499849781394\n",
      "Batch 286\n",
      "Loss for Batch(286): 0.029962044209241867\n",
      "Batch 287\n",
      "Loss for Batch(287): 0.0003516900760587305\n",
      "Batch 288\n",
      "Loss for Batch(288): 0.021775763481855392\n",
      "Batch 289\n",
      "Loss for Batch(289): 0.0001396090374328196\n",
      "Batch 290\n",
      "Loss for Batch(290): 0.011601842939853668\n",
      "Batch 291\n",
      "Loss for Batch(291): 0.012636931613087654\n",
      "Batch 292\n",
      "Loss for Batch(292): 0.00023790565319359303\n",
      "Batch 293\n",
      "Loss for Batch(293): 0.01745053566992283\n",
      "Batch 294\n",
      "Loss for Batch(294): 1.4751942217117175e-05\n",
      "Batch 295\n",
      "Loss for Batch(295): 0.0005139540880918503\n",
      "Batch 296\n",
      "Loss for Batch(296): 0.05071747675538063\n",
      "Batch 297\n",
      "Loss for Batch(297): 0.024529797956347466\n",
      "Batch 298\n",
      "Loss for Batch(298): 0.037152163684368134\n",
      "Batch 299\n",
      "Loss for Batch(299): 0.02578320913016796\n",
      "Batch 300\n",
      "Loss for Batch(300): 0.037985168397426605\n",
      "Batch 301\n",
      "Loss for Batch(301): 0.07401112467050552\n",
      "Batch 302\n",
      "Loss for Batch(302): 0.010130600072443485\n",
      "Batch 303\n",
      "Loss for Batch(303): 0.005834500305354595\n",
      "Batch 304\n",
      "Loss for Batch(304): 0.08043905347585678\n",
      "Batch 305\n",
      "Loss for Batch(305): 0.028936240822076797\n",
      "Batch 306\n",
      "Loss for Batch(306): 0.0064097740687429905\n",
      "Batch 307\n",
      "Loss for Batch(307): 0.12640556693077087\n",
      "Batch 308\n",
      "Loss for Batch(308): 0.02255118452012539\n",
      "Batch 309\n",
      "Loss for Batch(309): 0.027588218450546265\n",
      "Batch 310\n",
      "Loss for Batch(310): 0.005720975808799267\n",
      "Batch 311\n",
      "Loss for Batch(311): 0.03757444769144058\n",
      "Batch 312\n",
      "Loss for Batch(312): 0.3960353136062622\n",
      "Batch 313\n",
      "Loss for Batch(313): 0.36072203516960144\n",
      "Batch 314\n",
      "Loss for Batch(314): 0.013408361934125423\n",
      "Batch 315\n",
      "Loss for Batch(315): 0.4256954491138458\n",
      "Batch 316\n",
      "Loss for Batch(316): 0.004839049652218819\n",
      "Batch 317\n",
      "Loss for Batch(317): 0.010767694562673569\n",
      "Batch 318\n",
      "Loss for Batch(318): 0.03989478945732117\n",
      "Batch 319\n",
      "Loss for Batch(319): 0.0012532175751402974\n",
      "Batch 320\n",
      "Loss for Batch(320): 0.022944249212741852\n",
      "Batch 321\n",
      "Loss for Batch(321): 0.0007588344160467386\n",
      "Batch 322\n",
      "Loss for Batch(322): 0.00494678458198905\n",
      "Batch 323\n",
      "Loss for Batch(323): 0.02890283614397049\n",
      "Batch 324\n",
      "Loss for Batch(324): 0.012811590917408466\n",
      "Batch 325\n",
      "Loss for Batch(325): 0.0009130266262218356\n",
      "Batch 326\n",
      "Loss for Batch(326): 0.0015629336703568697\n",
      "Batch 327\n",
      "Loss for Batch(327): 0.04726633429527283\n",
      "Batch 328\n",
      "Loss for Batch(328): 0.38177698850631714\n",
      "Batch 329\n",
      "Loss for Batch(329): 0.004988421220332384\n",
      "Batch 330\n",
      "Loss for Batch(330): 0.004592733457684517\n",
      "Batch 331\n",
      "Loss for Batch(331): 0.020475316792726517\n",
      "Batch 332\n",
      "Loss for Batch(332): 0.009290636517107487\n",
      "Batch 333\n",
      "Loss for Batch(333): 0.029721472412347794\n",
      "Batch 334\n",
      "Loss for Batch(334): 8.86872221599333e-05\n",
      "Batch 335\n",
      "Loss for Batch(335): 0.13628630340099335\n",
      "Batch 336\n",
      "Loss for Batch(336): 0.4607653319835663\n",
      "Batch 337\n",
      "Loss for Batch(337): 0.03695422410964966\n",
      "Batch 338\n",
      "Loss for Batch(338): 0.020453302189707756\n",
      "Batch 339\n",
      "Loss for Batch(339): 0.0034914046991616488\n",
      "Batch 340\n",
      "Loss for Batch(340): 0.012141724117100239\n",
      "Batch 341\n",
      "Loss for Batch(341): 0.00012484453327488154\n",
      "Batch 342\n",
      "Loss for Batch(342): 0.0022862195037305355\n",
      "Batch 343\n",
      "Loss for Batch(343): 0.017321143299341202\n",
      "Batch 344\n",
      "Loss for Batch(344): 0.008325990289449692\n",
      "Batch 345\n",
      "Loss for Batch(345): 7.664626173209399e-05\n",
      "Batch 346\n",
      "Loss for Batch(346): 0.006082852836698294\n",
      "Batch 347\n",
      "Loss for Batch(347): 0.05868295952677727\n",
      "Batch 348\n",
      "Loss for Batch(348): 0.016676370054483414\n",
      "Batch 349\n",
      "Loss for Batch(349): 0.03177747130393982\n",
      "Batch 350\n",
      "Loss for Batch(350): 0.0010397536680102348\n",
      "Batch 351\n",
      "Loss for Batch(351): 0.06352242082357407\n",
      "Batch 352\n",
      "Loss for Batch(352): 0.01175564993172884\n",
      "Batch 353\n",
      "Loss for Batch(353): 0.006664797198027372\n",
      "Batch 354\n",
      "Loss for Batch(354): 0.04458772391080856\n",
      "Batch 355\n",
      "Loss for Batch(355): 0.01247141882777214\n",
      "Batch 356\n",
      "Loss for Batch(356): 0.003887333208695054\n",
      "Batch 357\n",
      "Loss for Batch(357): 0.00028646306600421667\n",
      "Batch 358\n",
      "Loss for Batch(358): 0.0003730788885150105\n",
      "Batch 359\n",
      "Loss for Batch(359): 0.19441869854927063\n",
      "Batch 360\n",
      "Loss for Batch(360): 0.010115751065313816\n",
      "Batch 361\n",
      "Loss for Batch(361): 0.07600381970405579\n",
      "Batch 362\n",
      "Loss for Batch(362): 0.022628599777817726\n",
      "Batch 363\n",
      "Loss for Batch(363): 0.0003053094260394573\n",
      "Batch 364\n",
      "Loss for Batch(364): 0.0007701407885178924\n",
      "Batch 365\n",
      "Loss for Batch(365): 0.2511734962463379\n",
      "Batch 366\n",
      "Loss for Batch(366): 0.04810650646686554\n",
      "Batch 367\n",
      "Loss for Batch(367): 0.009233079850673676\n",
      "Batch 368\n",
      "Loss for Batch(368): 0.014134030789136887\n",
      "Batch 369\n",
      "Loss for Batch(369): 0.0009211373399011791\n",
      "Batch 370\n",
      "Loss for Batch(370): 0.04688505455851555\n",
      "Batch 371\n",
      "Loss for Batch(371): 0.18142442405223846\n",
      "Batch 372\n",
      "Loss for Batch(372): 0.0027523194439709187\n",
      "Batch 373\n",
      "Loss for Batch(373): 0.10686541348695755\n",
      "Batch 374\n",
      "Loss for Batch(374): 0.020307932049036026\n",
      "Batch 375\n",
      "Loss for Batch(375): 0.00018238640041090548\n",
      "Batch 376\n",
      "Loss for Batch(376): 0.12639454007148743\n",
      "Batch 377\n",
      "Loss for Batch(377): 0.019933467730879784\n",
      "Batch 378\n",
      "Loss for Batch(378): 0.0001744302426232025\n",
      "Batch 379\n",
      "Loss for Batch(379): 0.020543647930026054\n",
      "Batch 380\n",
      "Loss for Batch(380): 0.0011356761679053307\n",
      "Batch 381\n",
      "Loss for Batch(381): 0.012005154974758625\n",
      "Batch 382\n",
      "Loss for Batch(382): 0.002354023512452841\n",
      "Batch 383\n",
      "Loss for Batch(383): 0.03592468053102493\n",
      "Batch 384\n",
      "Loss for Batch(384): 0.09846949577331543\n",
      "Batch 385\n",
      "Loss for Batch(385): 0.008475418202579021\n",
      "Batch 386\n",
      "Loss for Batch(386): 0.27680543065071106\n",
      "Batch 387\n",
      "Loss for Batch(387): 0.3503277599811554\n",
      "Batch 388\n",
      "Loss for Batch(388): 0.0006671864539384842\n",
      "Batch 389\n",
      "Loss for Batch(389): 0.006483078468590975\n",
      "Batch 390\n",
      "Loss for Batch(390): 0.008657798171043396\n",
      "Batch 391\n",
      "Loss for Batch(391): 0.004762390162795782\n",
      "Batch 392\n",
      "Loss for Batch(392): 0.10761792212724686\n",
      "Batch 393\n",
      "Loss for Batch(393): 0.020406417548656464\n",
      "Batch 394\n",
      "Loss for Batch(394): 0.21832223236560822\n",
      "Batch 395\n",
      "Loss for Batch(395): 0.08487352728843689\n",
      "Batch 396\n",
      "Loss for Batch(396): 0.003983630798757076\n",
      "Batch 397\n",
      "Loss for Batch(397): 0.057747580111026764\n",
      "Batch 398\n",
      "Loss for Batch(398): 0.016618767753243446\n",
      "Batch 399\n",
      "Loss for Batch(399): 0.0009140725014731288\n",
      "Batch 400\n",
      "Loss for Batch(400): 0.020229116082191467\n",
      "Batch 401\n",
      "Loss for Batch(401): 0.01449950598180294\n",
      "Batch 402\n",
      "Loss for Batch(402): 0.14014281332492828\n",
      "Batch 403\n",
      "Loss for Batch(403): 0.006319600157439709\n",
      "Batch 404\n",
      "Loss for Batch(404): 0.014370430260896683\n",
      "Batch 405\n",
      "Loss for Batch(405): 0.0024897295515984297\n",
      "Batch 406\n",
      "Loss for Batch(406): 0.027253326028585434\n",
      "Batch 407\n",
      "Loss for Batch(407): 0.01128170732408762\n",
      "Batch 408\n",
      "Loss for Batch(408): 0.0025670374743640423\n",
      "Batch 409\n",
      "Loss for Batch(409): 0.07991687208414078\n",
      "Batch 410\n",
      "Loss for Batch(410): 0.032150041311979294\n",
      "Batch 411\n",
      "Loss for Batch(411): 0.005274495109915733\n",
      "Batch 412\n",
      "Loss for Batch(412): 0.061203066259622574\n",
      "Batch 413\n",
      "Loss for Batch(413): 0.03732777759432793\n",
      "Batch 414\n",
      "Loss for Batch(414): 0.03671056777238846\n",
      "Batch 415\n",
      "Loss for Batch(415): 0.005867993459105492\n",
      "Batch 416\n",
      "Loss for Batch(416): 0.021350853145122528\n",
      "Batch 417\n",
      "Loss for Batch(417): 0.018110303208231926\n",
      "Batch 418\n",
      "Loss for Batch(418): 0.017140541225671768\n",
      "Batch 419\n",
      "Loss for Batch(419): 0.008273012936115265\n",
      "Batch 420\n",
      "Loss for Batch(420): 0.0005402194801717997\n",
      "Batch 421\n",
      "Loss for Batch(421): 0.045696597546339035\n",
      "Batch 422\n",
      "Loss for Batch(422): 0.006497482769191265\n",
      "Batch 423\n",
      "Loss for Batch(423): 0.0025656577199697495\n",
      "Batch 424\n",
      "Loss for Batch(424): 0.01176629401743412\n",
      "Batch 425\n",
      "Loss for Batch(425): 0.005899656563997269\n",
      "Batch 426\n",
      "Loss for Batch(426): 3.150010161334649e-05\n",
      "Batch 427\n",
      "Loss for Batch(427): 0.04428459703922272\n",
      "Batch 428\n",
      "Loss for Batch(428): 0.051772452890872955\n",
      "Batch 429\n",
      "Loss for Batch(429): 0.017052147537469864\n",
      "Batch 430\n",
      "Loss for Batch(430): 0.0014854064211249352\n",
      "Batch 431\n",
      "Loss for Batch(431): 0.00039345838013105094\n",
      "Batch 432\n",
      "Loss for Batch(432): 0.012471242807805538\n",
      "Batch 433\n",
      "Loss for Batch(433): 0.004717929754406214\n",
      "Batch 434\n",
      "Loss for Batch(434): 0.019545795395970345\n",
      "Batch 435\n",
      "Loss for Batch(435): 0.13040809333324432\n",
      "Batch 436\n",
      "Loss for Batch(436): 0.0011946646263822913\n",
      "Batch 437\n",
      "Loss for Batch(437): 0.0038299807347357273\n",
      "Batch 438\n",
      "Loss for Batch(438): 0.13515286147594452\n",
      "Batch 439\n",
      "Loss for Batch(439): 0.23275184631347656\n",
      "Batch 440\n",
      "Loss for Batch(440): 4.6400709834415466e-05\n",
      "Batch 441\n",
      "Loss for Batch(441): 0.002020819578319788\n",
      "Batch 442\n",
      "Loss for Batch(442): 0.03481569513678551\n",
      "Batch 443\n",
      "Loss for Batch(443): 0.21202319860458374\n",
      "Batch 444\n",
      "Loss for Batch(444): 0.029948655515909195\n",
      "Batch 445\n",
      "Loss for Batch(445): 0.027232779189944267\n",
      "Batch 446\n",
      "Loss for Batch(446): 0.0009668560232967138\n",
      "Batch 447\n",
      "Loss for Batch(447): 0.004423144273459911\n",
      "Batch 448\n",
      "Loss for Batch(448): 0.0036297079641371965\n",
      "Batch 449\n",
      "Loss for Batch(449): 0.002431480446830392\n",
      "Batch 450\n",
      "Loss for Batch(450): 0.09270671010017395\n",
      "Batch 451\n",
      "Loss for Batch(451): 0.0008590492652729154\n",
      "Batch 452\n",
      "Loss for Batch(452): 0.07002069801092148\n",
      "Batch 453\n",
      "Loss for Batch(453): 0.051830463111400604\n",
      "Batch 454\n",
      "Loss for Batch(454): 0.14726398885250092\n",
      "Batch 455\n",
      "Loss for Batch(455): 0.028210286051034927\n",
      "Batch 456\n",
      "Loss for Batch(456): 0.00014124785957392305\n",
      "Batch 457\n",
      "Loss for Batch(457): 0.001844707760028541\n",
      "Batch 458\n",
      "Loss for Batch(458): 0.014126129448413849\n",
      "Batch 459\n",
      "Loss for Batch(459): 0.0007193585624918342\n",
      "Batch 460\n",
      "Loss for Batch(460): 0.061792563647031784\n",
      "Batch 461\n",
      "Loss for Batch(461): 0.021995307877659798\n",
      "Batch 462\n",
      "Loss for Batch(462): 0.002003844827413559\n",
      "Batch 463\n",
      "Loss for Batch(463): 0.0425693579018116\n",
      "Batch 464\n",
      "Loss for Batch(464): 0.00029353066929616034\n",
      "Batch 465\n",
      "Loss for Batch(465): 0.0004278184496797621\n",
      "Batch 466\n",
      "Loss for Batch(466): 0.008313503116369247\n",
      "Batch 467\n",
      "Loss for Batch(467): 0.006111400667577982\n",
      "Batch 468\n",
      "Loss for Batch(468): 0.04505601525306702\n",
      "Batch 469\n",
      "Loss for Batch(469): 0.011832225136458874\n",
      "Batch 470\n",
      "Loss for Batch(470): 0.049626369029283524\n",
      "Batch 471\n",
      "Loss for Batch(471): 0.005574596580117941\n",
      "Batch 472\n",
      "Loss for Batch(472): 0.018988581374287605\n",
      "Batch 473\n",
      "Loss for Batch(473): 0.016774693503975868\n",
      "Batch 474\n",
      "Loss for Batch(474): 0.012987500056624413\n",
      "Batch 475\n",
      "Loss for Batch(475): 0.04732564091682434\n",
      "Batch 476\n",
      "Loss for Batch(476): 0.006313422229140997\n",
      "Batch 477\n",
      "Loss for Batch(477): 0.02001144364476204\n",
      "Batch 478\n",
      "Loss for Batch(478): 0.00530576054006815\n",
      "Batch 479\n",
      "Loss for Batch(479): 0.010962740518152714\n",
      "Batch 480\n",
      "Loss for Batch(480): 0.015005241148173809\n",
      "Batch 481\n",
      "Loss for Batch(481): 0.3487485945224762\n",
      "Batch 482\n",
      "Loss for Batch(482): 0.6225361824035645\n",
      "Batch 483\n",
      "Loss for Batch(483): 0.02935977838933468\n",
      "Batch 484\n",
      "Loss for Batch(484): 0.02123541384935379\n",
      "Batch 485\n",
      "Loss for Batch(485): 0.002260287292301655\n",
      "Batch 486\n",
      "Loss for Batch(486): 0.00594643410295248\n",
      "Batch 487\n",
      "Loss for Batch(487): 0.004993785172700882\n",
      "Batch 488\n",
      "Loss for Batch(488): 0.002389304805546999\n",
      "Batch 489\n",
      "Loss for Batch(489): 0.0015313072362914681\n",
      "Batch 490\n",
      "Loss for Batch(490): 0.008793946355581284\n",
      "Batch 491\n",
      "Loss for Batch(491): 0.008552254177629948\n",
      "Batch 492\n",
      "Loss for Batch(492): 0.004863671027123928\n",
      "Batch 493\n",
      "Loss for Batch(493): 0.0026282877661287785\n",
      "Batch 494\n",
      "Loss for Batch(494): 0.026336630806326866\n",
      "Batch 495\n",
      "Loss for Batch(495): 0.12154009193181992\n",
      "Batch 496\n",
      "Loss for Batch(496): 3.865189501084387e-05\n",
      "Batch 497\n",
      "Loss for Batch(497): 0.0011874018236994743\n",
      "Batch 498\n",
      "Loss for Batch(498): 0.09276831895112991\n",
      "Batch 499\n",
      "Loss for Batch(499): 0.002614471362903714\n",
      "Batch 500\n",
      "Loss for Batch(500): 0.0001551275490783155\n",
      "Batch 501\n",
      "Loss for Batch(501): 0.0102479113265872\n",
      "Batch 502\n",
      "Loss for Batch(502): 0.05522901937365532\n",
      "Batch 503\n",
      "Loss for Batch(503): 0.0017594177043065429\n",
      "Batch 504\n",
      "Loss for Batch(504): 0.001243610167875886\n",
      "Batch 505\n",
      "Loss for Batch(505): 0.10359426587820053\n",
      "Batch 506\n",
      "Loss for Batch(506): 0.3149835765361786\n",
      "Batch 507\n",
      "Loss for Batch(507): 0.04877400025725365\n",
      "Batch 508\n",
      "Loss for Batch(508): 0.001169571653008461\n",
      "Batch 509\n",
      "Loss for Batch(509): 0.00014306623779702932\n",
      "Batch 510\n",
      "Loss for Batch(510): 0.0006751609034836292\n",
      "Batch 511\n",
      "Loss for Batch(511): 0.04477756470441818\n",
      "Batch 512\n",
      "Loss for Batch(512): 0.0036977846175432205\n",
      "Batch 513\n",
      "Loss for Batch(513): 0.012286396697163582\n",
      "Batch 514\n",
      "Loss for Batch(514): 0.005728000309318304\n",
      "Batch 515\n",
      "Loss for Batch(515): 0.09651760756969452\n",
      "Batch 516\n",
      "Loss for Batch(516): 0.012892832048237324\n",
      "Batch 517\n",
      "Loss for Batch(517): 0.006830740254372358\n",
      "Batch 518\n",
      "Loss for Batch(518): 0.0010969201102852821\n",
      "Batch 519\n",
      "Loss for Batch(519): 0.0022120142821222544\n",
      "Batch 520\n",
      "Loss for Batch(520): 0.0012970759999006987\n",
      "Batch 521\n",
      "Loss for Batch(521): 0.0023123060818761587\n",
      "Batch 522\n",
      "Loss for Batch(522): 0.00042414735071361065\n",
      "Batch 523\n",
      "Loss for Batch(523): 0.0013051442801952362\n",
      "Batch 524\n",
      "Loss for Batch(524): 0.011736654676496983\n",
      "Batch 525\n",
      "Loss for Batch(525): 0.015361662954092026\n",
      "Batch 526\n",
      "Loss for Batch(526): 0.008214419707655907\n",
      "Batch 527\n",
      "Loss for Batch(527): 0.004446153994649649\n",
      "Batch 528\n",
      "Loss for Batch(528): 0.00388398882932961\n",
      "Batch 529\n",
      "Loss for Batch(529): 0.0467909537255764\n",
      "Batch 530\n",
      "Loss for Batch(530): 0.08124399185180664\n",
      "Batch 531\n",
      "Loss for Batch(531): 0.09021523594856262\n",
      "Batch 532\n",
      "Loss for Batch(532): 0.0010874252766370773\n",
      "Batch 533\n",
      "Loss for Batch(533): 0.020657332614064217\n",
      "Batch 534\n",
      "Loss for Batch(534): 0.0029130661860108376\n",
      "Batch 535\n",
      "Loss for Batch(535): 0.07474608719348907\n",
      "Batch 536\n",
      "Loss for Batch(536): 0.3273160755634308\n",
      "Batch 537\n",
      "Loss for Batch(537): 0.025241566821932793\n",
      "Batch 538\n",
      "Loss for Batch(538): 0.02577064000070095\n",
      "Batch 539\n",
      "Loss for Batch(539): 0.0015513480175286531\n",
      "Batch 540\n",
      "Loss for Batch(540): 0.0013786624185740948\n",
      "Batch 541\n",
      "Loss for Batch(541): 0.03076745755970478\n",
      "Batch 542\n",
      "Loss for Batch(542): 0.011571323499083519\n",
      "Batch 543\n",
      "Loss for Batch(543): 0.0025936835445463657\n",
      "Batch 544\n",
      "Loss for Batch(544): 0.014782648533582687\n",
      "Batch 545\n",
      "Loss for Batch(545): 0.1952340304851532\n",
      "Batch 546\n",
      "Loss for Batch(546): 0.009934370405972004\n",
      "Batch 547\n",
      "Loss for Batch(547): 8.477939263684675e-05\n",
      "Batch 548\n",
      "Loss for Batch(548): 0.031069442629814148\n",
      "Batch 549\n",
      "Loss for Batch(549): 0.001529237488284707\n",
      "Batch 550\n",
      "Loss for Batch(550): 0.018716998398303986\n",
      "Batch 551\n",
      "Loss for Batch(551): 0.02130165323615074\n",
      "Batch 552\n",
      "Loss for Batch(552): 0.010658511891961098\n",
      "Batch 553\n",
      "Loss for Batch(553): 5.247871740721166e-05\n",
      "Batch 554\n",
      "Loss for Batch(554): 0.20473052561283112\n",
      "Batch 555\n",
      "Loss for Batch(555): 0.3409440219402313\n",
      "Batch 556\n",
      "Loss for Batch(556): 0.003509367350488901\n",
      "Batch 557\n",
      "Loss for Batch(557): 0.004335473757237196\n",
      "Batch 558\n",
      "Loss for Batch(558): 0.004360913764685392\n",
      "Batch 559\n",
      "Loss for Batch(559): 0.012908145785331726\n",
      "Batch 560\n",
      "Loss for Batch(560): 0.011736931279301643\n",
      "Batch 561\n",
      "Loss for Batch(561): 0.0010067056864500046\n",
      "Batch 562\n",
      "Loss for Batch(562): 0.02871580421924591\n",
      "Batch 563\n",
      "Loss for Batch(563): 0.002119131153449416\n",
      "Batch 564\n",
      "Loss for Batch(564): 0.0016080958303064108\n",
      "Batch 565\n",
      "Loss for Batch(565): 0.0008418008219450712\n",
      "Batch 566\n",
      "Loss for Batch(566): 0.3757489025592804\n",
      "Batch 567\n",
      "Loss for Batch(567): 0.02469681203365326\n",
      "Batch 568\n",
      "Loss for Batch(568): 0.0974942296743393\n",
      "Batch 569\n",
      "Loss for Batch(569): 0.02252187952399254\n",
      "Batch 570\n",
      "Loss for Batch(570): 0.00042450675391592085\n",
      "Batch 571\n",
      "Loss for Batch(571): 0.00863003358244896\n",
      "Batch 572\n",
      "Loss for Batch(572): 0.0007243516156449914\n",
      "Batch 573\n",
      "Loss for Batch(573): 0.005459990352392197\n",
      "Batch 574\n",
      "Loss for Batch(574): 0.007917807437479496\n",
      "Batch 575\n",
      "Loss for Batch(575): 0.05680876970291138\n",
      "Batch 576\n",
      "Loss for Batch(576): 0.019198168069124222\n",
      "Batch 577\n",
      "Loss for Batch(577): 0.013511648401618004\n",
      "Batch 578\n",
      "Loss for Batch(578): 0.008275854401290417\n",
      "Batch 579\n",
      "Loss for Batch(579): 0.0001329819206148386\n",
      "Batch 580\n",
      "Loss for Batch(580): 0.001314607565291226\n",
      "Batch 581\n",
      "Loss for Batch(581): 0.04690210521221161\n",
      "Batch 582\n",
      "Loss for Batch(582): 0.03255826234817505\n",
      "Batch 583\n",
      "Loss for Batch(583): 0.004219645634293556\n",
      "Batch 584\n",
      "Loss for Batch(584): 0.052626557648181915\n",
      "Batch 585\n",
      "Loss for Batch(585): 0.10282345861196518\n",
      "Batch 586\n",
      "Loss for Batch(586): 0.03474442660808563\n",
      "Batch 587\n",
      "Loss for Batch(587): 0.008168571628630161\n",
      "Batch 588\n",
      "Loss for Batch(588): 0.024713097140192986\n",
      "Batch 589\n",
      "Loss for Batch(589): 0.0005788628477603197\n",
      "Batch 590\n",
      "Loss for Batch(590): 0.0007193804485723376\n",
      "Batch 591\n",
      "Loss for Batch(591): 0.013562362641096115\n",
      "Batch 592\n",
      "Loss for Batch(592): 6.168695108499378e-05\n",
      "Batch 593\n",
      "Loss for Batch(593): 0.08658325672149658\n",
      "Batch 594\n",
      "Loss for Batch(594): 0.02312534675002098\n",
      "Batch 595\n",
      "Loss for Batch(595): 0.0012486103223636746\n",
      "Batch 596\n",
      "Loss for Batch(596): 0.004076236858963966\n",
      "Batch 597\n",
      "Loss for Batch(597): 0.004308672621846199\n",
      "Batch 598\n",
      "Loss for Batch(598): 0.08690115064382553\n",
      "Batch 599\n",
      "Loss for Batch(599): 0.005906383041292429\n",
      "Batch 600\n",
      "Loss for Batch(600): 0.003052930813282728\n",
      "Batch 601\n",
      "Loss for Batch(601): 0.012712957337498665\n",
      "Batch 602\n",
      "Loss for Batch(602): 0.005489359609782696\n",
      "Batch 603\n",
      "Loss for Batch(603): 0.042242951691150665\n",
      "Batch 604\n",
      "Loss for Batch(604): 0.04202965646982193\n",
      "Batch 605\n",
      "Loss for Batch(605): 0.10777008533477783\n",
      "Batch 606\n",
      "Loss for Batch(606): 0.025473464280366898\n",
      "Batch 607\n",
      "Loss for Batch(607): 0.006979968398809433\n",
      "Batch 608\n",
      "Loss for Batch(608): 0.024046102538704872\n",
      "Batch 609\n",
      "Loss for Batch(609): 0.0006746386061422527\n",
      "Batch 610\n",
      "Loss for Batch(610): 0.23183660209178925\n",
      "Batch 611\n",
      "Loss for Batch(611): 0.0012124574277549982\n",
      "Batch 612\n",
      "Loss for Batch(612): 0.04933507740497589\n",
      "Batch 613\n",
      "Loss for Batch(613): 0.013007096946239471\n",
      "Batch 614\n",
      "Loss for Batch(614): 0.011255173943936825\n",
      "Batch 615\n",
      "Loss for Batch(615): 0.04510895162820816\n",
      "Batch 616\n",
      "Loss for Batch(616): 0.06331529468297958\n",
      "Batch 617\n",
      "Loss for Batch(617): 0.004412331152707338\n",
      "Batch 618\n",
      "Loss for Batch(618): 0.0024842508137226105\n",
      "Batch 619\n",
      "Loss for Batch(619): 0.010294905863702297\n",
      "Batch 620\n",
      "Loss for Batch(620): 0.01586087979376316\n",
      "Batch 621\n",
      "Loss for Batch(621): 0.0011335668386891484\n",
      "Batch 622\n",
      "Loss for Batch(622): 0.015122924000024796\n",
      "Batch 623\n",
      "Loss for Batch(623): 0.004138334188610315\n",
      "Batch 624\n",
      "Loss for Batch(624): 0.04425451532006264\n",
      "Batch 625\n",
      "Loss for Batch(625): 0.011058863252401352\n",
      "Batch 626\n",
      "Loss for Batch(626): 0.13758468627929688\n",
      "Batch 627\n",
      "Loss for Batch(627): 0.0011604705359786749\n",
      "Batch 628\n",
      "Loss for Batch(628): 0.06289344280958176\n",
      "Batch 629\n",
      "Loss for Batch(629): 0.003219380509108305\n",
      "Batch 630\n",
      "Loss for Batch(630): 0.0006614846060983837\n",
      "Batch 631\n",
      "Loss for Batch(631): 0.0022847140207886696\n",
      "Batch 632\n",
      "Loss for Batch(632): 0.0007927608676254749\n",
      "Batch 633\n",
      "Loss for Batch(633): 0.041116707026958466\n",
      "Batch 634\n",
      "Loss for Batch(634): 0.07190115004777908\n",
      "Batch 635\n",
      "Loss for Batch(635): 0.047976378351449966\n",
      "Batch 636\n",
      "Loss for Batch(636): 0.030154477804899216\n",
      "Batch 637\n",
      "Loss for Batch(637): 0.060947053134441376\n",
      "Batch 638\n",
      "Loss for Batch(638): 0.0013842553598806262\n",
      "Batch 639\n",
      "Loss for Batch(639): 0.0883348137140274\n",
      "Batch 640\n",
      "Loss for Batch(640): 0.037146177142858505\n",
      "Batch 641\n",
      "Loss for Batch(641): 0.029808612540364265\n",
      "Batch 642\n",
      "Loss for Batch(642): 5.9151319874217734e-05\n",
      "Batch 643\n",
      "Loss for Batch(643): 0.0005009264568798244\n",
      "Batch 644\n",
      "Loss for Batch(644): 0.03859124705195427\n",
      "Batch 645\n",
      "Loss for Batch(645): 0.015401423908770084\n",
      "Batch 646\n",
      "Loss for Batch(646): 0.09658479690551758\n",
      "Batch 647\n",
      "Loss for Batch(647): 0.0020528167951852083\n",
      "Batch 648\n",
      "Loss for Batch(648): 0.019619809463620186\n",
      "Batch 649\n",
      "Loss for Batch(649): 0.00010998506331816316\n",
      "Batch 650\n",
      "Loss for Batch(650): 0.0500011146068573\n",
      "Batch 651\n",
      "Loss for Batch(651): 0.06849288940429688\n",
      "Batch 652\n",
      "Loss for Batch(652): 0.0002761705545708537\n",
      "Batch 653\n",
      "Loss for Batch(653): 0.12461347877979279\n",
      "Batch 654\n",
      "Loss for Batch(654): 0.527737557888031\n",
      "Batch 655\n",
      "Loss for Batch(655): 0.09862930327653885\n",
      "Batch 656\n",
      "Loss for Batch(656): 0.1265416443347931\n",
      "Batch 657\n",
      "Loss for Batch(657): 0.1048775464296341\n",
      "Batch 658\n",
      "Loss for Batch(658): 0.000579996791202575\n",
      "Batch 659\n",
      "Loss for Batch(659): 0.03168971836566925\n",
      "Batch 660\n",
      "Loss for Batch(660): 0.0053077759221196175\n",
      "Batch 661\n",
      "Loss for Batch(661): 0.05527285858988762\n",
      "Batch 662\n",
      "Loss for Batch(662): 0.31571611762046814\n",
      "Batch 663\n",
      "Loss for Batch(663): 0.5464334487915039\n",
      "Batch 664\n",
      "Loss for Batch(664): 0.24498066306114197\n",
      "Batch 665\n",
      "Loss for Batch(665): 0.1244492307305336\n",
      "Batch 666\n",
      "Loss for Batch(666): 0.0017200583824887872\n",
      "Batch 667\n",
      "Loss for Batch(667): 0.00666381698101759\n",
      "Batch 668\n",
      "Loss for Batch(668): 0.010982125997543335\n",
      "Batch 669\n",
      "Loss for Batch(669): 0.25243547558784485\n",
      "Batch 670\n",
      "Loss for Batch(670): 0.019592121243476868\n",
      "Batch 671\n",
      "Loss for Batch(671): 0.3548075556755066\n",
      "Batch 672\n",
      "Loss for Batch(672): 0.11461961269378662\n",
      "Batch 673\n",
      "Loss for Batch(673): 0.012438208796083927\n",
      "Batch 674\n",
      "Loss for Batch(674): 0.017951970919966698\n",
      "Batch 675\n",
      "Loss for Batch(675): 0.023214735090732574\n",
      "Batch 676\n",
      "Loss for Batch(676): 0.0076101431623101234\n",
      "Batch 677\n",
      "Loss for Batch(677): 0.07676403224468231\n",
      "Batch 678\n",
      "Loss for Batch(678): 0.004613309632986784\n",
      "Batch 679\n",
      "Loss for Batch(679): 0.08108039200305939\n",
      "Batch 680\n",
      "Loss for Batch(680): 0.04223969578742981\n",
      "Batch 681\n",
      "Loss for Batch(681): 0.002654941286891699\n",
      "Batch 682\n",
      "Loss for Batch(682): 0.1648663580417633\n",
      "Batch 683\n",
      "Loss for Batch(683): 0.10436812043190002\n",
      "Batch 684\n",
      "Loss for Batch(684): 0.06374547630548477\n",
      "Batch 685\n",
      "Loss for Batch(685): 0.04025639593601227\n",
      "Batch 686\n",
      "Loss for Batch(686): 0.007028084248304367\n",
      "Batch 687\n",
      "Loss for Batch(687): 0.0019101784564554691\n",
      "Batch 688\n",
      "Loss for Batch(688): 0.0031202880199998617\n",
      "Batch 689\n",
      "Loss for Batch(689): 0.0453137569129467\n",
      "Batch 690\n",
      "Loss for Batch(690): 0.025505807250738144\n",
      "Batch 691\n",
      "Loss for Batch(691): 0.021199872717261314\n",
      "Batch 692\n",
      "Loss for Batch(692): 0.005323414225131273\n",
      "Batch 693\n",
      "Loss for Batch(693): 0.016500329598784447\n",
      "Batch 694\n",
      "Loss for Batch(694): 0.000593686883803457\n",
      "Batch 695\n",
      "Loss for Batch(695): 0.0005370730068534613\n",
      "Batch 696\n",
      "Loss for Batch(696): 0.005191226489841938\n",
      "Batch 697\n",
      "Loss for Batch(697): 0.000940251222345978\n",
      "Batch 698\n",
      "Loss for Batch(698): 0.01795370504260063\n",
      "Batch 699\n",
      "Loss for Batch(699): 0.010413139127194881\n",
      "Batch 700\n",
      "Loss for Batch(700): 0.18942022323608398\n",
      "Batch 701\n",
      "Loss for Batch(701): 0.026640096679329872\n",
      "Batch 702\n",
      "Loss for Batch(702): 0.0007381652249023318\n",
      "Batch 703\n",
      "Loss for Batch(703): 0.010617638006806374\n",
      "Batch 704\n",
      "Loss for Batch(704): 0.026807276532053947\n",
      "Batch 705\n",
      "Loss for Batch(705): 0.037747904658317566\n",
      "Batch 706\n",
      "Loss for Batch(706): 0.13537316024303436\n",
      "Batch 707\n",
      "Loss for Batch(707): 0.015825694426894188\n",
      "Batch 708\n",
      "Loss for Batch(708): 0.0025690575130283833\n",
      "Batch 709\n",
      "Loss for Batch(709): 0.05260881781578064\n",
      "Batch 710\n",
      "Loss for Batch(710): 0.00026767016970552504\n",
      "Batch 711\n",
      "Loss for Batch(711): 0.02493322640657425\n",
      "Batch 712\n",
      "Loss for Batch(712): 0.0001469236012781039\n",
      "Batch 713\n",
      "Loss for Batch(713): 0.03353051841259003\n",
      "Batch 714\n",
      "Loss for Batch(714): 0.019737660884857178\n",
      "Batch 715\n",
      "Loss for Batch(715): 0.00810402724891901\n",
      "Batch 716\n",
      "Loss for Batch(716): 0.06404124945402145\n",
      "Batch 717\n",
      "Loss for Batch(717): 0.00928501971065998\n",
      "Batch 718\n",
      "Loss for Batch(718): 0.003927696496248245\n",
      "Batch 719\n",
      "Loss for Batch(719): 0.007351623848080635\n",
      "Batch 720\n",
      "Loss for Batch(720): 0.016999876126646996\n",
      "Batch 721\n",
      "Loss for Batch(721): 0.00864990521222353\n",
      "Batch 722\n",
      "Loss for Batch(722): 0.005176639184355736\n",
      "Batch 723\n",
      "Loss for Batch(723): 0.0029819749761372805\n",
      "Batch 724\n",
      "Loss for Batch(724): 0.026252958923578262\n",
      "Batch 725\n",
      "Loss for Batch(725): 0.0002484261058270931\n",
      "Batch 726\n",
      "Loss for Batch(726): 0.019280722364783287\n",
      "Batch 727\n",
      "Loss for Batch(727): 0.006946071516722441\n",
      "Batch 728\n",
      "Loss for Batch(728): 0.04693436250090599\n",
      "Batch 729\n",
      "Loss for Batch(729): 0.000737059279344976\n",
      "Batch 730\n",
      "Loss for Batch(730): 0.0019871045369654894\n",
      "Batch 731\n",
      "Loss for Batch(731): 0.14974364638328552\n",
      "Batch 732\n",
      "Loss for Batch(732): 0.3444940447807312\n",
      "Batch 733\n",
      "Loss for Batch(733): 0.0009686661069281399\n",
      "Batch 734\n",
      "Loss for Batch(734): 0.035876523703336716\n",
      "Batch 735\n",
      "Loss for Batch(735): 0.010138694196939468\n",
      "Batch 736\n",
      "Loss for Batch(736): 0.016879940405488014\n",
      "Batch 737\n",
      "Loss for Batch(737): 0.003544142469763756\n",
      "Batch 738\n",
      "Loss for Batch(738): 0.1694442182779312\n",
      "Batch 739\n",
      "Loss for Batch(739): 0.011245270259678364\n",
      "Batch 740\n",
      "Loss for Batch(740): 0.017107058316469193\n",
      "Batch 741\n",
      "Loss for Batch(741): 0.017834477126598358\n",
      "Batch 742\n",
      "Loss for Batch(742): 0.06385783851146698\n",
      "Batch 743\n",
      "Loss for Batch(743): 0.0009314679191447794\n",
      "Batch 744\n",
      "Loss for Batch(744): 0.0008067189482972026\n",
      "Batch 745\n",
      "Loss for Batch(745): 0.15663066506385803\n",
      "Batch 746\n",
      "Loss for Batch(746): 0.02560225874185562\n",
      "Batch 747\n",
      "Loss for Batch(747): 0.19869595766067505\n",
      "Batch 748\n",
      "Loss for Batch(748): 0.01699122227728367\n",
      "Batch 749\n",
      "Loss for Batch(749): 0.15477563440799713\n",
      "Batch 750\n",
      "Loss for Batch(750): 0.021624797955155373\n",
      "Batch 751\n",
      "Loss for Batch(751): 0.006721894256770611\n",
      "Batch 752\n",
      "Loss for Batch(752): 1.1883107423782349\n",
      "Batch 753\n",
      "Loss for Batch(753): 0.005292096640914679\n",
      "Avg Loss for 754 Batches0.05080910158297593\n",
      "Epoch(98) Finished\n",
      "**********************************************\n",
      "Avg Test Loss:\n",
      "0.21103683752654487\n",
      "Test Accuracy:\n",
      "0.9189907038512616\n",
      "**********************************************\n",
      "******************Epoch(99):***********************\n",
      "Batch 1\n",
      "Loss for Batch(1): 0.010132082737982273\n",
      "Batch 2\n",
      "Loss for Batch(2): 0.010322343558073044\n",
      "Batch 3\n",
      "Loss for Batch(3): 0.0005385247059166431\n",
      "Batch 4\n",
      "Loss for Batch(4): 0.0011479619424790144\n",
      "Batch 5\n",
      "Loss for Batch(5): 0.028955359011888504\n",
      "Batch 6\n",
      "Loss for Batch(6): 0.01557786762714386\n",
      "Batch 7\n",
      "Loss for Batch(7): 0.00046398883569054306\n",
      "Batch 8\n",
      "Loss for Batch(8): 0.0040903096087276936\n",
      "Batch 9\n",
      "Loss for Batch(9): 0.11726635694503784\n",
      "Batch 10\n",
      "Loss for Batch(10): 0.06798815727233887\n",
      "Batch 11\n",
      "Loss for Batch(11): 0.3954935669898987\n",
      "Batch 12\n",
      "Loss for Batch(12): 4.8455327487317845e-05\n",
      "Batch 13\n",
      "Loss for Batch(13): 0.023077931255102158\n",
      "Batch 14\n",
      "Loss for Batch(14): 0.05977924168109894\n",
      "Batch 15\n",
      "Loss for Batch(15): 0.04524330422282219\n",
      "Batch 16\n",
      "Loss for Batch(16): 0.14844898879528046\n",
      "Batch 17\n",
      "Loss for Batch(17): 0.024109307676553726\n",
      "Batch 18\n",
      "Loss for Batch(18): 0.03429807350039482\n",
      "Batch 19\n",
      "Loss for Batch(19): 0.0012550529791042209\n",
      "Batch 20\n",
      "Loss for Batch(20): 0.019404476508498192\n",
      "Batch 21\n",
      "Loss for Batch(21): 0.06297380477190018\n",
      "Batch 22\n",
      "Loss for Batch(22): 0.008695201016962528\n",
      "Batch 23\n",
      "Loss for Batch(23): 0.10908866673707962\n",
      "Batch 24\n",
      "Loss for Batch(24): 0.0052757179364562035\n",
      "Batch 25\n",
      "Loss for Batch(25): 0.12038975954055786\n",
      "Batch 26\n",
      "Loss for Batch(26): 0.008498036302626133\n",
      "Batch 27\n",
      "Loss for Batch(27): 0.06280312687158585\n",
      "Batch 28\n",
      "Loss for Batch(28): 0.0028626667335629463\n",
      "Batch 29\n",
      "Loss for Batch(29): 0.0034956582821905613\n",
      "Batch 30\n",
      "Loss for Batch(30): 0.000388080719858408\n",
      "Batch 31\n",
      "Loss for Batch(31): 0.00016094668535515666\n",
      "Batch 32\n",
      "Loss for Batch(32): 0.0030493505764752626\n",
      "Batch 33\n",
      "Loss for Batch(33): 0.008996282704174519\n",
      "Batch 34\n",
      "Loss for Batch(34): 0.1445574164390564\n",
      "Batch 35\n",
      "Loss for Batch(35): 0.0028428449295461178\n",
      "Batch 36\n",
      "Loss for Batch(36): 0.03664742782711983\n",
      "Batch 37\n",
      "Loss for Batch(37): 0.0003805689630098641\n",
      "Batch 38\n",
      "Loss for Batch(38): 0.0040183356031775475\n",
      "Batch 39\n",
      "Loss for Batch(39): 0.0008323267684318125\n",
      "Batch 40\n",
      "Loss for Batch(40): 0.11622093617916107\n",
      "Batch 41\n",
      "Loss for Batch(41): 7.330747757805511e-05\n",
      "Batch 42\n",
      "Loss for Batch(42): 0.03667121380567551\n",
      "Batch 43\n",
      "Loss for Batch(43): 0.0060851541347801685\n",
      "Batch 44\n",
      "Loss for Batch(44): 0.11051096022129059\n",
      "Batch 45\n",
      "Loss for Batch(45): 0.004255292005836964\n",
      "Batch 46\n",
      "Loss for Batch(46): 0.0017737367888912559\n",
      "Batch 47\n",
      "Loss for Batch(47): 0.11528120189905167\n",
      "Batch 48\n",
      "Loss for Batch(48): 0.027098724618554115\n",
      "Batch 49\n",
      "Loss for Batch(49): 0.002013136399909854\n",
      "Batch 50\n",
      "Loss for Batch(50): 0.0014910551253706217\n",
      "Batch 51\n",
      "Loss for Batch(51): 0.017577920109033585\n",
      "Batch 52\n",
      "Loss for Batch(52): 0.23479847609996796\n",
      "Batch 53\n",
      "Loss for Batch(53): 0.003656989661976695\n",
      "Batch 54\n",
      "Loss for Batch(54): 0.002861380809918046\n",
      "Batch 55\n",
      "Loss for Batch(55): 0.0029338900931179523\n",
      "Batch 56\n",
      "Loss for Batch(56): 0.005349734332412481\n",
      "Batch 57\n",
      "Loss for Batch(57): 0.014717691577970982\n",
      "Batch 58\n",
      "Loss for Batch(58): 0.0023460625670850277\n",
      "Batch 59\n",
      "Loss for Batch(59): 0.02922222949564457\n",
      "Batch 60\n",
      "Loss for Batch(60): 0.002290189266204834\n",
      "Batch 61\n",
      "Loss for Batch(61): 0.10647214949131012\n",
      "Batch 62\n",
      "Loss for Batch(62): 0.0034574386663734913\n",
      "Batch 63\n",
      "Loss for Batch(63): 0.0871155858039856\n",
      "Batch 64\n",
      "Loss for Batch(64): 0.031134361401200294\n",
      "Batch 65\n",
      "Loss for Batch(65): 0.020945580676198006\n",
      "Batch 66\n",
      "Loss for Batch(66): 0.008355188183486462\n",
      "Batch 67\n",
      "Loss for Batch(67): 0.0070642465725541115\n",
      "Batch 68\n",
      "Loss for Batch(68): 0.0011093690991401672\n",
      "Batch 69\n",
      "Loss for Batch(69): 0.00035392396966926754\n",
      "Batch 70\n",
      "Loss for Batch(70): 0.101758673787117\n",
      "Batch 71\n",
      "Loss for Batch(71): 0.007905103266239166\n",
      "Batch 72\n",
      "Loss for Batch(72): 0.008417757228016853\n",
      "Batch 73\n",
      "Loss for Batch(73): 0.14286959171295166\n",
      "Batch 74\n",
      "Loss for Batch(74): 0.002980654127895832\n",
      "Batch 75\n",
      "Loss for Batch(75): 0.005264327395707369\n",
      "Batch 76\n",
      "Loss for Batch(76): 0.004871537908911705\n",
      "Batch 77\n",
      "Loss for Batch(77): 0.0007433893042616546\n",
      "Batch 78\n",
      "Loss for Batch(78): 0.0013656198279932141\n",
      "Batch 79\n",
      "Loss for Batch(79): 0.053480446338653564\n",
      "Batch 80\n",
      "Loss for Batch(80): 0.004641656298190355\n",
      "Batch 81\n",
      "Loss for Batch(81): 0.005888248793780804\n",
      "Batch 82\n",
      "Loss for Batch(82): 0.003922654781490564\n",
      "Batch 83\n",
      "Loss for Batch(83): 0.07975653558969498\n",
      "Batch 84\n",
      "Loss for Batch(84): 0.06038576364517212\n",
      "Batch 85\n",
      "Loss for Batch(85): 0.1496811807155609\n",
      "Batch 86\n",
      "Loss for Batch(86): 0.014370218850672245\n",
      "Batch 87\n",
      "Loss for Batch(87): 0.00023539952235296369\n",
      "Batch 88\n",
      "Loss for Batch(88): 0.0009259043727070093\n",
      "Batch 89\n",
      "Loss for Batch(89): 0.011927898041903973\n",
      "Batch 90\n",
      "Loss for Batch(90): 0.006323537789285183\n",
      "Batch 91\n",
      "Loss for Batch(91): 0.007213825825601816\n",
      "Batch 92\n",
      "Loss for Batch(92): 0.04910043999552727\n",
      "Batch 93\n",
      "Loss for Batch(93): 0.08477848768234253\n",
      "Batch 94\n",
      "Loss for Batch(94): 0.010447104461491108\n",
      "Batch 95\n",
      "Loss for Batch(95): 0.0017529298784211278\n",
      "Batch 96\n",
      "Loss for Batch(96): 0.06059170886874199\n",
      "Batch 97\n",
      "Loss for Batch(97): 0.0004245650488883257\n",
      "Batch 98\n",
      "Loss for Batch(98): 0.00305366818793118\n",
      "Batch 99\n",
      "Loss for Batch(99): 0.0010083478409796953\n",
      "Batch 100\n",
      "Loss for Batch(100): 0.03090847283601761\n",
      "Batch 101\n",
      "Loss for Batch(101): 0.006963948719203472\n",
      "Batch 102\n",
      "Loss for Batch(102): 0.03009607456624508\n",
      "Batch 103\n",
      "Loss for Batch(103): 0.005311811808496714\n",
      "Batch 104\n",
      "Loss for Batch(104): 0.013635464012622833\n",
      "Batch 105\n",
      "Loss for Batch(105): 0.069239042699337\n",
      "Batch 106\n",
      "Loss for Batch(106): 0.0019374664407223463\n",
      "Batch 107\n",
      "Loss for Batch(107): 0.0011248935479670763\n",
      "Batch 108\n",
      "Loss for Batch(108): 0.0021811085753142834\n",
      "Batch 109\n",
      "Loss for Batch(109): 0.0010994974290952086\n",
      "Batch 110\n",
      "Loss for Batch(110): 0.0023025302216410637\n",
      "Batch 111\n",
      "Loss for Batch(111): 0.029232600703835487\n",
      "Batch 112\n",
      "Loss for Batch(112): 0.0043930415995419025\n",
      "Batch 113\n",
      "Loss for Batch(113): 0.0003325182187836617\n",
      "Batch 114\n",
      "Loss for Batch(114): 0.020364079624414444\n",
      "Batch 115\n",
      "Loss for Batch(115): 0.15544065833091736\n",
      "Batch 116\n",
      "Loss for Batch(116): 0.020505376160144806\n",
      "Batch 117\n",
      "Loss for Batch(117): 0.04464813694357872\n",
      "Batch 118\n",
      "Loss for Batch(118): 0.05214175954461098\n",
      "Batch 119\n",
      "Loss for Batch(119): 0.019387537613511086\n",
      "Batch 120\n",
      "Loss for Batch(120): 0.023902222514152527\n",
      "Batch 121\n",
      "Loss for Batch(121): 0.033970821648836136\n",
      "Batch 122\n",
      "Loss for Batch(122): 0.007733161561191082\n",
      "Batch 123\n",
      "Loss for Batch(123): 0.0003645781835075468\n",
      "Batch 124\n",
      "Loss for Batch(124): 0.024011904373764992\n",
      "Batch 125\n",
      "Loss for Batch(125): 0.0018970672972500324\n",
      "Batch 126\n",
      "Loss for Batch(126): 0.02559651993215084\n",
      "Batch 127\n",
      "Loss for Batch(127): 0.01218452863395214\n",
      "Batch 128\n",
      "Loss for Batch(128): 0.058868907392024994\n",
      "Batch 129\n",
      "Loss for Batch(129): 0.012696654535830021\n",
      "Batch 130\n",
      "Loss for Batch(130): 0.04724626615643501\n",
      "Batch 131\n",
      "Loss for Batch(131): 0.008172383531928062\n",
      "Batch 132\n",
      "Loss for Batch(132): 0.011556609533727169\n",
      "Batch 133\n",
      "Loss for Batch(133): 0.0027878631372004747\n",
      "Batch 134\n",
      "Loss for Batch(134): 0.003097105072811246\n",
      "Batch 135\n",
      "Loss for Batch(135): 0.29798611998558044\n",
      "Batch 136\n",
      "Loss for Batch(136): 0.0009701203089207411\n",
      "Batch 137\n",
      "Loss for Batch(137): 0.15047681331634521\n",
      "Batch 138\n",
      "Loss for Batch(138): 0.06466044485569\n",
      "Batch 139\n",
      "Loss for Batch(139): 0.00861044880002737\n",
      "Batch 140\n",
      "Loss for Batch(140): 0.0122029148042202\n",
      "Batch 141\n",
      "Loss for Batch(141): 0.06511356681585312\n",
      "Batch 142\n",
      "Loss for Batch(142): 0.06721530109643936\n",
      "Batch 143\n",
      "Loss for Batch(143): 0.04789931699633598\n",
      "Batch 144\n",
      "Loss for Batch(144): 0.035750862210989\n",
      "Batch 145\n",
      "Loss for Batch(145): 0.21522453427314758\n",
      "Batch 146\n",
      "Loss for Batch(146): 0.003513591131195426\n",
      "Batch 147\n",
      "Loss for Batch(147): 0.03235268220305443\n",
      "Batch 148\n",
      "Loss for Batch(148): 0.01621844246983528\n",
      "Batch 149\n",
      "Loss for Batch(149): 0.08839672803878784\n",
      "Batch 150\n",
      "Loss for Batch(150): 0.008276999928057194\n",
      "Batch 151\n",
      "Loss for Batch(151): 0.001936666783876717\n",
      "Batch 152\n",
      "Loss for Batch(152): 0.18594086170196533\n",
      "Batch 153\n",
      "Loss for Batch(153): 0.004170247819274664\n",
      "Batch 154\n",
      "Loss for Batch(154): 0.01201336458325386\n",
      "Batch 155\n",
      "Loss for Batch(155): 0.057170480489730835\n",
      "Batch 156\n",
      "Loss for Batch(156): 0.11489589512348175\n",
      "Batch 157\n",
      "Loss for Batch(157): 0.0381622388958931\n",
      "Batch 158\n",
      "Loss for Batch(158): 0.0009616691968403757\n",
      "Batch 159\n",
      "Loss for Batch(159): 0.005551741924136877\n",
      "Batch 160\n",
      "Loss for Batch(160): 0.10188814252614975\n",
      "Batch 161\n",
      "Loss for Batch(161): 0.03571050986647606\n",
      "Batch 162\n",
      "Loss for Batch(162): 0.07005495578050613\n",
      "Batch 163\n",
      "Loss for Batch(163): 0.0180054921656847\n",
      "Batch 164\n",
      "Loss for Batch(164): 0.0005210500676184893\n",
      "Batch 165\n",
      "Loss for Batch(165): 0.017130248248577118\n",
      "Batch 166\n",
      "Loss for Batch(166): 0.003051919396966696\n",
      "Batch 167\n",
      "Loss for Batch(167): 0.10717225074768066\n",
      "Batch 168\n",
      "Loss for Batch(168): 0.008581454865634441\n",
      "Batch 169\n",
      "Loss for Batch(169): 0.002786602359265089\n",
      "Batch 170\n",
      "Loss for Batch(170): 0.00790471863001585\n",
      "Batch 171\n",
      "Loss for Batch(171): 0.10334400832653046\n",
      "Batch 172\n",
      "Loss for Batch(172): 0.0003884132602252066\n",
      "Batch 173\n",
      "Loss for Batch(173): 0.001700019696727395\n",
      "Batch 174\n",
      "Loss for Batch(174): 0.018873464316129684\n",
      "Batch 175\n",
      "Loss for Batch(175): 0.008486559614539146\n",
      "Batch 176\n",
      "Loss for Batch(176): 0.01345596369355917\n",
      "Batch 177\n",
      "Loss for Batch(177): 0.011188235133886337\n",
      "Batch 178\n",
      "Loss for Batch(178): 0.0005156768602319062\n",
      "Batch 179\n",
      "Loss for Batch(179): 0.003110431134700775\n",
      "Batch 180\n",
      "Loss for Batch(180): 0.17112594842910767\n",
      "Batch 181\n",
      "Loss for Batch(181): 0.013086698018014431\n",
      "Batch 182\n",
      "Loss for Batch(182): 0.4935450553894043\n",
      "Batch 183\n",
      "Loss for Batch(183): 0.026199964806437492\n",
      "Batch 184\n",
      "Loss for Batch(184): 0.006695958785712719\n",
      "Batch 185\n",
      "Loss for Batch(185): 0.0056541054509580135\n",
      "Batch 186\n",
      "Loss for Batch(186): 0.1868133395910263\n",
      "Batch 187\n",
      "Loss for Batch(187): 0.004935701377689838\n",
      "Batch 188\n",
      "Loss for Batch(188): 0.0033026260789483786\n",
      "Batch 189\n",
      "Loss for Batch(189): 0.1352188140153885\n",
      "Batch 190\n",
      "Loss for Batch(190): 0.0049228062853217125\n",
      "Batch 191\n",
      "Loss for Batch(191): 0.03130273148417473\n",
      "Batch 192\n",
      "Loss for Batch(192): 0.010546212084591389\n",
      "Batch 193\n",
      "Loss for Batch(193): 0.17172200977802277\n",
      "Batch 194\n",
      "Loss for Batch(194): 0.031342118978500366\n",
      "Batch 195\n",
      "Loss for Batch(195): 0.024312619119882584\n",
      "Batch 196\n",
      "Loss for Batch(196): 0.9787837862968445\n",
      "Batch 197\n",
      "Loss for Batch(197): 0.016968457028269768\n",
      "Batch 198\n",
      "Loss for Batch(198): 0.08152685314416885\n",
      "Batch 199\n",
      "Loss for Batch(199): 0.05076487362384796\n",
      "Batch 200\n",
      "Loss for Batch(200): 0.007070896681398153\n",
      "Batch 201\n",
      "Loss for Batch(201): 0.00891848560422659\n",
      "Batch 202\n",
      "Loss for Batch(202): 0.04085218533873558\n",
      "Batch 203\n",
      "Loss for Batch(203): 0.004510974511504173\n",
      "Batch 204\n",
      "Loss for Batch(204): 0.20836220681667328\n",
      "Batch 205\n",
      "Loss for Batch(205): 0.0009362632408738136\n",
      "Batch 206\n",
      "Loss for Batch(206): 0.12442733347415924\n",
      "Batch 207\n",
      "Loss for Batch(207): 0.023598413914442062\n",
      "Batch 208\n",
      "Loss for Batch(208): 0.34685125946998596\n",
      "Batch 209\n",
      "Loss for Batch(209): 0.01357738021761179\n",
      "Batch 210\n",
      "Loss for Batch(210): 0.4906569719314575\n",
      "Batch 211\n",
      "Loss for Batch(211): 0.06744395941495895\n",
      "Batch 212\n",
      "Loss for Batch(212): 0.00036323952372185886\n",
      "Batch 213\n",
      "Loss for Batch(213): 0.004057451616972685\n",
      "Batch 214\n",
      "Loss for Batch(214): 0.009012085385620594\n",
      "Batch 215\n",
      "Loss for Batch(215): 0.536341667175293\n",
      "Batch 216\n",
      "Loss for Batch(216): 0.013149014674127102\n",
      "Batch 217\n",
      "Loss for Batch(217): 0.00816772598773241\n",
      "Batch 218\n",
      "Loss for Batch(218): 0.007078438997268677\n",
      "Batch 219\n",
      "Loss for Batch(219): 0.0008316495222970843\n",
      "Batch 220\n",
      "Loss for Batch(220): 0.00988277979195118\n",
      "Batch 221\n",
      "Loss for Batch(221): 0.04716724902391434\n",
      "Batch 222\n",
      "Loss for Batch(222): 0.019581254571676254\n",
      "Batch 223\n",
      "Loss for Batch(223): 0.2289266139268875\n",
      "Batch 224\n",
      "Loss for Batch(224): 0.017237938940525055\n",
      "Batch 225\n",
      "Loss for Batch(225): 0.21457462012767792\n",
      "Batch 226\n",
      "Loss for Batch(226): 0.00018905906472355127\n",
      "Batch 227\n",
      "Loss for Batch(227): 5.4027153964852914e-05\n",
      "Batch 228\n",
      "Loss for Batch(228): 0.002388743218034506\n",
      "Batch 229\n",
      "Loss for Batch(229): 0.01369988452643156\n",
      "Batch 230\n",
      "Loss for Batch(230): 0.015983982011675835\n",
      "Batch 231\n",
      "Loss for Batch(231): 0.07547134906053543\n",
      "Batch 232\n",
      "Loss for Batch(232): 0.009920716285705566\n",
      "Batch 233\n",
      "Loss for Batch(233): 0.02645096555352211\n",
      "Batch 234\n",
      "Loss for Batch(234): 0.0007959364447742701\n",
      "Batch 235\n",
      "Loss for Batch(235): 0.00195648823864758\n",
      "Batch 236\n",
      "Loss for Batch(236): 0.004880260676145554\n",
      "Batch 237\n",
      "Loss for Batch(237): 0.014939689077436924\n",
      "Batch 238\n",
      "Loss for Batch(238): 0.03943752869963646\n",
      "Batch 239\n",
      "Loss for Batch(239): 0.09242019802331924\n",
      "Batch 240\n",
      "Loss for Batch(240): 0.0135719645768404\n",
      "Batch 241\n",
      "Loss for Batch(241): 0.0009792206110432744\n",
      "Batch 242\n",
      "Loss for Batch(242): 0.014098145067691803\n",
      "Batch 243\n",
      "Loss for Batch(243): 0.003637502668425441\n",
      "Batch 244\n",
      "Loss for Batch(244): 0.04881753399968147\n",
      "Batch 245\n",
      "Loss for Batch(245): 0.0003256974450778216\n",
      "Batch 246\n",
      "Loss for Batch(246): 0.014720214530825615\n",
      "Batch 247\n",
      "Loss for Batch(247): 0.003180351108312607\n",
      "Batch 248\n",
      "Loss for Batch(248): 0.020546013489365578\n",
      "Batch 249\n",
      "Loss for Batch(249): 0.011006047949194908\n",
      "Batch 250\n",
      "Loss for Batch(250): 0.02181084081530571\n",
      "Batch 251\n",
      "Loss for Batch(251): 0.011481069028377533\n",
      "Batch 252\n",
      "Loss for Batch(252): 0.005382123868912458\n",
      "Batch 253\n",
      "Loss for Batch(253): 0.0005805949913337827\n",
      "Batch 254\n",
      "Loss for Batch(254): 0.007451461628079414\n",
      "Batch 255\n",
      "Loss for Batch(255): 0.0016625047428533435\n",
      "Batch 256\n",
      "Loss for Batch(256): 0.0033648405224084854\n",
      "Batch 257\n",
      "Loss for Batch(257): 0.00407044542953372\n",
      "Batch 258\n",
      "Loss for Batch(258): 0.007453044410794973\n",
      "Batch 259\n",
      "Loss for Batch(259): 0.012439163401722908\n",
      "Batch 260\n",
      "Loss for Batch(260): 0.00043046174687333405\n",
      "Batch 261\n",
      "Loss for Batch(261): 0.012390130199491978\n",
      "Batch 262\n",
      "Loss for Batch(262): 0.021639099344611168\n",
      "Batch 263\n",
      "Loss for Batch(263): 0.030752813443541527\n",
      "Batch 264\n",
      "Loss for Batch(264): 0.012747897766530514\n",
      "Batch 265\n",
      "Loss for Batch(265): 0.30628499388694763\n",
      "Batch 266\n",
      "Loss for Batch(266): 0.9501990675926208\n",
      "Batch 267\n",
      "Loss for Batch(267): 0.07631978392601013\n",
      "Batch 268\n",
      "Loss for Batch(268): 0.000547356263268739\n",
      "Batch 269\n",
      "Loss for Batch(269): 0.008330877870321274\n",
      "Batch 270\n",
      "Loss for Batch(270): 0.033194366842508316\n",
      "Batch 271\n",
      "Loss for Batch(271): 0.001976206200197339\n",
      "Batch 272\n",
      "Loss for Batch(272): 0.024544313549995422\n",
      "Batch 273\n",
      "Loss for Batch(273): 0.007530721370130777\n",
      "Batch 274\n",
      "Loss for Batch(274): 0.025268500670790672\n",
      "Batch 275\n",
      "Loss for Batch(275): 0.016951244324445724\n",
      "Batch 276\n",
      "Loss for Batch(276): 0.0014308391837403178\n",
      "Batch 277\n",
      "Loss for Batch(277): 0.014650586061179638\n",
      "Batch 278\n",
      "Loss for Batch(278): 0.30252113938331604\n",
      "Batch 279\n",
      "Loss for Batch(279): 0.04993915557861328\n",
      "Batch 280\n",
      "Loss for Batch(280): 0.05856970325112343\n",
      "Batch 281\n",
      "Loss for Batch(281): 0.36952313780784607\n",
      "Batch 282\n",
      "Loss for Batch(282): 0.535886824131012\n",
      "Batch 283\n",
      "Loss for Batch(283): 0.47688984870910645\n",
      "Batch 284\n",
      "Loss for Batch(284): 0.03677178919315338\n",
      "Batch 285\n",
      "Loss for Batch(285): 0.0008527152822352946\n",
      "Batch 286\n",
      "Loss for Batch(286): 0.18255774676799774\n",
      "Batch 287\n",
      "Loss for Batch(287): 0.0035092306789010763\n",
      "Batch 288\n",
      "Loss for Batch(288): 0.19104841351509094\n",
      "Batch 289\n",
      "Loss for Batch(289): 0.003197586862370372\n",
      "Batch 290\n",
      "Loss for Batch(290): 0.04535946995019913\n",
      "Batch 291\n",
      "Loss for Batch(291): 0.002102798316627741\n",
      "Batch 292\n",
      "Loss for Batch(292): 0.0019617837388068438\n",
      "Batch 293\n",
      "Loss for Batch(293): 0.005652390420436859\n",
      "Batch 294\n",
      "Loss for Batch(294): 0.002825086936354637\n",
      "Batch 295\n",
      "Loss for Batch(295): 0.029106926172971725\n",
      "Batch 296\n",
      "Loss for Batch(296): 0.04630410298705101\n",
      "Batch 297\n",
      "Loss for Batch(297): 0.006726485211402178\n",
      "Batch 298\n",
      "Loss for Batch(298): 0.017189528793096542\n",
      "Batch 299\n",
      "Loss for Batch(299): 0.04599321633577347\n",
      "Batch 300\n",
      "Loss for Batch(300): 0.07029120624065399\n",
      "Batch 301\n",
      "Loss for Batch(301): 0.09399378299713135\n",
      "Batch 302\n",
      "Loss for Batch(302): 0.01706906408071518\n",
      "Batch 303\n",
      "Loss for Batch(303): 0.0055277240462601185\n",
      "Batch 304\n",
      "Loss for Batch(304): 0.009808912873268127\n",
      "Batch 305\n",
      "Loss for Batch(305): 0.3622477650642395\n",
      "Batch 306\n",
      "Loss for Batch(306): 0.005892961751669645\n",
      "Batch 307\n",
      "Loss for Batch(307): 0.004700354766100645\n",
      "Batch 308\n",
      "Loss for Batch(308): 0.0009552306146360934\n",
      "Batch 309\n",
      "Loss for Batch(309): 0.0017372851725667715\n",
      "Batch 310\n",
      "Loss for Batch(310): 0.08297369629144669\n",
      "Batch 311\n",
      "Loss for Batch(311): 0.019668539986014366\n",
      "Batch 312\n",
      "Loss for Batch(312): 0.14970453083515167\n",
      "Batch 313\n",
      "Loss for Batch(313): 0.010749557055532932\n",
      "Batch 314\n",
      "Loss for Batch(314): 0.02408093586564064\n",
      "Batch 315\n",
      "Loss for Batch(315): 0.10792753100395203\n",
      "Batch 316\n",
      "Loss for Batch(316): 0.0012342359405010939\n",
      "Batch 317\n",
      "Loss for Batch(317): 0.0009131518891081214\n",
      "Batch 318\n",
      "Loss for Batch(318): 0.0010045255767181516\n",
      "Batch 319\n",
      "Loss for Batch(319): 0.00012709613656625152\n",
      "Batch 320\n",
      "Loss for Batch(320): 0.032079897820949554\n",
      "Batch 321\n",
      "Loss for Batch(321): 0.008323246613144875\n",
      "Batch 322\n",
      "Loss for Batch(322): 0.02581675536930561\n",
      "Batch 323\n",
      "Loss for Batch(323): 0.002391972579061985\n",
      "Batch 324\n",
      "Loss for Batch(324): 0.014276964589953423\n",
      "Batch 325\n",
      "Loss for Batch(325): 0.01916351355612278\n",
      "Batch 326\n",
      "Loss for Batch(326): 0.002299271756783128\n",
      "Batch 327\n",
      "Loss for Batch(327): 0.005486022215336561\n",
      "Batch 328\n",
      "Loss for Batch(328): 0.04544194042682648\n",
      "Batch 329\n",
      "Loss for Batch(329): 0.007859226316213608\n",
      "Batch 330\n",
      "Loss for Batch(330): 0.001401951303705573\n",
      "Batch 331\n",
      "Loss for Batch(331): 0.031136760488152504\n",
      "Batch 332\n",
      "Loss for Batch(332): 0.0003843183221761137\n",
      "Batch 333\n",
      "Loss for Batch(333): 0.01004225853830576\n",
      "Batch 334\n",
      "Loss for Batch(334): 6.111912080086768e-05\n",
      "Batch 335\n",
      "Loss for Batch(335): 0.0058364844880998135\n",
      "Batch 336\n",
      "Loss for Batch(336): 0.03255356103181839\n",
      "Batch 337\n",
      "Loss for Batch(337): 0.004794333595782518\n",
      "Batch 338\n",
      "Loss for Batch(338): 0.11080620437860489\n",
      "Batch 339\n",
      "Loss for Batch(339): 0.0012067125644534826\n",
      "Batch 340\n",
      "Loss for Batch(340): 0.018098635599017143\n",
      "Batch 341\n",
      "Loss for Batch(341): 0.024903010576963425\n",
      "Batch 342\n",
      "Loss for Batch(342): 0.002575760241597891\n",
      "Batch 343\n",
      "Loss for Batch(343): 0.013635994866490364\n",
      "Batch 344\n",
      "Loss for Batch(344): 0.00785529799759388\n",
      "Batch 345\n",
      "Loss for Batch(345): 0.11933424323797226\n",
      "Batch 346\n",
      "Loss for Batch(346): 0.010385646484792233\n",
      "Batch 347\n",
      "Loss for Batch(347): 0.0024129103403538465\n",
      "Batch 348\n",
      "Loss for Batch(348): 0.0009178860927931964\n",
      "Batch 349\n",
      "Loss for Batch(349): 0.038459066301584244\n",
      "Batch 350\n",
      "Loss for Batch(350): 0.02374884858727455\n",
      "Batch 351\n",
      "Loss for Batch(351): 0.0014024360571056604\n",
      "Batch 352\n",
      "Loss for Batch(352): 0.0025632595643401146\n",
      "Batch 353\n",
      "Loss for Batch(353): 0.0027068378403782845\n",
      "Batch 354\n",
      "Loss for Batch(354): 0.08983734995126724\n",
      "Batch 355\n",
      "Loss for Batch(355): 0.12653639912605286\n",
      "Batch 356\n",
      "Loss for Batch(356): 0.024833224713802338\n",
      "Batch 357\n",
      "Loss for Batch(357): 0.01693195104598999\n",
      "Batch 358\n",
      "Loss for Batch(358): 0.018418876454234123\n",
      "Batch 359\n",
      "Loss for Batch(359): 0.0028292920906096697\n",
      "Batch 360\n",
      "Loss for Batch(360): 0.0321660116314888\n",
      "Batch 361\n",
      "Loss for Batch(361): 0.10719265788793564\n",
      "Batch 362\n",
      "Loss for Batch(362): 0.00019490618433337659\n",
      "Batch 363\n",
      "Loss for Batch(363): 0.004000777378678322\n",
      "Batch 364\n",
      "Loss for Batch(364): 0.0005215270793996751\n",
      "Batch 365\n",
      "Loss for Batch(365): 0.02968883141875267\n",
      "Batch 366\n",
      "Loss for Batch(366): 0.0011249055387452245\n",
      "Batch 367\n",
      "Loss for Batch(367): 0.0001670924830250442\n",
      "Batch 368\n",
      "Loss for Batch(368): 0.007547562941908836\n",
      "Batch 369\n",
      "Loss for Batch(369): 0.0023137442767620087\n",
      "Batch 370\n",
      "Loss for Batch(370): 0.03705901280045509\n",
      "Batch 371\n",
      "Loss for Batch(371): 0.029876191169023514\n",
      "Batch 372\n",
      "Loss for Batch(372): 1.2069768672517966e-05\n",
      "Batch 373\n",
      "Loss for Batch(373): 0.0015984481433406472\n",
      "Batch 374\n",
      "Loss for Batch(374): 0.01061616837978363\n",
      "Batch 375\n",
      "Loss for Batch(375): 0.02863103337585926\n",
      "Batch 376\n",
      "Loss for Batch(376): 0.02654317207634449\n",
      "Batch 377\n",
      "Loss for Batch(377): 0.007058035582304001\n",
      "Batch 378\n",
      "Loss for Batch(378): 0.0006031570956110954\n",
      "Batch 379\n",
      "Loss for Batch(379): 0.002879741368815303\n",
      "Batch 380\n",
      "Loss for Batch(380): 0.005480811931192875\n",
      "Batch 381\n",
      "Loss for Batch(381): 0.3777821660041809\n",
      "Batch 382\n",
      "Loss for Batch(382): 0.021114187315106392\n",
      "Batch 383\n",
      "Loss for Batch(383): 0.0007348298677243292\n",
      "Batch 384\n",
      "Loss for Batch(384): 0.0035733277909457684\n",
      "Batch 385\n",
      "Loss for Batch(385): 0.2092522382736206\n",
      "Batch 386\n",
      "Loss for Batch(386): 0.08162432909011841\n",
      "Batch 387\n",
      "Loss for Batch(387): 0.0437365397810936\n",
      "Batch 388\n",
      "Loss for Batch(388): 0.02651998959481716\n",
      "Batch 389\n",
      "Loss for Batch(389): 0.16646318137645721\n",
      "Batch 390\n",
      "Loss for Batch(390): 0.006315904203802347\n",
      "Batch 391\n",
      "Loss for Batch(391): 0.05055877938866615\n",
      "Batch 392\n",
      "Loss for Batch(392): 0.039557695388793945\n",
      "Batch 393\n",
      "Loss for Batch(393): 0.09737253189086914\n",
      "Batch 394\n",
      "Loss for Batch(394): 0.028744827955961227\n",
      "Batch 395\n",
      "Loss for Batch(395): 0.10274012386798859\n",
      "Batch 396\n",
      "Loss for Batch(396): 0.019435593858361244\n",
      "Batch 397\n",
      "Loss for Batch(397): 0.0027061335276812315\n",
      "Batch 398\n",
      "Loss for Batch(398): 0.2815042734146118\n",
      "Batch 399\n",
      "Loss for Batch(399): 0.10103722661733627\n",
      "Batch 400\n",
      "Loss for Batch(400): 2.1248588382150047e-05\n",
      "Batch 401\n",
      "Loss for Batch(401): 0.02234700322151184\n",
      "Batch 402\n",
      "Loss for Batch(402): 0.003598880721256137\n",
      "Batch 403\n",
      "Loss for Batch(403): 0.028861993923783302\n",
      "Batch 404\n",
      "Loss for Batch(404): 0.023370228707790375\n",
      "Batch 405\n",
      "Loss for Batch(405): 0.0043799919076263905\n",
      "Batch 406\n",
      "Loss for Batch(406): 0.0009924207115545869\n",
      "Batch 407\n",
      "Loss for Batch(407): 0.00026367674581706524\n",
      "Batch 408\n",
      "Loss for Batch(408): 0.017428796738386154\n",
      "Batch 409\n",
      "Loss for Batch(409): 0.011953981593251228\n",
      "Batch 410\n",
      "Loss for Batch(410): 0.0014239797601476312\n",
      "Batch 411\n",
      "Loss for Batch(411): 0.06027621403336525\n",
      "Batch 412\n",
      "Loss for Batch(412): 0.026918793097138405\n",
      "Batch 413\n",
      "Loss for Batch(413): 0.0029936512000858784\n",
      "Batch 414\n",
      "Loss for Batch(414): 0.0038343702908605337\n",
      "Batch 415\n",
      "Loss for Batch(415): 0.0008327014511451125\n",
      "Batch 416\n",
      "Loss for Batch(416): 0.053291574120521545\n",
      "Batch 417\n",
      "Loss for Batch(417): 0.024566922336816788\n",
      "Batch 418\n",
      "Loss for Batch(418): 0.003974356688559055\n",
      "Batch 419\n",
      "Loss for Batch(419): 0.004763026721775532\n",
      "Batch 420\n",
      "Loss for Batch(420): 0.0005504374275915325\n",
      "Batch 421\n",
      "Loss for Batch(421): 0.03967965766787529\n",
      "Batch 422\n",
      "Loss for Batch(422): 0.00048245498328469694\n",
      "Batch 423\n",
      "Loss for Batch(423): 0.021397747099399567\n",
      "Batch 424\n",
      "Loss for Batch(424): 0.056278493255376816\n",
      "Batch 425\n",
      "Loss for Batch(425): 0.0066558183170855045\n",
      "Batch 426\n",
      "Loss for Batch(426): 0.05584105849266052\n",
      "Batch 427\n",
      "Loss for Batch(427): 0.0016906397650018334\n",
      "Batch 428\n",
      "Loss for Batch(428): 0.0679677277803421\n",
      "Batch 429\n",
      "Loss for Batch(429): 0.011365925893187523\n",
      "Batch 430\n",
      "Loss for Batch(430): 0.15724985301494598\n",
      "Batch 431\n",
      "Loss for Batch(431): 0.2714757025241852\n",
      "Batch 432\n",
      "Loss for Batch(432): 0.020829593762755394\n",
      "Batch 433\n",
      "Loss for Batch(433): 0.002020101062953472\n",
      "Batch 434\n",
      "Loss for Batch(434): 0.00111077178735286\n",
      "Batch 435\n",
      "Loss for Batch(435): 0.014851999469101429\n",
      "Batch 436\n",
      "Loss for Batch(436): 0.024227647110819817\n",
      "Batch 437\n",
      "Loss for Batch(437): 0.0044707139022648335\n",
      "Batch 438\n",
      "Loss for Batch(438): 0.006549640092998743\n",
      "Batch 439\n",
      "Loss for Batch(439): 0.0059631094336509705\n",
      "Batch 440\n",
      "Loss for Batch(440): 0.005660319700837135\n",
      "Batch 441\n",
      "Loss for Batch(441): 0.0002185431367252022\n",
      "Batch 442\n",
      "Loss for Batch(442): 0.008894401602447033\n",
      "Batch 443\n",
      "Loss for Batch(443): 0.002609890652820468\n",
      "Batch 444\n",
      "Loss for Batch(444): 0.1053745448589325\n",
      "Batch 445\n",
      "Loss for Batch(445): 0.0009316971991211176\n",
      "Batch 446\n",
      "Loss for Batch(446): 0.035586319863796234\n",
      "Batch 447\n",
      "Loss for Batch(447): 0.01396284718066454\n",
      "Batch 448\n",
      "Loss for Batch(448): 0.03337053954601288\n",
      "Batch 449\n",
      "Loss for Batch(449): 0.051541537046432495\n",
      "Batch 450\n",
      "Loss for Batch(450): 0.05710023269057274\n",
      "Batch 451\n",
      "Loss for Batch(451): 8.710071415407583e-05\n",
      "Batch 452\n",
      "Loss for Batch(452): 0.07100051641464233\n",
      "Batch 453\n",
      "Loss for Batch(453): 0.0010205826256424189\n",
      "Batch 454\n",
      "Loss for Batch(454): 0.07540342211723328\n",
      "Batch 455\n",
      "Loss for Batch(455): 0.03388242423534393\n",
      "Batch 456\n",
      "Loss for Batch(456): 0.02001176029443741\n",
      "Batch 457\n",
      "Loss for Batch(457): 0.0005326293758116663\n",
      "Batch 458\n",
      "Loss for Batch(458): 0.20718014240264893\n",
      "Batch 459\n",
      "Loss for Batch(459): 0.11852958053350449\n",
      "Batch 460\n",
      "Loss for Batch(460): 0.0643220841884613\n",
      "Batch 461\n",
      "Loss for Batch(461): 0.17543482780456543\n",
      "Batch 462\n",
      "Loss for Batch(462): 0.0019540537614375353\n",
      "Batch 463\n",
      "Loss for Batch(463): 0.0010457065654918551\n",
      "Batch 464\n",
      "Loss for Batch(464): 0.05014088749885559\n",
      "Batch 465\n",
      "Loss for Batch(465): 0.012827777303755283\n",
      "Batch 466\n",
      "Loss for Batch(466): 0.0014574213419109583\n",
      "Batch 467\n",
      "Loss for Batch(467): 0.000443755037849769\n",
      "Batch 468\n",
      "Loss for Batch(468): 0.01292749959975481\n",
      "Batch 469\n",
      "Loss for Batch(469): 0.012529143132269382\n",
      "Batch 470\n",
      "Loss for Batch(470): 0.016984857618808746\n",
      "Batch 471\n",
      "Loss for Batch(471): 0.0009323497069999576\n",
      "Batch 472\n",
      "Loss for Batch(472): 0.19675447046756744\n",
      "Batch 473\n",
      "Loss for Batch(473): 0.09367342293262482\n",
      "Batch 474\n",
      "Loss for Batch(474): 0.0061540668830275536\n",
      "Batch 475\n",
      "Loss for Batch(475): 0.005236223805695772\n",
      "Batch 476\n",
      "Loss for Batch(476): 0.03649869188666344\n",
      "Batch 477\n",
      "Loss for Batch(477): 0.04636404290795326\n",
      "Batch 478\n",
      "Loss for Batch(478): 0.0008321410277858377\n",
      "Batch 479\n",
      "Loss for Batch(479): 0.019750647246837616\n",
      "Batch 480\n",
      "Loss for Batch(480): 0.027961231768131256\n",
      "Batch 481\n",
      "Loss for Batch(481): 0.01311742514371872\n",
      "Batch 482\n",
      "Loss for Batch(482): 0.021283332258462906\n",
      "Batch 483\n",
      "Loss for Batch(483): 0.001134977675974369\n",
      "Batch 484\n",
      "Loss for Batch(484): 0.033999569714069366\n",
      "Batch 485\n",
      "Loss for Batch(485): 0.3229809105396271\n",
      "Batch 486\n",
      "Loss for Batch(486): 0.005805881693959236\n",
      "Batch 487\n",
      "Loss for Batch(487): 0.20288340747356415\n",
      "Batch 488\n",
      "Loss for Batch(488): 0.13781017065048218\n",
      "Batch 489\n",
      "Loss for Batch(489): 0.049830660223960876\n",
      "Batch 490\n",
      "Loss for Batch(490): 0.2457386553287506\n",
      "Batch 491\n",
      "Loss for Batch(491): 0.0062921615317463875\n",
      "Batch 492\n",
      "Loss for Batch(492): 0.008164441213011742\n",
      "Batch 493\n",
      "Loss for Batch(493): 0.003225028747692704\n",
      "Batch 494\n",
      "Loss for Batch(494): 0.018321560695767403\n",
      "Batch 495\n",
      "Loss for Batch(495): 0.0004788046353496611\n",
      "Batch 496\n",
      "Loss for Batch(496): 0.009100186638534069\n",
      "Batch 497\n",
      "Loss for Batch(497): 0.03786490485072136\n",
      "Batch 498\n",
      "Loss for Batch(498): 0.02112661488354206\n",
      "Batch 499\n",
      "Loss for Batch(499): 0.018202291801571846\n",
      "Batch 500\n",
      "Loss for Batch(500): 0.003143652807921171\n",
      "Batch 501\n",
      "Loss for Batch(501): 0.039905812591314316\n",
      "Batch 502\n",
      "Loss for Batch(502): 0.2715272307395935\n",
      "Batch 503\n",
      "Loss for Batch(503): 0.06481613963842392\n",
      "Batch 504\n",
      "Loss for Batch(504): 0.025089465081691742\n",
      "Batch 505\n",
      "Loss for Batch(505): 0.008542319759726524\n",
      "Batch 506\n",
      "Loss for Batch(506): 0.004280015826225281\n",
      "Batch 507\n",
      "Loss for Batch(507): 1.001128911972046\n",
      "Batch 508\n",
      "Loss for Batch(508): 0.010007348842918873\n",
      "Batch 509\n",
      "Loss for Batch(509): 0.0008373683667741716\n",
      "Batch 510\n",
      "Loss for Batch(510): 0.10087980329990387\n",
      "Batch 511\n",
      "Loss for Batch(511): 0.15699554979801178\n",
      "Batch 512\n",
      "Loss for Batch(512): 0.0029754452407360077\n",
      "Batch 513\n",
      "Loss for Batch(513): 0.0005413650069385767\n",
      "Batch 514\n",
      "Loss for Batch(514): 0.001213175361044705\n",
      "Batch 515\n",
      "Loss for Batch(515): 0.041839368641376495\n",
      "Batch 516\n",
      "Loss for Batch(516): 0.014492575079202652\n",
      "Batch 517\n",
      "Loss for Batch(517): 0.001114636892452836\n",
      "Batch 518\n",
      "Loss for Batch(518): 0.05010757967829704\n",
      "Batch 519\n",
      "Loss for Batch(519): 0.08772046118974686\n",
      "Batch 520\n",
      "Loss for Batch(520): 0.017458420246839523\n",
      "Batch 521\n",
      "Loss for Batch(521): 0.006077240686863661\n",
      "Batch 522\n",
      "Loss for Batch(522): 0.009420836344361305\n",
      "Batch 523\n",
      "Loss for Batch(523): 0.0036653815768659115\n",
      "Batch 524\n",
      "Loss for Batch(524): 4.5834152842871845e-05\n",
      "Batch 525\n",
      "Loss for Batch(525): 0.09741079062223434\n",
      "Batch 526\n",
      "Loss for Batch(526): 0.009689809754490852\n",
      "Batch 527\n",
      "Loss for Batch(527): 0.0167483352124691\n",
      "Batch 528\n",
      "Loss for Batch(528): 0.007903102785348892\n",
      "Batch 529\n",
      "Loss for Batch(529): 0.06565625220537186\n",
      "Batch 530\n",
      "Loss for Batch(530): 0.008841721341013908\n",
      "Batch 531\n",
      "Loss for Batch(531): 0.32924920320510864\n",
      "Batch 532\n",
      "Loss for Batch(532): 0.007889492437243462\n",
      "Batch 533\n",
      "Loss for Batch(533): 0.0016721960855647922\n",
      "Batch 534\n",
      "Loss for Batch(534): 0.005063336342573166\n",
      "Batch 535\n",
      "Loss for Batch(535): 0.2054462432861328\n",
      "Batch 536\n",
      "Loss for Batch(536): 0.008161326870322227\n",
      "Batch 537\n",
      "Loss for Batch(537): 0.17071020603179932\n",
      "Batch 538\n",
      "Loss for Batch(538): 0.03165177255868912\n",
      "Batch 539\n",
      "Loss for Batch(539): 0.07641761749982834\n",
      "Batch 540\n",
      "Loss for Batch(540): 0.054476454854011536\n",
      "Batch 541\n",
      "Loss for Batch(541): 0.006362740881741047\n",
      "Batch 542\n",
      "Loss for Batch(542): 0.002034142380580306\n",
      "Batch 543\n",
      "Loss for Batch(543): 0.013340801000595093\n",
      "Batch 544\n",
      "Loss for Batch(544): 0.08638492226600647\n",
      "Batch 545\n",
      "Loss for Batch(545): 0.019105006009340286\n",
      "Batch 546\n",
      "Loss for Batch(546): 0.004916589707136154\n",
      "Batch 547\n",
      "Loss for Batch(547): 0.003583828452974558\n",
      "Batch 548\n",
      "Loss for Batch(548): 0.03192630037665367\n",
      "Batch 549\n",
      "Loss for Batch(549): 0.09857775270938873\n",
      "Batch 550\n",
      "Loss for Batch(550): 7.950540020829067e-05\n",
      "Batch 551\n",
      "Loss for Batch(551): 0.08866167813539505\n",
      "Batch 552\n",
      "Loss for Batch(552): 0.002341888379305601\n",
      "Batch 553\n",
      "Loss for Batch(553): 0.0014477598015218973\n",
      "Batch 554\n",
      "Loss for Batch(554): 0.11577755957841873\n",
      "Batch 555\n",
      "Loss for Batch(555): 0.021870488300919533\n",
      "Batch 556\n",
      "Loss for Batch(556): 0.028309086337685585\n",
      "Batch 557\n",
      "Loss for Batch(557): 0.010628115385770798\n",
      "Batch 558\n",
      "Loss for Batch(558): 0.05408623814582825\n",
      "Batch 559\n",
      "Loss for Batch(559): 0.08783982694149017\n",
      "Batch 560\n",
      "Loss for Batch(560): 0.12363691627979279\n",
      "Batch 561\n",
      "Loss for Batch(561): 0.007846767082810402\n",
      "Batch 562\n",
      "Loss for Batch(562): 0.031428731977939606\n",
      "Batch 563\n",
      "Loss for Batch(563): 0.0008238928858190775\n",
      "Batch 564\n",
      "Loss for Batch(564): 0.0015352334594354033\n",
      "Batch 565\n",
      "Loss for Batch(565): 0.011927427724003792\n",
      "Batch 566\n",
      "Loss for Batch(566): 0.011298849247395992\n",
      "Batch 567\n",
      "Loss for Batch(567): 0.49954652786254883\n",
      "Batch 568\n",
      "Loss for Batch(568): 0.3961615264415741\n",
      "Batch 569\n",
      "Loss for Batch(569): 0.0019474875880405307\n",
      "Batch 570\n",
      "Loss for Batch(570): 0.0035084038972854614\n",
      "Batch 571\n",
      "Loss for Batch(571): 0.0008598279673606157\n",
      "Batch 572\n",
      "Loss for Batch(572): 0.0011944944271817803\n",
      "Batch 573\n",
      "Loss for Batch(573): 0.0033460466656833887\n",
      "Batch 574\n",
      "Loss for Batch(574): 0.0018843482248485088\n",
      "Batch 575\n",
      "Loss for Batch(575): 0.01026034727692604\n",
      "Batch 576\n",
      "Loss for Batch(576): 0.017886945977807045\n",
      "Batch 577\n",
      "Loss for Batch(577): 0.006332386750727892\n",
      "Batch 578\n",
      "Loss for Batch(578): 0.09266788512468338\n",
      "Batch 579\n",
      "Loss for Batch(579): 0.002833434147760272\n",
      "Batch 580\n",
      "Loss for Batch(580): 0.6211665272712708\n",
      "Batch 581\n",
      "Loss for Batch(581): 0.03702821210026741\n",
      "Batch 582\n",
      "Loss for Batch(582): 0.0009071412496268749\n",
      "Batch 583\n",
      "Loss for Batch(583): 0.1363825649023056\n",
      "Batch 584\n",
      "Loss for Batch(584): 0.006337405648082495\n",
      "Batch 585\n",
      "Loss for Batch(585): 0.000834978127386421\n",
      "Batch 586\n",
      "Loss for Batch(586): 0.011582178995013237\n",
      "Batch 587\n",
      "Loss for Batch(587): 0.005093168932944536\n",
      "Batch 588\n",
      "Loss for Batch(588): 0.0006235616747289896\n",
      "Batch 589\n",
      "Loss for Batch(589): 0.005332785192877054\n",
      "Batch 590\n",
      "Loss for Batch(590): 0.004013723693788052\n",
      "Batch 591\n",
      "Loss for Batch(591): 0.009082789532840252\n",
      "Batch 592\n",
      "Loss for Batch(592): 0.01745387353003025\n",
      "Batch 593\n",
      "Loss for Batch(593): 0.021574996411800385\n",
      "Batch 594\n",
      "Loss for Batch(594): 0.0022868935484439135\n",
      "Batch 595\n",
      "Loss for Batch(595): 0.0021659003105014563\n",
      "Batch 596\n",
      "Loss for Batch(596): 0.07587964832782745\n",
      "Batch 597\n",
      "Loss for Batch(597): 0.00038453881279565394\n",
      "Batch 598\n",
      "Loss for Batch(598): 0.07213716208934784\n",
      "Batch 599\n",
      "Loss for Batch(599): 0.08413102477788925\n",
      "Batch 600\n",
      "Loss for Batch(600): 0.07987786084413528\n",
      "Batch 601\n",
      "Loss for Batch(601): 0.0012281951494514942\n",
      "Batch 602\n",
      "Loss for Batch(602): 0.02031714841723442\n",
      "Batch 603\n",
      "Loss for Batch(603): 0.0031821047887206078\n",
      "Batch 604\n",
      "Loss for Batch(604): 0.01944684609770775\n",
      "Batch 605\n",
      "Loss for Batch(605): 0.009056376293301582\n",
      "Batch 606\n",
      "Loss for Batch(606): 0.0013240479165688157\n",
      "Batch 607\n",
      "Loss for Batch(607): 0.09338489174842834\n",
      "Batch 608\n",
      "Loss for Batch(608): 0.007117383647710085\n",
      "Batch 609\n",
      "Loss for Batch(609): 0.03231470286846161\n",
      "Batch 610\n",
      "Loss for Batch(610): 0.0034608016721904278\n",
      "Batch 611\n",
      "Loss for Batch(611): 0.0044456832110881805\n",
      "Batch 612\n",
      "Loss for Batch(612): 0.22531931102275848\n",
      "Batch 613\n",
      "Loss for Batch(613): 0.06808830052614212\n",
      "Batch 614\n",
      "Loss for Batch(614): 0.04632004350423813\n",
      "Batch 615\n",
      "Loss for Batch(615): 0.0005797365447506309\n",
      "Batch 616\n",
      "Loss for Batch(616): 0.01872348040342331\n",
      "Batch 617\n",
      "Loss for Batch(617): 0.008744453079998493\n",
      "Batch 618\n",
      "Loss for Batch(618): 0.021687643602490425\n",
      "Batch 619\n",
      "Loss for Batch(619): 0.04421049728989601\n",
      "Batch 620\n",
      "Loss for Batch(620): 0.0003386709140613675\n",
      "Batch 621\n",
      "Loss for Batch(621): 0.00466838339343667\n",
      "Batch 622\n",
      "Loss for Batch(622): 0.0004235285159666091\n",
      "Batch 623\n",
      "Loss for Batch(623): 0.0025651000905781984\n",
      "Batch 624\n",
      "Loss for Batch(624): 0.009776807390153408\n",
      "Batch 625\n",
      "Loss for Batch(625): 0.01601935736835003\n",
      "Batch 626\n",
      "Loss for Batch(626): 0.03948904946446419\n",
      "Batch 627\n",
      "Loss for Batch(627): 4.744324178318493e-05\n",
      "Batch 628\n",
      "Loss for Batch(628): 0.01689952425658703\n",
      "Batch 629\n",
      "Loss for Batch(629): 0.007141066249459982\n",
      "Batch 630\n",
      "Loss for Batch(630): 0.08686563372612\n",
      "Batch 631\n",
      "Loss for Batch(631): 9.258668433176354e-05\n",
      "Batch 632\n",
      "Loss for Batch(632): 0.10647900402545929\n",
      "Batch 633\n",
      "Loss for Batch(633): 0.03820038586854935\n",
      "Batch 634\n",
      "Loss for Batch(634): 0.147273987531662\n",
      "Batch 635\n",
      "Loss for Batch(635): 0.0021551535464823246\n",
      "Batch 636\n",
      "Loss for Batch(636): 0.0004847976379096508\n",
      "Batch 637\n",
      "Loss for Batch(637): 0.0018166489899158478\n",
      "Batch 638\n",
      "Loss for Batch(638): 0.009612062014639378\n",
      "Batch 639\n",
      "Loss for Batch(639): 0.4346601068973541\n",
      "Batch 640\n",
      "Loss for Batch(640): 0.10218632221221924\n",
      "Batch 641\n",
      "Loss for Batch(641): 0.0226163100451231\n",
      "Batch 642\n",
      "Loss for Batch(642): 0.07260727137327194\n",
      "Batch 643\n",
      "Loss for Batch(643): 0.2387993186712265\n",
      "Batch 644\n",
      "Loss for Batch(644): 0.009766705334186554\n",
      "Batch 645\n",
      "Loss for Batch(645): 0.08024515956640244\n",
      "Batch 646\n",
      "Loss for Batch(646): 0.013163683004677296\n",
      "Batch 647\n",
      "Loss for Batch(647): 0.06578980386257172\n",
      "Batch 648\n",
      "Loss for Batch(648): 0.011020820587873459\n",
      "Batch 649\n",
      "Loss for Batch(649): 0.15968263149261475\n",
      "Batch 650\n",
      "Loss for Batch(650): 0.004302105400711298\n",
      "Batch 651\n",
      "Loss for Batch(651): 0.004371450282633305\n",
      "Batch 652\n",
      "Loss for Batch(652): 0.09123456478118896\n",
      "Batch 653\n",
      "Loss for Batch(653): 0.07566520571708679\n",
      "Batch 654\n",
      "Loss for Batch(654): 0.05991894379258156\n",
      "Batch 655\n",
      "Loss for Batch(655): 0.005410280078649521\n",
      "Batch 656\n",
      "Loss for Batch(656): 0.07927308231592178\n",
      "Batch 657\n",
      "Loss for Batch(657): 0.012457070872187614\n",
      "Batch 658\n",
      "Loss for Batch(658): 0.0016423625638708472\n",
      "Batch 659\n",
      "Loss for Batch(659): 0.021305909380316734\n",
      "Batch 660\n",
      "Loss for Batch(660): 0.005819584242999554\n",
      "Batch 661\n",
      "Loss for Batch(661): 0.08896595239639282\n",
      "Batch 662\n",
      "Loss for Batch(662): 0.041067011654376984\n",
      "Batch 663\n",
      "Loss for Batch(663): 0.00163624482229352\n",
      "Batch 664\n",
      "Loss for Batch(664): 0.29309892654418945\n",
      "Batch 665\n",
      "Loss for Batch(665): 0.00042332004522904754\n",
      "Batch 666\n",
      "Loss for Batch(666): 0.4205957055091858\n",
      "Batch 667\n",
      "Loss for Batch(667): 0.11367020010948181\n",
      "Batch 668\n",
      "Loss for Batch(668): 0.05935546010732651\n",
      "Batch 669\n",
      "Loss for Batch(669): 0.005571984685957432\n",
      "Batch 670\n",
      "Loss for Batch(670): 0.00018969428492709994\n",
      "Batch 671\n",
      "Loss for Batch(671): 0.004312872886657715\n",
      "Batch 672\n",
      "Loss for Batch(672): 0.0001829625543905422\n",
      "Batch 673\n",
      "Loss for Batch(673): 0.03025856614112854\n",
      "Batch 674\n",
      "Loss for Batch(674): 0.06299595534801483\n",
      "Batch 675\n",
      "Loss for Batch(675): 0.05735781416296959\n",
      "Batch 676\n",
      "Loss for Batch(676): 0.014353085309267044\n",
      "Batch 677\n",
      "Loss for Batch(677): 0.005835030227899551\n",
      "Batch 678\n",
      "Loss for Batch(678): 0.019266126677393913\n",
      "Batch 679\n",
      "Loss for Batch(679): 0.09299851208925247\n",
      "Batch 680\n",
      "Loss for Batch(680): 0.06541749835014343\n",
      "Batch 681\n",
      "Loss for Batch(681): 0.07333433628082275\n",
      "Batch 682\n",
      "Loss for Batch(682): 0.020817290991544724\n",
      "Batch 683\n",
      "Loss for Batch(683): 0.0019088309491053224\n",
      "Batch 684\n",
      "Loss for Batch(684): 0.057128626853227615\n",
      "Batch 685\n",
      "Loss for Batch(685): 0.08443207293748856\n",
      "Batch 686\n",
      "Loss for Batch(686): 0.1199323758482933\n",
      "Batch 687\n",
      "Loss for Batch(687): 0.10618329793214798\n",
      "Batch 688\n",
      "Loss for Batch(688): 0.000320704304613173\n",
      "Batch 689\n",
      "Loss for Batch(689): 0.006920179817825556\n",
      "Batch 690\n",
      "Loss for Batch(690): 0.030005166307091713\n",
      "Batch 691\n",
      "Loss for Batch(691): 0.00808626227080822\n",
      "Batch 692\n",
      "Loss for Batch(692): 0.007678331341594458\n",
      "Batch 693\n",
      "Loss for Batch(693): 0.02638566680252552\n",
      "Batch 694\n",
      "Loss for Batch(694): 0.002747358987107873\n",
      "Batch 695\n",
      "Loss for Batch(695): 0.010714239440858364\n",
      "Batch 696\n",
      "Loss for Batch(696): 0.0036384277045726776\n",
      "Batch 697\n",
      "Loss for Batch(697): 0.00037355057429522276\n",
      "Batch 698\n",
      "Loss for Batch(698): 0.0007738708518445492\n",
      "Batch 699\n",
      "Loss for Batch(699): 0.002602323889732361\n",
      "Batch 700\n",
      "Loss for Batch(700): 0.013476966880261898\n",
      "Batch 701\n",
      "Loss for Batch(701): 0.01413766946643591\n",
      "Batch 702\n",
      "Loss for Batch(702): 0.0015671943547204137\n",
      "Batch 703\n",
      "Loss for Batch(703): 0.0026848497800529003\n",
      "Batch 704\n",
      "Loss for Batch(704): 0.23331592977046967\n",
      "Batch 705\n",
      "Loss for Batch(705): 0.002374577336013317\n",
      "Batch 706\n",
      "Loss for Batch(706): 0.0849415510892868\n",
      "Batch 707\n",
      "Loss for Batch(707): 0.0008577954140491784\n",
      "Batch 708\n",
      "Loss for Batch(708): 0.00365642667748034\n",
      "Batch 709\n",
      "Loss for Batch(709): 0.20218691229820251\n",
      "Batch 710\n",
      "Loss for Batch(710): 0.010592055507004261\n",
      "Batch 711\n",
      "Loss for Batch(711): 0.014520862139761448\n",
      "Batch 712\n",
      "Loss for Batch(712): 0.0070096757262945175\n",
      "Batch 713\n",
      "Loss for Batch(713): 0.002384864492341876\n",
      "Batch 714\n",
      "Loss for Batch(714): 0.017594879493117332\n",
      "Batch 715\n",
      "Loss for Batch(715): 0.0051041338592767715\n",
      "Batch 716\n",
      "Loss for Batch(716): 0.015088140964508057\n",
      "Batch 717\n",
      "Loss for Batch(717): 7.968534919200465e-05\n",
      "Batch 718\n",
      "Loss for Batch(718): 0.005733354948461056\n",
      "Batch 719\n",
      "Loss for Batch(719): 0.16193167865276337\n",
      "Batch 720\n",
      "Loss for Batch(720): 0.008469233289361\n",
      "Batch 721\n",
      "Loss for Batch(721): 0.0019362826133146882\n",
      "Batch 722\n",
      "Loss for Batch(722): 0.003751582931727171\n",
      "Batch 723\n",
      "Loss for Batch(723): 0.06617811322212219\n",
      "Batch 724\n",
      "Loss for Batch(724): 0.015836993232369423\n",
      "Batch 725\n",
      "Loss for Batch(725): 0.016094211488962173\n",
      "Batch 726\n",
      "Loss for Batch(726): 0.029517412185668945\n",
      "Batch 727\n",
      "Loss for Batch(727): 0.03138922154903412\n",
      "Batch 728\n",
      "Loss for Batch(728): 0.010480999946594238\n",
      "Batch 729\n",
      "Loss for Batch(729): 0.2970978319644928\n",
      "Batch 730\n",
      "Loss for Batch(730): 0.13237173855304718\n",
      "Batch 731\n",
      "Loss for Batch(731): 0.005995814222842455\n",
      "Batch 732\n",
      "Loss for Batch(732): 0.010327523574233055\n",
      "Batch 733\n",
      "Loss for Batch(733): 0.003218444064259529\n",
      "Batch 734\n",
      "Loss for Batch(734): 0.01877507008612156\n",
      "Batch 735\n",
      "Loss for Batch(735): 0.004590955562889576\n",
      "Batch 736\n",
      "Loss for Batch(736): 0.12050318717956543\n",
      "Batch 737\n",
      "Loss for Batch(737): 0.003147431882098317\n",
      "Batch 738\n",
      "Loss for Batch(738): 0.016976241022348404\n",
      "Batch 739\n",
      "Loss for Batch(739): 0.002974255010485649\n",
      "Batch 740\n",
      "Loss for Batch(740): 0.04985570162534714\n",
      "Batch 741\n",
      "Loss for Batch(741): 0.007719140965491533\n",
      "Batch 742\n",
      "Loss for Batch(742): 0.039478473365306854\n",
      "Batch 743\n",
      "Loss for Batch(743): 0.004614134319126606\n",
      "Batch 744\n",
      "Loss for Batch(744): 0.02653600461781025\n",
      "Batch 745\n",
      "Loss for Batch(745): 0.005800435319542885\n",
      "Batch 746\n",
      "Loss for Batch(746): 0.004211100749671459\n",
      "Batch 747\n",
      "Loss for Batch(747): 0.018876422196626663\n",
      "Batch 748\n",
      "Loss for Batch(748): 0.01011515874415636\n",
      "Batch 749\n",
      "Loss for Batch(749): 0.0015497831627726555\n",
      "Batch 750\n",
      "Loss for Batch(750): 1.168238122772891e-05\n",
      "Batch 751\n",
      "Loss for Batch(751): 0.15909725427627563\n",
      "Batch 752\n",
      "Loss for Batch(752): 0.0023077726364135742\n",
      "Batch 753\n",
      "Loss for Batch(753): 0.3603445589542389\n",
      "Avg Loss for 754 Batches0.04843837188217009\n",
      "Epoch(99) Finished\n",
      "**********************************************\n",
      "Avg Test Loss:\n",
      "0.2978361553715336\n",
      "Test Accuracy:\n",
      "0.9176626826029216\n",
      "**********************************************\n",
      "******************Epoch(100):***********************\n",
      "Batch 1\n",
      "Loss for Batch(1): 0.00624114740639925\n",
      "Batch 2\n",
      "Loss for Batch(2): 0.000560244545340538\n",
      "Batch 3\n",
      "Loss for Batch(3): 0.28795820474624634\n",
      "Batch 4\n",
      "Loss for Batch(4): 0.018995342776179314\n",
      "Batch 5\n",
      "Loss for Batch(5): 0.019597290083765984\n",
      "Batch 6\n",
      "Loss for Batch(6): 0.00063354178564623\n",
      "Batch 7\n",
      "Loss for Batch(7): 0.03196961432695389\n",
      "Batch 8\n",
      "Loss for Batch(8): 0.03766914829611778\n",
      "Batch 9\n",
      "Loss for Batch(9): 0.0484229139983654\n",
      "Batch 10\n",
      "Loss for Batch(10): 0.0100217554718256\n",
      "Batch 11\n",
      "Loss for Batch(11): 0.028353404253721237\n",
      "Batch 12\n",
      "Loss for Batch(12): 0.04581311345100403\n",
      "Batch 13\n",
      "Loss for Batch(13): 0.015568127855658531\n",
      "Batch 14\n",
      "Loss for Batch(14): 0.11240289360284805\n",
      "Batch 15\n",
      "Loss for Batch(15): 0.0003131142584607005\n",
      "Batch 16\n",
      "Loss for Batch(16): 0.006054762285202742\n",
      "Batch 17\n",
      "Loss for Batch(17): 0.002362688072025776\n",
      "Batch 18\n",
      "Loss for Batch(18): 0.007698213681578636\n",
      "Batch 19\n",
      "Loss for Batch(19): 0.026389040052890778\n",
      "Batch 20\n",
      "Loss for Batch(20): 0.009714741259813309\n",
      "Batch 21\n",
      "Loss for Batch(21): 0.07225768268108368\n",
      "Batch 22\n",
      "Loss for Batch(22): 0.0020994211081415415\n",
      "Batch 23\n",
      "Loss for Batch(23): 0.009748900309205055\n",
      "Batch 24\n",
      "Loss for Batch(24): 0.012261968106031418\n",
      "Batch 25\n",
      "Loss for Batch(25): 0.009407233446836472\n",
      "Batch 26\n",
      "Loss for Batch(26): 0.00018863193690776825\n",
      "Batch 27\n",
      "Loss for Batch(27): 0.031953584402799606\n",
      "Batch 28\n",
      "Loss for Batch(28): 0.05471089854836464\n",
      "Batch 29\n",
      "Loss for Batch(29): 0.024855349212884903\n",
      "Batch 30\n",
      "Loss for Batch(30): 0.015134013257920742\n",
      "Batch 31\n",
      "Loss for Batch(31): 0.001241358695551753\n",
      "Batch 32\n",
      "Loss for Batch(32): 0.0018608879763633013\n",
      "Batch 33\n",
      "Loss for Batch(33): 0.015651587396860123\n",
      "Batch 34\n",
      "Loss for Batch(34): 0.013429359532892704\n",
      "Batch 35\n",
      "Loss for Batch(35): 0.06001368910074234\n",
      "Batch 36\n",
      "Loss for Batch(36): 0.010320187546312809\n",
      "Batch 37\n",
      "Loss for Batch(37): 0.0002010515017900616\n",
      "Batch 38\n",
      "Loss for Batch(38): 0.004691666923463345\n",
      "Batch 39\n",
      "Loss for Batch(39): 0.0017579233972355723\n",
      "Batch 40\n",
      "Loss for Batch(40): 0.013259981758892536\n",
      "Batch 41\n",
      "Loss for Batch(41): 0.0036752510350197554\n",
      "Batch 42\n",
      "Loss for Batch(42): 0.013533659279346466\n",
      "Batch 43\n",
      "Loss for Batch(43): 0.02355286106467247\n",
      "Batch 44\n",
      "Loss for Batch(44): 0.048748619854450226\n",
      "Batch 45\n",
      "Loss for Batch(45): 0.2912808656692505\n",
      "Batch 46\n",
      "Loss for Batch(46): 0.0008493511704728007\n",
      "Batch 47\n",
      "Loss for Batch(47): 0.04462338238954544\n",
      "Batch 48\n",
      "Loss for Batch(48): 0.2106633186340332\n",
      "Batch 49\n",
      "Loss for Batch(49): 0.02295994758605957\n",
      "Batch 50\n",
      "Loss for Batch(50): 0.005605549085885286\n",
      "Batch 51\n",
      "Loss for Batch(51): 0.044141560792922974\n",
      "Batch 52\n",
      "Loss for Batch(52): 0.006680176593363285\n",
      "Batch 53\n",
      "Loss for Batch(53): 0.006275101564824581\n",
      "Batch 54\n",
      "Loss for Batch(54): 0.0014216587878763676\n",
      "Batch 55\n",
      "Loss for Batch(55): 0.003063224721699953\n",
      "Batch 56\n",
      "Loss for Batch(56): 0.05544407293200493\n",
      "Batch 57\n",
      "Loss for Batch(57): 0.0026447968557476997\n",
      "Batch 58\n",
      "Loss for Batch(58): 0.0012543147895485163\n",
      "Batch 59\n",
      "Loss for Batch(59): 0.0003017722337972373\n",
      "Batch 60\n",
      "Loss for Batch(60): 0.005092432722449303\n",
      "Batch 61\n",
      "Loss for Batch(61): 0.010355882346630096\n",
      "Batch 62\n",
      "Loss for Batch(62): 0.3053223490715027\n",
      "Batch 63\n",
      "Loss for Batch(63): 0.010731315240263939\n",
      "Batch 64\n",
      "Loss for Batch(64): 0.10591040551662445\n",
      "Batch 65\n",
      "Loss for Batch(65): 0.0016749217174947262\n",
      "Batch 66\n",
      "Loss for Batch(66): 0.021637193858623505\n",
      "Batch 67\n",
      "Loss for Batch(67): 0.02561923675239086\n",
      "Batch 68\n",
      "Loss for Batch(68): 0.012202303856611252\n",
      "Batch 69\n",
      "Loss for Batch(69): 0.01238064281642437\n",
      "Batch 70\n",
      "Loss for Batch(70): 0.13331520557403564\n",
      "Batch 71\n",
      "Loss for Batch(71): 0.012036810629069805\n",
      "Batch 72\n",
      "Loss for Batch(72): 0.007213626988232136\n",
      "Batch 73\n",
      "Loss for Batch(73): 0.09729118645191193\n",
      "Batch 74\n",
      "Loss for Batch(74): 0.1820044219493866\n",
      "Batch 75\n",
      "Loss for Batch(75): 0.012010210193693638\n",
      "Batch 76\n",
      "Loss for Batch(76): 0.0092893922701478\n",
      "Batch 77\n",
      "Loss for Batch(77): 0.03082949109375477\n",
      "Batch 78\n",
      "Loss for Batch(78): 0.03048539161682129\n",
      "Batch 79\n",
      "Loss for Batch(79): 0.0010159743251278996\n",
      "Batch 80\n",
      "Loss for Batch(80): 0.00022788497153669596\n",
      "Batch 81\n",
      "Loss for Batch(81): 0.00032134217326529324\n",
      "Batch 82\n",
      "Loss for Batch(82): 0.0035307658836245537\n",
      "Batch 83\n",
      "Loss for Batch(83): 0.012594478204846382\n",
      "Batch 84\n",
      "Loss for Batch(84): 0.0029051194433122873\n",
      "Batch 85\n",
      "Loss for Batch(85): 0.0008511316846124828\n",
      "Batch 86\n",
      "Loss for Batch(86): 0.3971312344074249\n",
      "Batch 87\n",
      "Loss for Batch(87): 0.021726077422499657\n",
      "Batch 88\n",
      "Loss for Batch(88): 0.07910765707492828\n",
      "Batch 89\n",
      "Loss for Batch(89): 0.006973722949624062\n",
      "Batch 90\n",
      "Loss for Batch(90): 0.002089601708576083\n",
      "Batch 91\n",
      "Loss for Batch(91): 0.060310039669275284\n",
      "Batch 92\n",
      "Loss for Batch(92): 0.004593612626194954\n",
      "Batch 93\n",
      "Loss for Batch(93): 0.00356845511123538\n",
      "Batch 94\n",
      "Loss for Batch(94): 0.03175025060772896\n",
      "Batch 95\n",
      "Loss for Batch(95): 0.0017118294490501285\n",
      "Batch 96\n",
      "Loss for Batch(96): 0.006014981307089329\n",
      "Batch 97\n",
      "Loss for Batch(97): 0.07917706668376923\n",
      "Batch 98\n",
      "Loss for Batch(98): 0.0007051429129205644\n",
      "Batch 99\n",
      "Loss for Batch(99): 0.016097160056233406\n",
      "Batch 100\n",
      "Loss for Batch(100): 0.000655480136629194\n",
      "Batch 101\n",
      "Loss for Batch(101): 0.2762802243232727\n",
      "Batch 102\n",
      "Loss for Batch(102): 0.019042467698454857\n",
      "Batch 103\n",
      "Loss for Batch(103): 0.0034647646825760603\n",
      "Batch 104\n",
      "Loss for Batch(104): 0.01058991253376007\n",
      "Batch 105\n",
      "Loss for Batch(105): 0.09232668578624725\n",
      "Batch 106\n",
      "Loss for Batch(106): 0.003662058152258396\n",
      "Batch 107\n",
      "Loss for Batch(107): 0.002895059296861291\n",
      "Batch 108\n",
      "Loss for Batch(108): 0.02071545645594597\n",
      "Batch 109\n",
      "Loss for Batch(109): 0.009607926942408085\n",
      "Batch 110\n",
      "Loss for Batch(110): 0.0012958318693563342\n",
      "Batch 111\n",
      "Loss for Batch(111): 0.02801048383116722\n",
      "Batch 112\n",
      "Loss for Batch(112): 0.000670462439302355\n",
      "Batch 113\n",
      "Loss for Batch(113): 0.005638609174638987\n",
      "Batch 114\n",
      "Loss for Batch(114): 0.00692468136548996\n",
      "Batch 115\n",
      "Loss for Batch(115): 0.03855540230870247\n",
      "Batch 116\n",
      "Loss for Batch(116): 0.005565728526562452\n",
      "Batch 117\n",
      "Loss for Batch(117): 0.0004711796354968101\n",
      "Batch 118\n",
      "Loss for Batch(118): 0.0004140257660765201\n",
      "Batch 119\n",
      "Loss for Batch(119): 0.00016281724674627185\n",
      "Batch 120\n",
      "Loss for Batch(120): 0.0028714158106595278\n",
      "Batch 121\n",
      "Loss for Batch(121): 0.016238734126091003\n",
      "Batch 122\n",
      "Loss for Batch(122): 0.0005859534721821547\n",
      "Batch 123\n",
      "Loss for Batch(123): 0.20690706372261047\n",
      "Batch 124\n",
      "Loss for Batch(124): 0.053380563855171204\n",
      "Batch 125\n",
      "Loss for Batch(125): 0.040767181664705276\n",
      "Batch 126\n",
      "Loss for Batch(126): 0.026629403233528137\n",
      "Batch 127\n",
      "Loss for Batch(127): 0.001889468519948423\n",
      "Batch 128\n",
      "Loss for Batch(128): 0.6278992891311646\n",
      "Batch 129\n",
      "Loss for Batch(129): 0.015944136306643486\n",
      "Batch 130\n",
      "Loss for Batch(130): 0.0031774514354765415\n",
      "Batch 131\n",
      "Loss for Batch(131): 0.0032184834126383066\n",
      "Batch 132\n",
      "Loss for Batch(132): 0.008754092268645763\n",
      "Batch 133\n",
      "Loss for Batch(133): 0.08257856965065002\n",
      "Batch 134\n",
      "Loss for Batch(134): 0.006274378392845392\n",
      "Batch 135\n",
      "Loss for Batch(135): 0.055085644125938416\n",
      "Batch 136\n",
      "Loss for Batch(136): 0.005845983978360891\n",
      "Batch 137\n",
      "Loss for Batch(137): 0.0002796001499518752\n",
      "Batch 138\n",
      "Loss for Batch(138): 0.026896392926573753\n",
      "Batch 139\n",
      "Loss for Batch(139): 0.022456318140029907\n",
      "Batch 140\n",
      "Loss for Batch(140): 0.03782733529806137\n",
      "Batch 141\n",
      "Loss for Batch(141): 0.006022056099027395\n",
      "Batch 142\n",
      "Loss for Batch(142): 0.001444242661818862\n",
      "Batch 143\n",
      "Loss for Batch(143): 0.0015658490592613816\n",
      "Batch 144\n",
      "Loss for Batch(144): 0.0032183798030018806\n",
      "Batch 145\n",
      "Loss for Batch(145): 0.0005035761278122663\n",
      "Batch 146\n",
      "Loss for Batch(146): 0.02091149054467678\n",
      "Batch 147\n",
      "Loss for Batch(147): 0.03384552523493767\n",
      "Batch 148\n",
      "Loss for Batch(148): 0.00034267178853042424\n",
      "Batch 149\n",
      "Loss for Batch(149): 0.05454844608902931\n",
      "Batch 150\n",
      "Loss for Batch(150): 0.008032293058931828\n",
      "Batch 151\n",
      "Loss for Batch(151): 0.03199927136301994\n",
      "Batch 152\n",
      "Loss for Batch(152): 0.9779335260391235\n",
      "Batch 153\n",
      "Loss for Batch(153): 0.001358773559331894\n",
      "Batch 154\n",
      "Loss for Batch(154): 0.0051307049579918385\n",
      "Batch 155\n",
      "Loss for Batch(155): 0.22255584597587585\n",
      "Batch 156\n",
      "Loss for Batch(156): 0.10424377024173737\n",
      "Batch 157\n",
      "Loss for Batch(157): 0.004120462574064732\n",
      "Batch 158\n",
      "Loss for Batch(158): 0.04886725917458534\n",
      "Batch 159\n",
      "Loss for Batch(159): 0.010312072932720184\n",
      "Batch 160\n",
      "Loss for Batch(160): 0.0005773318698629737\n",
      "Batch 161\n",
      "Loss for Batch(161): 0.0018627289682626724\n",
      "Batch 162\n",
      "Loss for Batch(162): 0.9335193037986755\n",
      "Batch 163\n",
      "Loss for Batch(163): 0.04345483332872391\n",
      "Batch 164\n",
      "Loss for Batch(164): 0.009338595904409885\n",
      "Batch 165\n",
      "Loss for Batch(165): 0.21971860527992249\n",
      "Batch 166\n",
      "Loss for Batch(166): 0.002038008999079466\n",
      "Batch 167\n",
      "Loss for Batch(167): 0.10293586552143097\n",
      "Batch 168\n",
      "Loss for Batch(168): 0.0021457967814058065\n",
      "Batch 169\n",
      "Loss for Batch(169): 0.006409644614905119\n",
      "Batch 170\n",
      "Loss for Batch(170): 0.028179682791233063\n",
      "Batch 171\n",
      "Loss for Batch(171): 0.1719694435596466\n",
      "Batch 172\n",
      "Loss for Batch(172): 0.026458123698830605\n",
      "Batch 173\n",
      "Loss for Batch(173): 0.04022584110498428\n",
      "Batch 174\n",
      "Loss for Batch(174): 0.0041291178204119205\n",
      "Batch 175\n",
      "Loss for Batch(175): 0.002179923700168729\n",
      "Batch 176\n",
      "Loss for Batch(176): 0.02163582481443882\n",
      "Batch 177\n",
      "Loss for Batch(177): 0.0239062812179327\n",
      "Batch 178\n",
      "Loss for Batch(178): 0.06370271742343903\n",
      "Batch 179\n",
      "Loss for Batch(179): 0.011607424356043339\n",
      "Batch 180\n",
      "Loss for Batch(180): 0.027884338051080704\n",
      "Batch 181\n",
      "Loss for Batch(181): 0.0013746019685640931\n",
      "Batch 182\n",
      "Loss for Batch(182): 0.014392253942787647\n",
      "Batch 183\n",
      "Loss for Batch(183): 0.0015049254288896918\n",
      "Batch 184\n",
      "Loss for Batch(184): 0.006328756920993328\n",
      "Batch 185\n",
      "Loss for Batch(185): 0.00037723808782175183\n",
      "Batch 186\n",
      "Loss for Batch(186): 0.07033740729093552\n",
      "Batch 187\n",
      "Loss for Batch(187): 0.05450665205717087\n",
      "Batch 188\n",
      "Loss for Batch(188): 0.010148804634809494\n",
      "Batch 189\n",
      "Loss for Batch(189): 0.13441210985183716\n",
      "Batch 190\n",
      "Loss for Batch(190): 3.85026796720922e-05\n",
      "Batch 191\n",
      "Loss for Batch(191): 0.002765070414170623\n",
      "Batch 192\n",
      "Loss for Batch(192): 0.031419169157743454\n",
      "Batch 193\n",
      "Loss for Batch(193): 0.02834264375269413\n",
      "Batch 194\n",
      "Loss for Batch(194): 0.08456007391214371\n",
      "Batch 195\n",
      "Loss for Batch(195): 0.0010113230673596263\n",
      "Batch 196\n",
      "Loss for Batch(196): 0.0034133405424654484\n",
      "Batch 197\n",
      "Loss for Batch(197): 0.009235256351530552\n",
      "Batch 198\n",
      "Loss for Batch(198): 1.353007883153623e-05\n",
      "Batch 199\n",
      "Loss for Batch(199): 0.04494883865118027\n",
      "Batch 200\n",
      "Loss for Batch(200): 0.04315946623682976\n",
      "Batch 201\n",
      "Loss for Batch(201): 0.03725477308034897\n",
      "Batch 202\n",
      "Loss for Batch(202): 0.018136633560061455\n",
      "Batch 203\n",
      "Loss for Batch(203): 0.0019355590920895338\n",
      "Batch 204\n",
      "Loss for Batch(204): 0.08794842660427094\n",
      "Batch 205\n",
      "Loss for Batch(205): 0.0009047457715496421\n",
      "Batch 206\n",
      "Loss for Batch(206): 0.0014616060070693493\n",
      "Batch 207\n",
      "Loss for Batch(207): 0.0012320716632530093\n",
      "Batch 208\n",
      "Loss for Batch(208): 0.02030753344297409\n",
      "Batch 209\n",
      "Loss for Batch(209): 0.38119009137153625\n",
      "Batch 210\n",
      "Loss for Batch(210): 0.001547828083857894\n",
      "Batch 211\n",
      "Loss for Batch(211): 5.828982830280438e-05\n",
      "Batch 212\n",
      "Loss for Batch(212): 0.0025425918865948915\n",
      "Batch 213\n",
      "Loss for Batch(213): 0.06012373045086861\n",
      "Batch 214\n",
      "Loss for Batch(214): 0.04050347954034805\n",
      "Batch 215\n",
      "Loss for Batch(215): 0.0026868830900639296\n",
      "Batch 216\n",
      "Loss for Batch(216): 0.0006436802796088159\n",
      "Batch 217\n",
      "Loss for Batch(217): 0.002473971340805292\n",
      "Batch 218\n",
      "Loss for Batch(218): 0.00997965782880783\n",
      "Batch 219\n",
      "Loss for Batch(219): 0.007950854487717152\n",
      "Batch 220\n",
      "Loss for Batch(220): 0.0012840528506785631\n",
      "Batch 221\n",
      "Loss for Batch(221): 0.0012458525598049164\n",
      "Batch 222\n",
      "Loss for Batch(222): 0.0003420052817091346\n",
      "Batch 223\n",
      "Loss for Batch(223): 0.056364599615335464\n",
      "Batch 224\n",
      "Loss for Batch(224): 0.00038807804230600595\n",
      "Batch 225\n",
      "Loss for Batch(225): 0.0030330116860568523\n",
      "Batch 226\n",
      "Loss for Batch(226): 0.04249386489391327\n",
      "Batch 227\n",
      "Loss for Batch(227): 0.02913178876042366\n",
      "Batch 228\n",
      "Loss for Batch(228): 0.0049763028509914875\n",
      "Batch 229\n",
      "Loss for Batch(229): 0.01619086042046547\n",
      "Batch 230\n",
      "Loss for Batch(230): 0.0010803412878885865\n",
      "Batch 231\n",
      "Loss for Batch(231): 0.0019237614469602704\n",
      "Batch 232\n",
      "Loss for Batch(232): 0.04424956068396568\n",
      "Batch 233\n",
      "Loss for Batch(233): 3.894911424140446e-05\n",
      "Batch 234\n",
      "Loss for Batch(234): 9.717598732095212e-05\n",
      "Batch 235\n",
      "Loss for Batch(235): 0.024135855957865715\n",
      "Batch 236\n",
      "Loss for Batch(236): 0.03926948085427284\n",
      "Batch 237\n",
      "Loss for Batch(237): 0.00041144166607409716\n",
      "Batch 238\n",
      "Loss for Batch(238): 0.0005024854908697307\n",
      "Batch 239\n",
      "Loss for Batch(239): 0.3948841989040375\n",
      "Batch 240\n",
      "Loss for Batch(240): 0.006823119707405567\n",
      "Batch 241\n",
      "Loss for Batch(241): 0.0008099413244053721\n",
      "Batch 242\n",
      "Loss for Batch(242): 0.001498938538134098\n",
      "Batch 243\n",
      "Loss for Batch(243): 0.0440523624420166\n",
      "Batch 244\n",
      "Loss for Batch(244): 0.010035683400928974\n",
      "Batch 245\n",
      "Loss for Batch(245): 0.04012178257107735\n",
      "Batch 246\n",
      "Loss for Batch(246): 0.01013064756989479\n",
      "Batch 247\n",
      "Loss for Batch(247): 0.013317475095391273\n",
      "Batch 248\n",
      "Loss for Batch(248): 0.25023943185806274\n",
      "Batch 249\n",
      "Loss for Batch(249): 9.273301839129999e-05\n",
      "Batch 250\n",
      "Loss for Batch(250): 0.014350461773574352\n",
      "Batch 251\n",
      "Loss for Batch(251): 0.0015945610357448459\n",
      "Batch 252\n",
      "Loss for Batch(252): 0.00218673306517303\n",
      "Batch 253\n",
      "Loss for Batch(253): 0.6049984097480774\n",
      "Batch 254\n",
      "Loss for Batch(254): 0.0045287213288247585\n",
      "Batch 255\n",
      "Loss for Batch(255): 0.07204020768404007\n",
      "Batch 256\n",
      "Loss for Batch(256): 0.005910366773605347\n",
      "Batch 257\n",
      "Loss for Batch(257): 0.0002787573612295091\n",
      "Batch 258\n",
      "Loss for Batch(258): 0.02659950777888298\n",
      "Batch 259\n",
      "Loss for Batch(259): 0.0170576348900795\n",
      "Batch 260\n",
      "Loss for Batch(260): 0.03824058920145035\n",
      "Batch 261\n",
      "Loss for Batch(261): 0.024151550605893135\n",
      "Batch 262\n",
      "Loss for Batch(262): 0.053479261696338654\n",
      "Batch 263\n",
      "Loss for Batch(263): 0.05869124084711075\n",
      "Batch 264\n",
      "Loss for Batch(264): 0.0012003391748294234\n",
      "Batch 265\n",
      "Loss for Batch(265): 0.001285334350541234\n",
      "Batch 266\n",
      "Loss for Batch(266): 0.060073550790548325\n",
      "Batch 267\n",
      "Loss for Batch(267): 0.0038919630460441113\n",
      "Batch 268\n",
      "Loss for Batch(268): 0.009464667178690434\n",
      "Batch 269\n",
      "Loss for Batch(269): 0.01816587895154953\n",
      "Batch 270\n",
      "Loss for Batch(270): 0.11759796738624573\n",
      "Batch 271\n",
      "Loss for Batch(271): 2.7685659006237984e-05\n",
      "Batch 272\n",
      "Loss for Batch(272): 0.14994806051254272\n",
      "Batch 273\n",
      "Loss for Batch(273): 0.03201451152563095\n",
      "Batch 274\n",
      "Loss for Batch(274): 0.008069747127592564\n",
      "Batch 275\n",
      "Loss for Batch(275): 0.01576094515621662\n",
      "Batch 276\n",
      "Loss for Batch(276): 0.0015567992813885212\n",
      "Batch 277\n",
      "Loss for Batch(277): 0.015444932505488396\n",
      "Batch 278\n",
      "Loss for Batch(278): 0.017229363322257996\n",
      "Batch 279\n",
      "Loss for Batch(279): 0.00022530206479132175\n",
      "Batch 280\n",
      "Loss for Batch(280): 3.191683936165646e-05\n",
      "Batch 281\n",
      "Loss for Batch(281): 0.06937730312347412\n",
      "Batch 282\n",
      "Loss for Batch(282): 0.016624433919787407\n",
      "Batch 283\n",
      "Loss for Batch(283): 0.01582443155348301\n",
      "Batch 284\n",
      "Loss for Batch(284): 0.0006215757457539439\n",
      "Batch 285\n",
      "Loss for Batch(285): 0.00856047309935093\n",
      "Batch 286\n",
      "Loss for Batch(286): 0.20223109424114227\n",
      "Batch 287\n",
      "Loss for Batch(287): 0.06048595905303955\n",
      "Batch 288\n",
      "Loss for Batch(288): 0.07281310856342316\n",
      "Batch 289\n",
      "Loss for Batch(289): 0.003874258603900671\n",
      "Batch 290\n",
      "Loss for Batch(290): 0.010463148355484009\n",
      "Batch 291\n",
      "Loss for Batch(291): 0.13797102868556976\n",
      "Batch 292\n",
      "Loss for Batch(292): 0.0014882623217999935\n",
      "Batch 293\n",
      "Loss for Batch(293): 0.027954692021012306\n",
      "Batch 294\n",
      "Loss for Batch(294): 0.00011394578905310482\n",
      "Batch 295\n",
      "Loss for Batch(295): 0.0018791734473779798\n",
      "Batch 296\n",
      "Loss for Batch(296): 0.23768626153469086\n",
      "Batch 297\n",
      "Loss for Batch(297): 0.027694065123796463\n",
      "Batch 298\n",
      "Loss for Batch(298): 0.10158775001764297\n",
      "Batch 299\n",
      "Loss for Batch(299): 0.006688609253615141\n",
      "Batch 300\n",
      "Loss for Batch(300): 0.0007261038408614695\n",
      "Batch 301\n",
      "Loss for Batch(301): 0.05150633305311203\n",
      "Batch 302\n",
      "Loss for Batch(302): 0.01677253283560276\n",
      "Batch 303\n",
      "Loss for Batch(303): 0.00656531797721982\n",
      "Batch 304\n",
      "Loss for Batch(304): 0.052928049117326736\n",
      "Batch 305\n",
      "Loss for Batch(305): 0.0019805417396128178\n",
      "Batch 306\n",
      "Loss for Batch(306): 0.015095088630914688\n",
      "Batch 307\n",
      "Loss for Batch(307): 0.001474043121561408\n",
      "Batch 308\n",
      "Loss for Batch(308): 0.029222942888736725\n",
      "Batch 309\n",
      "Loss for Batch(309): 0.03736771270632744\n",
      "Batch 310\n",
      "Loss for Batch(310): 0.08005177974700928\n",
      "Batch 311\n",
      "Loss for Batch(311): 6.183535151649266e-05\n",
      "Batch 312\n",
      "Loss for Batch(312): 0.008078417740762234\n",
      "Batch 313\n",
      "Loss for Batch(313): 0.005080436822026968\n",
      "Batch 314\n",
      "Loss for Batch(314): 0.0021288974676281214\n",
      "Batch 315\n",
      "Loss for Batch(315): 0.01801949366927147\n",
      "Batch 316\n",
      "Loss for Batch(316): 0.036758940666913986\n",
      "Batch 317\n",
      "Loss for Batch(317): 0.00013594157644547522\n",
      "Batch 318\n",
      "Loss for Batch(318): 0.006911940407007933\n",
      "Batch 319\n",
      "Loss for Batch(319): 0.16241034865379333\n",
      "Batch 320\n",
      "Loss for Batch(320): 0.021048231050372124\n",
      "Batch 321\n",
      "Loss for Batch(321): 0.010224428959190845\n",
      "Batch 322\n",
      "Loss for Batch(322): 0.00034269288880750537\n",
      "Batch 323\n",
      "Loss for Batch(323): 0.18362027406692505\n",
      "Batch 324\n",
      "Loss for Batch(324): 0.005923091433942318\n",
      "Batch 325\n",
      "Loss for Batch(325): 0.0012854303931817412\n",
      "Batch 326\n",
      "Loss for Batch(326): 0.16135403513908386\n",
      "Batch 327\n",
      "Loss for Batch(327): 0.006511985789984465\n",
      "Batch 328\n",
      "Loss for Batch(328): 0.0003050667583011091\n",
      "Batch 329\n",
      "Loss for Batch(329): 0.003833121620118618\n",
      "Batch 330\n",
      "Loss for Batch(330): 0.0015307721914723516\n",
      "Batch 331\n",
      "Loss for Batch(331): 0.004695925861597061\n",
      "Batch 332\n",
      "Loss for Batch(332): 0.00035266519989818335\n",
      "Batch 333\n",
      "Loss for Batch(333): 0.06553559750318527\n",
      "Batch 334\n",
      "Loss for Batch(334): 0.005246778018772602\n",
      "Batch 335\n",
      "Loss for Batch(335): 0.004612896125763655\n",
      "Batch 336\n",
      "Loss for Batch(336): 0.005898983683437109\n",
      "Batch 337\n",
      "Loss for Batch(337): 3.504527558106929e-05\n",
      "Batch 338\n",
      "Loss for Batch(338): 0.0724332332611084\n",
      "Batch 339\n",
      "Loss for Batch(339): 0.2932577431201935\n",
      "Batch 340\n",
      "Loss for Batch(340): 0.03541960194706917\n",
      "Batch 341\n",
      "Loss for Batch(341): 0.003967359662055969\n",
      "Batch 342\n",
      "Loss for Batch(342): 0.018290270119905472\n",
      "Batch 343\n",
      "Loss for Batch(343): 0.08508019149303436\n",
      "Batch 344\n",
      "Loss for Batch(344): 0.035594187676906586\n",
      "Batch 345\n",
      "Loss for Batch(345): 0.0020010059233754873\n",
      "Batch 346\n",
      "Loss for Batch(346): 0.0006124258507043123\n",
      "Batch 347\n",
      "Loss for Batch(347): 0.01751425303518772\n",
      "Batch 348\n",
      "Loss for Batch(348): 0.01317207794636488\n",
      "Batch 349\n",
      "Loss for Batch(349): 0.0017231169622391462\n",
      "Batch 350\n",
      "Loss for Batch(350): 0.025226633995771408\n",
      "Batch 351\n",
      "Loss for Batch(351): 0.001643441733904183\n",
      "Batch 352\n",
      "Loss for Batch(352): 0.026400920003652573\n",
      "Batch 353\n",
      "Loss for Batch(353): 0.011732823215425014\n",
      "Batch 354\n",
      "Loss for Batch(354): 0.00047351670218631625\n",
      "Batch 355\n",
      "Loss for Batch(355): 0.09734056144952774\n",
      "Batch 356\n",
      "Loss for Batch(356): 0.01429658941924572\n",
      "Batch 357\n",
      "Loss for Batch(357): 0.02159392647445202\n",
      "Batch 358\n",
      "Loss for Batch(358): 0.0130637651309371\n",
      "Batch 359\n",
      "Loss for Batch(359): 0.08787202090024948\n",
      "Batch 360\n",
      "Loss for Batch(360): 0.0019961607176810503\n",
      "Batch 361\n",
      "Loss for Batch(361): 0.003962669521570206\n",
      "Batch 362\n",
      "Loss for Batch(362): 0.0020977857057005167\n",
      "Batch 363\n",
      "Loss for Batch(363): 0.41931888461112976\n",
      "Batch 364\n",
      "Loss for Batch(364): 0.003031723201274872\n",
      "Batch 365\n",
      "Loss for Batch(365): 0.0016093780286610126\n",
      "Batch 366\n",
      "Loss for Batch(366): 0.003987423609942198\n",
      "Batch 367\n",
      "Loss for Batch(367): 0.0018443779554218054\n",
      "Batch 368\n",
      "Loss for Batch(368): 0.0010805416386574507\n",
      "Batch 369\n",
      "Loss for Batch(369): 0.07579696178436279\n",
      "Batch 370\n",
      "Loss for Batch(370): 0.0035758791491389275\n",
      "Batch 371\n",
      "Loss for Batch(371): 0.04108932614326477\n",
      "Batch 372\n",
      "Loss for Batch(372): 0.02642207033932209\n",
      "Batch 373\n",
      "Loss for Batch(373): 0.0031597560737282038\n",
      "Batch 374\n",
      "Loss for Batch(374): 0.0017103441059589386\n",
      "Batch 375\n",
      "Loss for Batch(375): 0.0015533382538706064\n",
      "Batch 376\n",
      "Loss for Batch(376): 0.006487769540399313\n",
      "Batch 377\n",
      "Loss for Batch(377): 0.012862177565693855\n",
      "Batch 378\n",
      "Loss for Batch(378): 0.001707583898678422\n",
      "Batch 379\n",
      "Loss for Batch(379): 0.08116469532251358\n",
      "Batch 380\n",
      "Loss for Batch(380): 0.005905400961637497\n",
      "Batch 381\n",
      "Loss for Batch(381): 0.00019596573838498443\n",
      "Batch 382\n",
      "Loss for Batch(382): 0.004435825161635876\n",
      "Batch 383\n",
      "Loss for Batch(383): 0.0003206641413271427\n",
      "Batch 384\n",
      "Loss for Batch(384): 0.024241652339696884\n",
      "Batch 385\n",
      "Loss for Batch(385): 0.03147285431623459\n",
      "Batch 386\n",
      "Loss for Batch(386): 0.010035555809736252\n",
      "Batch 387\n",
      "Loss for Batch(387): 0.02084851823747158\n",
      "Batch 388\n",
      "Loss for Batch(388): 0.06037121266126633\n",
      "Batch 389\n",
      "Loss for Batch(389): 0.025689098984003067\n",
      "Batch 390\n",
      "Loss for Batch(390): 0.14780943095684052\n",
      "Batch 391\n",
      "Loss for Batch(391): 0.038438830524683\n",
      "Batch 392\n",
      "Loss for Batch(392): 0.0013927818508818746\n",
      "Batch 393\n",
      "Loss for Batch(393): 0.015275094658136368\n",
      "Batch 394\n",
      "Loss for Batch(394): 0.05543427914381027\n",
      "Batch 395\n",
      "Loss for Batch(395): 0.009608118794858456\n",
      "Batch 396\n",
      "Loss for Batch(396): 0.17714358866214752\n",
      "Batch 397\n",
      "Loss for Batch(397): 0.2921481430530548\n",
      "Batch 398\n",
      "Loss for Batch(398): 0.013378370553255081\n",
      "Batch 399\n",
      "Loss for Batch(399): 0.12274451553821564\n",
      "Batch 400\n",
      "Loss for Batch(400): 0.022225212305784225\n",
      "Batch 401\n",
      "Loss for Batch(401): 0.09995091706514359\n",
      "Batch 402\n",
      "Loss for Batch(402): 0.00040015202830545604\n",
      "Batch 403\n",
      "Loss for Batch(403): 0.02404666319489479\n",
      "Batch 404\n",
      "Loss for Batch(404): 0.002436818554997444\n",
      "Batch 405\n",
      "Loss for Batch(405): 0.09461960196495056\n",
      "Batch 406\n",
      "Loss for Batch(406): 0.0414825975894928\n",
      "Batch 407\n",
      "Loss for Batch(407): 0.14042702317237854\n",
      "Batch 408\n",
      "Loss for Batch(408): 0.009576605632901192\n",
      "Batch 409\n",
      "Loss for Batch(409): 0.22508540749549866\n",
      "Batch 410\n",
      "Loss for Batch(410): 0.07916229963302612\n",
      "Batch 411\n",
      "Loss for Batch(411): 0.0009969972306862473\n",
      "Batch 412\n",
      "Loss for Batch(412): 0.002261414425447583\n",
      "Batch 413\n",
      "Loss for Batch(413): 0.2590395510196686\n",
      "Batch 414\n",
      "Loss for Batch(414): 0.004915068857371807\n",
      "Batch 415\n",
      "Loss for Batch(415): 0.06571047753095627\n",
      "Batch 416\n",
      "Loss for Batch(416): 0.01236466970294714\n",
      "Batch 417\n",
      "Loss for Batch(417): 0.00027166304062120616\n",
      "Batch 418\n",
      "Loss for Batch(418): 0.04696972295641899\n",
      "Batch 419\n",
      "Loss for Batch(419): 0.04544176906347275\n",
      "Batch 420\n",
      "Loss for Batch(420): 0.0026454098988324404\n",
      "Batch 421\n",
      "Loss for Batch(421): 0.0018606455996632576\n",
      "Batch 422\n",
      "Loss for Batch(422): 0.001385834300890565\n",
      "Batch 423\n",
      "Loss for Batch(423): 0.6408392190933228\n",
      "Batch 424\n",
      "Loss for Batch(424): 0.0006050429074093699\n",
      "Batch 425\n",
      "Loss for Batch(425): 0.08873634785413742\n",
      "Batch 426\n",
      "Loss for Batch(426): 0.2077864706516266\n",
      "Batch 427\n",
      "Loss for Batch(427): 0.004069250542670488\n",
      "Batch 428\n",
      "Loss for Batch(428): 0.005061041563749313\n",
      "Batch 429\n",
      "Loss for Batch(429): 0.00787755474448204\n",
      "Batch 430\n",
      "Loss for Batch(430): 0.09280604869127274\n",
      "Batch 431\n",
      "Loss for Batch(431): 0.044594522565603256\n",
      "Batch 432\n",
      "Loss for Batch(432): 0.015770189464092255\n",
      "Batch 433\n",
      "Loss for Batch(433): 0.06372682750225067\n",
      "Batch 434\n",
      "Loss for Batch(434): 0.021081961691379547\n",
      "Batch 435\n",
      "Loss for Batch(435): 0.002104945247992873\n",
      "Batch 436\n",
      "Loss for Batch(436): 0.016108540818095207\n",
      "Batch 437\n",
      "Loss for Batch(437): 0.0007714852690696716\n",
      "Batch 438\n",
      "Loss for Batch(438): 0.024159207940101624\n",
      "Batch 439\n",
      "Loss for Batch(439): 0.012445926666259766\n",
      "Batch 440\n",
      "Loss for Batch(440): 0.006146203260868788\n",
      "Batch 441\n",
      "Loss for Batch(441): 0.020303208380937576\n",
      "Batch 442\n",
      "Loss for Batch(442): 0.001285410369746387\n",
      "Batch 443\n",
      "Loss for Batch(443): 0.00040137837640941143\n",
      "Batch 444\n",
      "Loss for Batch(444): 0.005989248398691416\n",
      "Batch 445\n",
      "Loss for Batch(445): 0.0006583412177860737\n",
      "Batch 446\n",
      "Loss for Batch(446): 0.0026107439771294594\n",
      "Batch 447\n",
      "Loss for Batch(447): 0.012308946810662746\n",
      "Batch 448\n",
      "Loss for Batch(448): 0.027996016666293144\n",
      "Batch 449\n",
      "Loss for Batch(449): 0.12220346927642822\n",
      "Batch 450\n",
      "Loss for Batch(450): 0.24634240567684174\n",
      "Batch 451\n",
      "Loss for Batch(451): 0.011944145895540714\n",
      "Batch 452\n",
      "Loss for Batch(452): 0.004628942348062992\n",
      "Batch 453\n",
      "Loss for Batch(453): 0.002877067541703582\n",
      "Batch 454\n",
      "Loss for Batch(454): 0.0004417671007104218\n",
      "Batch 455\n",
      "Loss for Batch(455): 0.001044517382979393\n",
      "Batch 456\n",
      "Loss for Batch(456): 0.043849773705005646\n",
      "Batch 457\n",
      "Loss for Batch(457): 0.03232366591691971\n",
      "Batch 458\n",
      "Loss for Batch(458): 0.14322854578495026\n",
      "Batch 459\n",
      "Loss for Batch(459): 0.040196701884269714\n",
      "Batch 460\n",
      "Loss for Batch(460): 0.038807835429906845\n",
      "Batch 461\n",
      "Loss for Batch(461): 0.06511750817298889\n",
      "Batch 462\n",
      "Loss for Batch(462): 0.0264994278550148\n",
      "Batch 463\n",
      "Loss for Batch(463): 0.004696506075561047\n",
      "Batch 464\n",
      "Loss for Batch(464): 0.04107692837715149\n",
      "Batch 465\n",
      "Loss for Batch(465): 0.0859007015824318\n",
      "Batch 466\n",
      "Loss for Batch(466): 0.006330174393951893\n",
      "Batch 467\n",
      "Loss for Batch(467): 0.047162946313619614\n",
      "Batch 468\n",
      "Loss for Batch(468): 0.0017834444297477603\n",
      "Batch 469\n",
      "Loss for Batch(469): 0.00914545264095068\n",
      "Batch 470\n",
      "Loss for Batch(470): 0.06349974125623703\n",
      "Batch 471\n",
      "Loss for Batch(471): 0.011555150151252747\n",
      "Batch 472\n",
      "Loss for Batch(472): 0.15524165332317352\n",
      "Batch 473\n",
      "Loss for Batch(473): 0.009741256013512611\n",
      "Batch 474\n",
      "Loss for Batch(474): 0.016978980973362923\n",
      "Batch 475\n",
      "Loss for Batch(475): 0.00188577885273844\n",
      "Batch 476\n",
      "Loss for Batch(476): 0.06715986877679825\n",
      "Batch 477\n",
      "Loss for Batch(477): 0.08750597387552261\n",
      "Batch 478\n",
      "Loss for Batch(478): 0.004954319912940264\n",
      "Batch 479\n",
      "Loss for Batch(479): 0.001783696934580803\n",
      "Batch 480\n",
      "Loss for Batch(480): 0.0001858796749729663\n",
      "Batch 481\n",
      "Loss for Batch(481): 0.009737228974699974\n",
      "Batch 482\n",
      "Loss for Batch(482): 0.31311190128326416\n",
      "Batch 483\n",
      "Loss for Batch(483): 0.003261040663346648\n",
      "Batch 484\n",
      "Loss for Batch(484): 0.27441683411598206\n",
      "Batch 485\n",
      "Loss for Batch(485): 0.11422901600599289\n",
      "Batch 486\n",
      "Loss for Batch(486): 0.01292033027857542\n",
      "Batch 487\n",
      "Loss for Batch(487): 0.10124462842941284\n",
      "Batch 488\n",
      "Loss for Batch(488): 0.012197518721222878\n",
      "Batch 489\n",
      "Loss for Batch(489): 0.004823935683816671\n",
      "Batch 490\n",
      "Loss for Batch(490): 0.06023355573415756\n",
      "Batch 491\n",
      "Loss for Batch(491): 0.01778709888458252\n",
      "Batch 492\n",
      "Loss for Batch(492): 0.2943543791770935\n",
      "Batch 493\n",
      "Loss for Batch(493): 0.006004794035106897\n",
      "Batch 494\n",
      "Loss for Batch(494): 0.023701373487710953\n",
      "Batch 495\n",
      "Loss for Batch(495): 0.01968691498041153\n",
      "Batch 496\n",
      "Loss for Batch(496): 0.011320620775222778\n",
      "Batch 497\n",
      "Loss for Batch(497): 0.007369713392108679\n",
      "Batch 498\n",
      "Loss for Batch(498): 0.12719625234603882\n",
      "Batch 499\n",
      "Loss for Batch(499): 0.0010799325536936522\n",
      "Batch 500\n",
      "Loss for Batch(500): 0.001070518046617508\n",
      "Batch 501\n",
      "Loss for Batch(501): 0.004887967836111784\n",
      "Batch 502\n",
      "Loss for Batch(502): 0.08267524093389511\n",
      "Batch 503\n",
      "Loss for Batch(503): 0.014411701820790768\n",
      "Batch 504\n",
      "Loss for Batch(504): 0.00195483909919858\n",
      "Batch 505\n",
      "Loss for Batch(505): 0.015520469285547733\n",
      "Batch 506\n",
      "Loss for Batch(506): 0.048395972698926926\n",
      "Batch 507\n",
      "Loss for Batch(507): 0.00014991311763878912\n",
      "Batch 508\n",
      "Loss for Batch(508): 0.001470391871407628\n",
      "Batch 509\n",
      "Loss for Batch(509): 0.13287591934204102\n",
      "Batch 510\n",
      "Loss for Batch(510): 0.0008836028282530606\n",
      "Batch 511\n",
      "Loss for Batch(511): 0.04064168035984039\n",
      "Batch 512\n",
      "Loss for Batch(512): 0.00042322505032643676\n",
      "Batch 513\n",
      "Loss for Batch(513): 0.019960010424256325\n",
      "Batch 514\n",
      "Loss for Batch(514): 0.07236284017562866\n",
      "Batch 515\n",
      "Loss for Batch(515): 0.036973558366298676\n",
      "Batch 516\n",
      "Loss for Batch(516): 0.027190277352929115\n",
      "Batch 517\n",
      "Loss for Batch(517): 0.004353780765086412\n",
      "Batch 518\n",
      "Loss for Batch(518): 0.0014475309289991856\n",
      "Batch 519\n",
      "Loss for Batch(519): 0.0240616574883461\n",
      "Batch 520\n",
      "Loss for Batch(520): 0.0023585583548992872\n",
      "Batch 521\n",
      "Loss for Batch(521): 0.011206638999283314\n",
      "Batch 522\n",
      "Loss for Batch(522): 0.01207145769149065\n",
      "Batch 523\n",
      "Loss for Batch(523): 0.0067891390062868595\n",
      "Batch 524\n",
      "Loss for Batch(524): 0.001264082849957049\n",
      "Batch 525\n",
      "Loss for Batch(525): 0.44668808579444885\n",
      "Batch 526\n",
      "Loss for Batch(526): 0.0015080757439136505\n",
      "Batch 527\n",
      "Loss for Batch(527): 0.007954569533467293\n",
      "Batch 528\n",
      "Loss for Batch(528): 0.09158905595541\n",
      "Batch 529\n",
      "Loss for Batch(529): 0.007447243668138981\n",
      "Batch 530\n",
      "Loss for Batch(530): 0.38437458872795105\n",
      "Batch 531\n",
      "Loss for Batch(531): 0.04204411804676056\n",
      "Batch 532\n",
      "Loss for Batch(532): 0.028438780456781387\n",
      "Batch 533\n",
      "Loss for Batch(533): 0.0020266310311853886\n",
      "Batch 534\n",
      "Loss for Batch(534): 0.06852816045284271\n",
      "Batch 535\n",
      "Loss for Batch(535): 0.0017051888862624764\n",
      "Batch 536\n",
      "Loss for Batch(536): 0.0010125467088073492\n",
      "Batch 537\n",
      "Loss for Batch(537): 0.15900801122188568\n",
      "Batch 538\n",
      "Loss for Batch(538): 0.00149779103230685\n",
      "Batch 539\n",
      "Loss for Batch(539): 0.15149514377117157\n",
      "Batch 540\n",
      "Loss for Batch(540): 0.08987942337989807\n",
      "Batch 541\n",
      "Loss for Batch(541): 0.0052468134090304375\n",
      "Batch 542\n",
      "Loss for Batch(542): 0.00328312860801816\n",
      "Batch 543\n",
      "Loss for Batch(543): 0.0025574243627488613\n",
      "Batch 544\n",
      "Loss for Batch(544): 0.20674975216388702\n",
      "Batch 545\n",
      "Loss for Batch(545): 0.015264613553881645\n",
      "Batch 546\n",
      "Loss for Batch(546): 0.008821274153888226\n",
      "Batch 547\n",
      "Loss for Batch(547): 0.0009922171011567116\n",
      "Batch 548\n",
      "Loss for Batch(548): 0.07517378032207489\n",
      "Batch 549\n",
      "Loss for Batch(549): 0.07416676729917526\n",
      "Batch 550\n",
      "Loss for Batch(550): 0.00041242112638428807\n",
      "Batch 551\n",
      "Loss for Batch(551): 0.014871599152684212\n",
      "Batch 552\n",
      "Loss for Batch(552): 0.002612966112792492\n",
      "Batch 553\n",
      "Loss for Batch(553): 0.004681073594838381\n",
      "Batch 554\n",
      "Loss for Batch(554): 0.001993432641029358\n",
      "Batch 555\n",
      "Loss for Batch(555): 0.00884309783577919\n",
      "Batch 556\n",
      "Loss for Batch(556): 0.08455996960401535\n",
      "Batch 557\n",
      "Loss for Batch(557): 0.0176340751349926\n",
      "Batch 558\n",
      "Loss for Batch(558): 0.0008469691383652389\n",
      "Batch 559\n",
      "Loss for Batch(559): 0.009439535439014435\n",
      "Batch 560\n",
      "Loss for Batch(560): 0.06397414207458496\n",
      "Batch 561\n",
      "Loss for Batch(561): 0.014640256762504578\n",
      "Batch 562\n",
      "Loss for Batch(562): 0.08675384521484375\n",
      "Batch 563\n",
      "Loss for Batch(563): 0.0011078383540734649\n",
      "Batch 564\n",
      "Loss for Batch(564): 0.0008845066768117249\n",
      "Batch 565\n",
      "Loss for Batch(565): 0.01975959911942482\n",
      "Batch 566\n",
      "Loss for Batch(566): 0.00020414701430127025\n",
      "Batch 567\n",
      "Loss for Batch(567): 0.18292544782161713\n",
      "Batch 568\n",
      "Loss for Batch(568): 0.00015220543718896806\n",
      "Batch 569\n",
      "Loss for Batch(569): 0.011899624951183796\n",
      "Batch 570\n",
      "Loss for Batch(570): 0.007854815572500229\n",
      "Batch 571\n",
      "Loss for Batch(571): 0.009282169863581657\n",
      "Batch 572\n",
      "Loss for Batch(572): 0.8259683847427368\n",
      "Batch 573\n",
      "Loss for Batch(573): 0.007382477633655071\n",
      "Batch 574\n",
      "Loss for Batch(574): 0.06449631601572037\n",
      "Batch 575\n",
      "Loss for Batch(575): 0.3013617694377899\n",
      "Batch 576\n",
      "Loss for Batch(576): 0.02591966837644577\n",
      "Batch 577\n",
      "Loss for Batch(577): 0.002722545526921749\n",
      "Batch 578\n",
      "Loss for Batch(578): 0.010024062357842922\n",
      "Batch 579\n",
      "Loss for Batch(579): 0.024933114647865295\n",
      "Batch 580\n",
      "Loss for Batch(580): 0.003083862131461501\n",
      "Batch 581\n",
      "Loss for Batch(581): 0.06479453295469284\n",
      "Batch 582\n",
      "Loss for Batch(582): 0.021598491817712784\n",
      "Batch 583\n",
      "Loss for Batch(583): 0.6329821944236755\n",
      "Batch 584\n",
      "Loss for Batch(584): 0.004912474658340216\n",
      "Batch 585\n",
      "Loss for Batch(585): 0.0007698724512010813\n",
      "Batch 586\n",
      "Loss for Batch(586): 0.05975170433521271\n",
      "Batch 587\n",
      "Loss for Batch(587): 0.0014503400307148695\n",
      "Batch 588\n",
      "Loss for Batch(588): 0.031793370842933655\n",
      "Batch 589\n",
      "Loss for Batch(589): 0.00010637232480803505\n",
      "Batch 590\n",
      "Loss for Batch(590): 0.010537472553551197\n",
      "Batch 591\n",
      "Loss for Batch(591): 0.1664724200963974\n",
      "Batch 592\n",
      "Loss for Batch(592): 0.3248617649078369\n",
      "Batch 593\n",
      "Loss for Batch(593): 0.5270407199859619\n",
      "Batch 594\n",
      "Loss for Batch(594): 0.008949555456638336\n",
      "Batch 595\n",
      "Loss for Batch(595): 0.000396112009184435\n",
      "Batch 596\n",
      "Loss for Batch(596): 0.0048539526760578156\n",
      "Batch 597\n",
      "Loss for Batch(597): 6.499457958852872e-05\n",
      "Batch 598\n",
      "Loss for Batch(598): 0.031168954446911812\n",
      "Batch 599\n",
      "Loss for Batch(599): 0.040952470153570175\n",
      "Batch 600\n",
      "Loss for Batch(600): 0.008732776157557964\n",
      "Batch 601\n",
      "Loss for Batch(601): 0.014384115114808083\n",
      "Batch 602\n",
      "Loss for Batch(602): 0.13933412730693817\n",
      "Batch 603\n",
      "Loss for Batch(603): 0.04398227855563164\n",
      "Batch 604\n",
      "Loss for Batch(604): 0.024238377809524536\n",
      "Batch 605\n",
      "Loss for Batch(605): 0.062451623380184174\n",
      "Batch 606\n",
      "Loss for Batch(606): 0.07897834479808807\n",
      "Batch 607\n",
      "Loss for Batch(607): 0.005968814715743065\n",
      "Batch 608\n",
      "Loss for Batch(608): 0.0866580456495285\n",
      "Batch 609\n",
      "Loss for Batch(609): 0.0011956131784245372\n",
      "Batch 610\n",
      "Loss for Batch(610): 0.002805188065394759\n",
      "Batch 611\n",
      "Loss for Batch(611): 0.007873020134866238\n",
      "Batch 612\n",
      "Loss for Batch(612): 0.0004323118191678077\n",
      "Batch 613\n",
      "Loss for Batch(613): 0.030527452006936073\n",
      "Batch 614\n",
      "Loss for Batch(614): 0.0002718163887038827\n",
      "Batch 615\n",
      "Loss for Batch(615): 0.11895324289798737\n",
      "Batch 616\n",
      "Loss for Batch(616): 0.01079699769616127\n",
      "Batch 617\n",
      "Loss for Batch(617): 0.002410966670140624\n",
      "Batch 618\n",
      "Loss for Batch(618): 0.006204487290233374\n",
      "Batch 619\n",
      "Loss for Batch(619): 0.15275193750858307\n",
      "Batch 620\n",
      "Loss for Batch(620): 0.015360158868134022\n",
      "Batch 621\n",
      "Loss for Batch(621): 0.0028664523269981146\n",
      "Batch 622\n",
      "Loss for Batch(622): 0.0031292124185711145\n",
      "Batch 623\n",
      "Loss for Batch(623): 0.00043806235771626234\n",
      "Batch 624\n",
      "Loss for Batch(624): 0.0034870593808591366\n",
      "Batch 625\n",
      "Loss for Batch(625): 0.09486668556928635\n",
      "Batch 626\n",
      "Loss for Batch(626): 0.0016858808230608702\n",
      "Batch 627\n",
      "Loss for Batch(627): 0.0658862516283989\n",
      "Batch 628\n",
      "Loss for Batch(628): 0.00974140502512455\n",
      "Batch 629\n",
      "Loss for Batch(629): 0.05335480347275734\n",
      "Batch 630\n",
      "Loss for Batch(630): 0.04064583033323288\n",
      "Batch 631\n",
      "Loss for Batch(631): 0.010635863058269024\n",
      "Batch 632\n",
      "Loss for Batch(632): 0.0003407838521525264\n",
      "Batch 633\n",
      "Loss for Batch(633): 0.01896797865629196\n",
      "Batch 634\n",
      "Loss for Batch(634): 0.02816089615225792\n",
      "Batch 635\n",
      "Loss for Batch(635): 0.09131335467100143\n",
      "Batch 636\n",
      "Loss for Batch(636): 0.09692639857530594\n",
      "Batch 637\n",
      "Loss for Batch(637): 0.029011785984039307\n",
      "Batch 638\n",
      "Loss for Batch(638): 0.0003880751319229603\n",
      "Batch 639\n",
      "Loss for Batch(639): 0.01697631925344467\n",
      "Batch 640\n",
      "Loss for Batch(640): 0.003213857300579548\n",
      "Batch 641\n",
      "Loss for Batch(641): 0.0006885943585075438\n",
      "Batch 642\n",
      "Loss for Batch(642): 0.006893736310303211\n",
      "Batch 643\n",
      "Loss for Batch(643): 0.011442087590694427\n",
      "Batch 644\n",
      "Loss for Batch(644): 0.004338789265602827\n",
      "Batch 645\n",
      "Loss for Batch(645): 0.008730549365282059\n",
      "Batch 646\n",
      "Loss for Batch(646): 0.07924099266529083\n",
      "Batch 647\n",
      "Loss for Batch(647): 0.04244692251086235\n",
      "Batch 648\n",
      "Loss for Batch(648): 0.1339847594499588\n",
      "Batch 649\n",
      "Loss for Batch(649): 0.036845266819000244\n",
      "Batch 650\n",
      "Loss for Batch(650): 0.023708907887339592\n",
      "Batch 651\n",
      "Loss for Batch(651): 0.04896217957139015\n",
      "Batch 652\n",
      "Loss for Batch(652): 0.010791325010359287\n",
      "Batch 653\n",
      "Loss for Batch(653): 0.07339894771575928\n",
      "Batch 654\n",
      "Loss for Batch(654): 0.013147247955203056\n",
      "Batch 655\n",
      "Loss for Batch(655): 0.014796673320233822\n",
      "Batch 656\n",
      "Loss for Batch(656): 0.3922262489795685\n",
      "Batch 657\n",
      "Loss for Batch(657): 0.12160101532936096\n",
      "Batch 658\n",
      "Loss for Batch(658): 0.025470562279224396\n",
      "Batch 659\n",
      "Loss for Batch(659): 0.011329969391226768\n",
      "Batch 660\n",
      "Loss for Batch(660): 0.1137695237994194\n",
      "Batch 661\n",
      "Loss for Batch(661): 0.07211393117904663\n",
      "Batch 662\n",
      "Loss for Batch(662): 0.6077103018760681\n",
      "Batch 663\n",
      "Loss for Batch(663): 0.0020173361990600824\n",
      "Batch 664\n",
      "Loss for Batch(664): 0.3663212060928345\n",
      "Batch 665\n",
      "Loss for Batch(665): 0.00047301186714321375\n",
      "Batch 666\n",
      "Loss for Batch(666): 0.0014776700409129262\n",
      "Batch 667\n",
      "Loss for Batch(667): 0.00041692800004966557\n",
      "Batch 668\n",
      "Loss for Batch(668): 0.0070599718019366264\n",
      "Batch 669\n",
      "Loss for Batch(669): 0.011929308995604515\n",
      "Batch 670\n",
      "Loss for Batch(670): 2.1546726202359423e-05\n",
      "Batch 671\n",
      "Loss for Batch(671): 0.0005800143699161708\n",
      "Batch 672\n",
      "Loss for Batch(672): 0.07087242603302002\n",
      "Batch 673\n",
      "Loss for Batch(673): 0.07621083408594131\n",
      "Batch 674\n",
      "Loss for Batch(674): 0.21087798476219177\n",
      "Batch 675\n",
      "Loss for Batch(675): 0.004092858172953129\n",
      "Batch 676\n",
      "Loss for Batch(676): 0.002977908356115222\n",
      "Batch 677\n",
      "Loss for Batch(677): 0.02313309535384178\n",
      "Batch 678\n",
      "Loss for Batch(678): 0.03514993190765381\n",
      "Batch 679\n",
      "Loss for Batch(679): 0.0030735579784959555\n",
      "Batch 680\n",
      "Loss for Batch(680): 0.02262674644589424\n",
      "Batch 681\n",
      "Loss for Batch(681): 0.04095841199159622\n",
      "Batch 682\n",
      "Loss for Batch(682): 0.00196636188775301\n",
      "Batch 683\n",
      "Loss for Batch(683): 0.009605204686522484\n",
      "Batch 684\n",
      "Loss for Batch(684): 0.20851892232894897\n",
      "Batch 685\n",
      "Loss for Batch(685): 0.03385147824883461\n",
      "Batch 686\n",
      "Loss for Batch(686): 0.006506579462438822\n",
      "Batch 687\n",
      "Loss for Batch(687): 0.05991359055042267\n",
      "Batch 688\n",
      "Loss for Batch(688): 0.008098488673567772\n",
      "Batch 689\n",
      "Loss for Batch(689): 0.03550301119685173\n",
      "Batch 690\n",
      "Loss for Batch(690): 0.05928964912891388\n",
      "Batch 691\n",
      "Loss for Batch(691): 0.00502936914563179\n",
      "Batch 692\n",
      "Loss for Batch(692): 0.0017668603686615825\n",
      "Batch 693\n",
      "Loss for Batch(693): 0.01328884158283472\n",
      "Batch 694\n",
      "Loss for Batch(694): 0.002460595453158021\n",
      "Batch 695\n",
      "Loss for Batch(695): 0.00016890386177692562\n",
      "Batch 696\n",
      "Loss for Batch(696): 0.10199850052595139\n",
      "Batch 697\n",
      "Loss for Batch(697): 0.03325709328055382\n",
      "Batch 698\n",
      "Loss for Batch(698): 0.04099871963262558\n",
      "Batch 699\n",
      "Loss for Batch(699): 0.022262481972575188\n",
      "Batch 700\n",
      "Loss for Batch(700): 0.05853516608476639\n",
      "Batch 701\n",
      "Loss for Batch(701): 0.0010283320443704724\n",
      "Batch 702\n",
      "Loss for Batch(702): 0.006374398712068796\n",
      "Batch 703\n",
      "Loss for Batch(703): 0.03755776956677437\n",
      "Batch 704\n",
      "Loss for Batch(704): 0.002742051612585783\n",
      "Batch 705\n",
      "Loss for Batch(705): 0.016593877226114273\n",
      "Batch 706\n",
      "Loss for Batch(706): 0.01853669434785843\n",
      "Batch 707\n",
      "Loss for Batch(707): 0.05718231946229935\n",
      "Batch 708\n",
      "Loss for Batch(708): 0.0070703234523534775\n",
      "Batch 709\n",
      "Loss for Batch(709): 0.012897362932562828\n",
      "Batch 710\n",
      "Loss for Batch(710): 0.0006369545008055866\n",
      "Batch 711\n",
      "Loss for Batch(711): 0.005947482772171497\n",
      "Batch 712\n",
      "Loss for Batch(712): 0.0025402328465133905\n",
      "Batch 713\n",
      "Loss for Batch(713): 0.038548193871974945\n",
      "Batch 714\n",
      "Loss for Batch(714): 0.0016691610217094421\n",
      "Batch 715\n",
      "Loss for Batch(715): 0.004760629031807184\n",
      "Batch 716\n",
      "Loss for Batch(716): 0.0036704123485833406\n",
      "Batch 717\n",
      "Loss for Batch(717): 0.007820980623364449\n",
      "Batch 718\n",
      "Loss for Batch(718): 0.00930317398160696\n",
      "Batch 719\n",
      "Loss for Batch(719): 0.018974818289279938\n",
      "Batch 720\n",
      "Loss for Batch(720): 0.09978599846363068\n",
      "Batch 721\n",
      "Loss for Batch(721): 0.4171653687953949\n",
      "Batch 722\n",
      "Loss for Batch(722): 0.10646606236696243\n",
      "Batch 723\n",
      "Loss for Batch(723): 0.06295688450336456\n",
      "Batch 724\n",
      "Loss for Batch(724): 0.01944415457546711\n",
      "Batch 725\n",
      "Loss for Batch(725): 0.16482946276664734\n",
      "Batch 726\n",
      "Loss for Batch(726): 0.21233892440795898\n",
      "Batch 727\n",
      "Loss for Batch(727): 0.049157559871673584\n",
      "Batch 728\n",
      "Loss for Batch(728): 0.06020483374595642\n",
      "Batch 729\n",
      "Loss for Batch(729): 0.028133738785982132\n",
      "Batch 730\n",
      "Loss for Batch(730): 0.00021601087064482272\n",
      "Batch 731\n",
      "Loss for Batch(731): 0.07034745812416077\n",
      "Batch 732\n",
      "Loss for Batch(732): 0.08029871433973312\n",
      "Batch 733\n",
      "Loss for Batch(733): 0.0013505460228770971\n",
      "Batch 734\n",
      "Loss for Batch(734): 0.1425449401140213\n",
      "Batch 735\n",
      "Loss for Batch(735): 0.013660161755979061\n",
      "Batch 736\n",
      "Loss for Batch(736): 0.0473385751247406\n",
      "Batch 737\n",
      "Loss for Batch(737): 0.02303418703377247\n",
      "Batch 738\n",
      "Loss for Batch(738): 0.08256299793720245\n",
      "Batch 739\n",
      "Loss for Batch(739): 0.16386091709136963\n",
      "Batch 740\n",
      "Loss for Batch(740): 0.0011101687559857965\n",
      "Batch 741\n",
      "Loss for Batch(741): 0.003912679385393858\n",
      "Batch 742\n",
      "Loss for Batch(742): 0.4173485040664673\n",
      "Batch 743\n",
      "Loss for Batch(743): 0.004442953504621983\n",
      "Batch 744\n",
      "Loss for Batch(744): 0.016415098682045937\n",
      "Batch 745\n",
      "Loss for Batch(745): 0.31580498814582825\n",
      "Batch 746\n",
      "Loss for Batch(746): 0.002233710139989853\n",
      "Batch 747\n",
      "Loss for Batch(747): 0.033213160932064056\n",
      "Batch 748\n",
      "Loss for Batch(748): 0.008123373612761497\n",
      "Batch 749\n",
      "Loss for Batch(749): 0.0016308216145262122\n",
      "Batch 750\n",
      "Loss for Batch(750): 0.00031510263215750456\n",
      "Batch 751\n",
      "Loss for Batch(751): 0.0012907077325507998\n",
      "Batch 752\n",
      "Loss for Batch(752): 0.02463800460100174\n",
      "Batch 753\n",
      "Loss for Batch(753): 8.583032467868179e-06\n",
      "Avg Loss for 754 Batches0.04809670300283455\n",
      "Epoch(100) Finished\n",
      "**********************************************\n",
      "Avg Test Loss:\n",
      "0.21452693307573478\n",
      "Test Accuracy:\n",
      "0.9322709163346613\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "train_loss, test_loss, test_acc=linear_helper_model.Train_FC_CNN(Linear_model, train_loader,test_loader, optimizer, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCVdY7I5OeuW"
   },
   "source": [
    "# Plot Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "zMcYa81SMWuw",
    "outputId": "cefaa72b-efff-441d-a231-a050ee4a3dbc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_helper_model.plot_loss(train_loss,\"Training Loss\",100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hL5g2pu5OqvF"
   },
   "source": [
    "# Plot Testing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "un3-y9PpOnNw",
    "outputId": "6e39ec28-d516-4d88-9a50-14fa9b424734"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_helper_model.plot_loss(test_loss,\"Testing Loss\",100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghratYEHO6tk"
   },
   "source": [
    "# Plot Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "7PQHZBc9Ovp9",
    "outputId": "276a68a7-eeb6-4e7a-ab1c-85b1cb19d591"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_helper_model.plot_loss(test_acc,\"Accuracy\",100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlLK6f87PQdX"
   },
   "source": [
    "# Define CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "u8Zp_s4HPE2Y"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "            super(CNN, self).__init__()\n",
    "            self.CNN_layers=nn.Sequential(\n",
    "            nn.Conv2d(3, 32,kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64,kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),    \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(36864,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4,2)\n",
    "            )\n",
    "            self.cross_entropy = nn.CrossEntropyLoss()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        y_pred=self.CNN_layers(x)\n",
    "        return y_pred\n",
    "\n",
    "    def get_loss(self, y_pred, y_true):\n",
    "        loss=self.cross_entropy(y_pred,y_true)\n",
    "        return loss\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOuuWC2kPcPc"
   },
   "source": [
    "# Print Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJR8dzwkPFED",
    "outputId": "00527039-f711-4050-8cff-31625178c35c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Architecture is:\n",
      "CNN(\n",
      "  (CNN_layers): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Flatten(start_dim=1, end_dim=-1)\n",
      "    (6): Linear(in_features=36864, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=512, out_features=4, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=4, out_features=2, bias=True)\n",
      "  )\n",
      "  (cross_entropy): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "CNN_model=CNN()\n",
    "CNN_model.to(dev)\n",
    "print(\"CNN Architecture is:\")\n",
    "print(CNN_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y21jKY0dPtN-"
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "GSW_nwAEPpQS"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(CNN_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5fZy3LKPygm"
   },
   "source": [
    "# Define Helper function for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "6fJoqV8UPwTv"
   },
   "outputs": [],
   "source": [
    "CNN_helper_model=Helper_FC_CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNT7Lh5AP70M"
   },
   "source": [
    "# Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYnapoUeP5zQ",
    "outputId": "7f043c95-0a35-48a6-bbc2-c521c9fdc649"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "Loss for Batch(530): 0.0009846335742622614\n",
      "Batch 531\n",
      "Loss for Batch(531): 0.0001436028687749058\n",
      "Batch 532\n",
      "Loss for Batch(532): 0.000330987386405468\n",
      "Batch 533\n",
      "Loss for Batch(533): 0.009285702370107174\n",
      "Batch 534\n",
      "Loss for Batch(534): 0.003569025080651045\n",
      "Batch 535\n",
      "Loss for Batch(535): 7.908603583928198e-05\n",
      "Batch 536\n",
      "Loss for Batch(536): 2.3602726287208498e-05\n",
      "Batch 537\n",
      "Loss for Batch(537): 0.002848248230293393\n",
      "Batch 538\n",
      "Loss for Batch(538): 0.0035547472070902586\n",
      "Batch 539\n",
      "Loss for Batch(539): 9.717779903439805e-05\n",
      "Batch 540\n",
      "Loss for Batch(540): 0.0004546456038951874\n",
      "Batch 541\n",
      "Loss for Batch(541): 0.015823468565940857\n",
      "Batch 542\n",
      "Loss for Batch(542): 0.04049414396286011\n",
      "Batch 543\n",
      "Loss for Batch(543): 0.0004077558405697346\n",
      "Batch 544\n",
      "Loss for Batch(544): 0.008921491913497448\n",
      "Batch 545\n",
      "Loss for Batch(545): 0.0946728065609932\n",
      "Batch 546\n",
      "Loss for Batch(546): 5.9988808061461896e-05\n",
      "Batch 547\n",
      "Loss for Batch(547): 0.0005274649010971189\n",
      "Batch 548\n",
      "Loss for Batch(548): 0.029568089172244072\n",
      "Batch 549\n",
      "Loss for Batch(549): 0.18509714305400848\n",
      "Batch 550\n",
      "Loss for Batch(550): 0.054421234875917435\n",
      "Batch 551\n",
      "Loss for Batch(551): 3.126083902316168e-05\n",
      "Batch 552\n",
      "Loss for Batch(552): 0.0017381071811541915\n",
      "Batch 553\n",
      "Loss for Batch(553): 0.00042753087473101914\n",
      "Batch 554\n",
      "Loss for Batch(554): 0.0015078787691891193\n",
      "Batch 555\n",
      "Loss for Batch(555): 0.0031081498600542545\n",
      "Batch 556\n",
      "Loss for Batch(556): 0.00033526011975482106\n",
      "Batch 557\n",
      "Loss for Batch(557): 0.02084042690694332\n",
      "Batch 558\n",
      "Loss for Batch(558): 0.004469534382224083\n",
      "Batch 559\n",
      "Loss for Batch(559): 0.001338443486019969\n",
      "Batch 560\n",
      "Loss for Batch(560): 7.497758633689955e-05\n",
      "Batch 561\n",
      "Loss for Batch(561): 0.01090006623417139\n",
      "Batch 562\n",
      "Loss for Batch(562): 0.0007273114169947803\n",
      "Batch 563\n",
      "Loss for Batch(563): 0.0015265654074028134\n",
      "Batch 564\n",
      "Loss for Batch(564): 0.008206971921026707\n",
      "Batch 565\n",
      "Loss for Batch(565): 0.03049522079527378\n",
      "Batch 566\n",
      "Loss for Batch(566): 0.028068769723176956\n",
      "Batch 567\n",
      "Loss for Batch(567): 0.0002339700295124203\n",
      "Batch 568\n",
      "Loss for Batch(568): 0.23363257944583893\n",
      "Batch 569\n",
      "Loss for Batch(569): 0.4176863133907318\n",
      "Batch 570\n",
      "Loss for Batch(570): 0.00011737204476958141\n",
      "Batch 571\n",
      "Loss for Batch(571): 0.004898975603282452\n",
      "Batch 572\n",
      "Loss for Batch(572): 0.010457695461809635\n",
      "Batch 573\n",
      "Loss for Batch(573): 0.002475837944075465\n",
      "Batch 574\n",
      "Loss for Batch(574): 0.01994624361395836\n",
      "Batch 575\n",
      "Loss for Batch(575): 0.09882901608943939\n",
      "Batch 576\n",
      "Loss for Batch(576): 0.004200132098048925\n",
      "Batch 577\n",
      "Loss for Batch(577): 0.02889084257185459\n",
      "Batch 578\n",
      "Loss for Batch(578): 0.0001897454058052972\n",
      "Batch 579\n",
      "Loss for Batch(579): 0.002139020012691617\n",
      "Batch 580\n",
      "Loss for Batch(580): 0.01048973761498928\n",
      "Batch 581\n",
      "Loss for Batch(581): 0.0008793065208010375\n",
      "Batch 582\n",
      "Loss for Batch(582): 0.04002610221505165\n",
      "Batch 583\n",
      "Loss for Batch(583): 0.00013546604895964265\n",
      "Batch 584\n",
      "Loss for Batch(584): 0.008096706122159958\n",
      "Batch 585\n",
      "Loss for Batch(585): 0.11577549576759338\n",
      "Batch 586\n",
      "Loss for Batch(586): 0.008432498201727867\n",
      "Batch 587\n",
      "Loss for Batch(587): 0.05377243831753731\n",
      "Batch 588\n",
      "Loss for Batch(588): 0.11817815899848938\n",
      "Batch 589\n",
      "Loss for Batch(589): 0.016311589628458023\n",
      "Batch 590\n",
      "Loss for Batch(590): 0.002710215514525771\n",
      "Batch 591\n",
      "Loss for Batch(591): 0.00022799833095632493\n",
      "Batch 592\n",
      "Loss for Batch(592): 0.00010414616554044187\n",
      "Batch 593\n",
      "Loss for Batch(593): 0.00973859429359436\n",
      "Batch 594\n",
      "Loss for Batch(594): 0.014595504850149155\n",
      "Batch 595\n",
      "Loss for Batch(595): 0.0008236243156716228\n",
      "Batch 596\n",
      "Loss for Batch(596): 0.00021426314197015017\n",
      "Batch 597\n",
      "Loss for Batch(597): 0.043531809002161026\n",
      "Batch 598\n",
      "Loss for Batch(598): 0.012857809662818909\n",
      "Batch 599\n",
      "Loss for Batch(599): 1.248704211320728e-05\n",
      "Batch 600\n",
      "Loss for Batch(600): 0.0028284182772040367\n",
      "Batch 601\n",
      "Loss for Batch(601): 0.0008368797716684639\n",
      "Batch 602\n",
      "Loss for Batch(602): 0.0008484364370815456\n",
      "Batch 603\n",
      "Loss for Batch(603): 0.0037115218583494425\n",
      "Batch 604\n",
      "Loss for Batch(604): 0.010705607943236828\n",
      "Batch 605\n",
      "Loss for Batch(605): 0.01755976863205433\n",
      "Batch 606\n",
      "Loss for Batch(606): 0.0029577985405921936\n",
      "Batch 607\n",
      "Loss for Batch(607): 0.02345510572195053\n",
      "Batch 608\n",
      "Loss for Batch(608): 0.003041170071810484\n",
      "Batch 609\n",
      "Loss for Batch(609): 0.004081037826836109\n",
      "Batch 610\n",
      "Loss for Batch(610): 0.011137164197862148\n",
      "Batch 611\n",
      "Loss for Batch(611): 5.08411685586907e-05\n",
      "Batch 612\n",
      "Loss for Batch(612): 0.0015539830783382058\n",
      "Batch 613\n",
      "Loss for Batch(613): 2.2410647943615913e-05\n",
      "Batch 614\n",
      "Loss for Batch(614): 9.31854301597923e-05\n",
      "Batch 615\n",
      "Loss for Batch(615): 0.00034377153497189283\n",
      "Batch 616\n",
      "Loss for Batch(616): 0.008566093631088734\n",
      "Batch 617\n",
      "Loss for Batch(617): 0.0072371745482087135\n",
      "Batch 618\n",
      "Loss for Batch(618): 0.0058909528888762\n",
      "Batch 619\n",
      "Loss for Batch(619): 5.5608103139093146e-05\n",
      "Batch 620\n",
      "Loss for Batch(620): 0.037333108484745026\n",
      "Batch 621\n",
      "Loss for Batch(621): 0.008626902475953102\n",
      "Batch 622\n",
      "Loss for Batch(622): 0.0014811959117650986\n",
      "Batch 623\n",
      "Loss for Batch(623): 0.031242091208696365\n",
      "Batch 624\n",
      "Loss for Batch(624): 0.0015989132225513458\n",
      "Batch 625\n",
      "Loss for Batch(625): 5.2509109082166106e-05\n",
      "Batch 626\n",
      "Loss for Batch(626): 0.003413570113480091\n",
      "Batch 627\n",
      "Loss for Batch(627): 0.010669257491827011\n",
      "Batch 628\n",
      "Loss for Batch(628): 0.013030336238443851\n",
      "Batch 629\n",
      "Loss for Batch(629): 0.0004440360935404897\n",
      "Batch 630\n",
      "Loss for Batch(630): 0.003498977515846491\n",
      "Batch 631\n",
      "Loss for Batch(631): 0.022631660103797913\n",
      "Batch 632\n",
      "Loss for Batch(632): 0.026847224682569504\n",
      "Batch 633\n",
      "Loss for Batch(633): 0.004137205425649881\n",
      "Batch 634\n",
      "Loss for Batch(634): 0.00010206572187598795\n",
      "Batch 635\n",
      "Loss for Batch(635): 0.0005294771399348974\n",
      "Batch 636\n",
      "Loss for Batch(636): 0.31597399711608887\n",
      "Batch 637\n",
      "Loss for Batch(637): 0.011763360351324081\n",
      "Batch 638\n",
      "Loss for Batch(638): 0.11940939724445343\n",
      "Batch 639\n",
      "Loss for Batch(639): 0.004976971540600061\n",
      "Batch 640\n",
      "Loss for Batch(640): 0.8257425427436829\n",
      "Batch 641\n",
      "Loss for Batch(641): 3.0367571525857784e-05\n",
      "Batch 642\n",
      "Loss for Batch(642): 0.0008184912148863077\n",
      "Batch 643\n",
      "Loss for Batch(643): 0.0013376582646742463\n",
      "Batch 644\n",
      "Loss for Batch(644): 0.005588296335190535\n",
      "Batch 645\n",
      "Loss for Batch(645): 0.0013258112594485283\n",
      "Batch 646\n",
      "Loss for Batch(646): 0.003622826188802719\n",
      "Batch 647\n",
      "Loss for Batch(647): 0.17593127489089966\n",
      "Batch 648\n",
      "Loss for Batch(648): 0.0032683787867426872\n",
      "Batch 649\n",
      "Loss for Batch(649): 0.0007803459884598851\n",
      "Batch 650\n",
      "Loss for Batch(650): 0.00020792918803635985\n",
      "Batch 651\n",
      "Loss for Batch(651): 0.0010102667147293687\n",
      "Batch 652\n",
      "Loss for Batch(652): 0.10679847747087479\n",
      "Batch 653\n",
      "Loss for Batch(653): 0.0004429892578627914\n",
      "Batch 654\n",
      "Loss for Batch(654): 0.011033879593014717\n",
      "Batch 655\n",
      "Loss for Batch(655): 0.03304501622915268\n",
      "Batch 656\n",
      "Loss for Batch(656): 0.11043359339237213\n",
      "Batch 657\n",
      "Loss for Batch(657): 0.015792395919561386\n",
      "Batch 658\n",
      "Loss for Batch(658): 0.0036706088576465845\n",
      "Batch 659\n",
      "Loss for Batch(659): 0.05101340264081955\n",
      "Batch 660\n",
      "Loss for Batch(660): 0.01814245618879795\n",
      "Batch 661\n",
      "Loss for Batch(661): 0.001134410034865141\n",
      "Batch 662\n",
      "Loss for Batch(662): 0.004304285626858473\n",
      "Batch 663\n",
      "Loss for Batch(663): 0.001003130804747343\n",
      "Batch 664\n",
      "Loss for Batch(664): 0.00010957122140098363\n",
      "Batch 665\n",
      "Loss for Batch(665): 0.0006275250343605876\n",
      "Batch 666\n",
      "Loss for Batch(666): 0.05858886241912842\n",
      "Batch 667\n",
      "Loss for Batch(667): 0.007869383320212364\n",
      "Batch 668\n",
      "Loss for Batch(668): 7.122712304408196e-06\n",
      "Batch 669\n",
      "Loss for Batch(669): 8.977901597972959e-05\n",
      "Batch 670\n",
      "Loss for Batch(670): 0.1838410645723343\n",
      "Batch 671\n",
      "Loss for Batch(671): 6.266977288760245e-05\n",
      "Batch 672\n",
      "Loss for Batch(672): 0.00041531038004904985\n",
      "Batch 673\n",
      "Loss for Batch(673): 0.01632998324930668\n",
      "Batch 674\n",
      "Loss for Batch(674): 0.0018417908577248454\n",
      "Batch 675\n",
      "Loss for Batch(675): 0.0006738835945725441\n",
      "Batch 676\n",
      "Loss for Batch(676): 0.03745178505778313\n",
      "Batch 677\n",
      "Loss for Batch(677): 0.07764984667301178\n",
      "Batch 678\n",
      "Loss for Batch(678): 0.03791658952832222\n",
      "Batch 679\n",
      "Loss for Batch(679): 0.019626546651124954\n",
      "Batch 680\n",
      "Loss for Batch(680): 0.005074055399745703\n",
      "Batch 681\n",
      "Loss for Batch(681): 0.010276641696691513\n",
      "Batch 682\n",
      "Loss for Batch(682): 0.301586389541626\n",
      "Batch 683\n",
      "Loss for Batch(683): 0.024606142193078995\n",
      "Batch 684\n",
      "Loss for Batch(684): 0.02196342684328556\n",
      "Batch 685\n",
      "Loss for Batch(685): 0.013817870989441872\n",
      "Batch 686\n",
      "Loss for Batch(686): 0.28037846088409424\n",
      "Batch 687\n",
      "Loss for Batch(687): 0.3197762668132782\n",
      "Batch 688\n",
      "Loss for Batch(688): 0.028621112927794456\n",
      "Batch 689\n",
      "Loss for Batch(689): 0.1610674113035202\n",
      "Batch 690\n",
      "Loss for Batch(690): 0.010572127066552639\n",
      "Batch 691\n",
      "Loss for Batch(691): 0.0010538059286773205\n",
      "Batch 692\n",
      "Loss for Batch(692): 0.0005692528793588281\n",
      "Batch 693\n",
      "Loss for Batch(693): 0.007072987034916878\n",
      "Batch 694\n",
      "Loss for Batch(694): 0.005114161875098944\n",
      "Batch 695\n",
      "Loss for Batch(695): 0.0032360085751861334\n",
      "Batch 696\n",
      "Loss for Batch(696): 0.0026707560755312443\n",
      "Batch 697\n",
      "Loss for Batch(697): 0.0019526826217770576\n",
      "Batch 698\n",
      "Loss for Batch(698): 0.003898041322827339\n",
      "Batch 699\n",
      "Loss for Batch(699): 0.023246867582201958\n",
      "Batch 700\n",
      "Loss for Batch(700): 0.038265567272901535\n",
      "Batch 701\n",
      "Loss for Batch(701): 0.06572404503822327\n",
      "Batch 702\n",
      "Loss for Batch(702): 0.0028486864175647497\n",
      "Batch 703\n",
      "Loss for Batch(703): 0.05324740335345268\n",
      "Batch 704\n",
      "Loss for Batch(704): 0.0006017776322551072\n",
      "Batch 705\n",
      "Loss for Batch(705): 0.0012521441094577312\n",
      "Batch 706\n",
      "Loss for Batch(706): 0.0004582176625262946\n",
      "Batch 707\n",
      "Loss for Batch(707): 0.001126041985116899\n",
      "Batch 708\n",
      "Loss for Batch(708): 0.019405528903007507\n",
      "Batch 709\n",
      "Loss for Batch(709): 0.0009413445368409157\n",
      "Batch 710\n",
      "Loss for Batch(710): 0.00011978149996139109\n",
      "Batch 711\n",
      "Loss for Batch(711): 0.00037280534161254764\n",
      "Batch 712\n",
      "Loss for Batch(712): 0.0028346856124699116\n",
      "Batch 713\n",
      "Loss for Batch(713): 0.0022620020899921656\n",
      "Batch 714\n",
      "Loss for Batch(714): 0.0005176572594791651\n",
      "Batch 715\n",
      "Loss for Batch(715): 0.0011359265772625804\n",
      "Batch 716\n",
      "Loss for Batch(716): 0.030208637937903404\n",
      "Batch 717\n",
      "Loss for Batch(717): 0.0757744237780571\n",
      "Batch 718\n",
      "Loss for Batch(718): 0.004109645262360573\n",
      "Batch 719\n",
      "Loss for Batch(719): 0.11841383576393127\n",
      "Batch 720\n",
      "Loss for Batch(720): 0.0007746872724965215\n",
      "Batch 721\n",
      "Loss for Batch(721): 0.04412056505680084\n",
      "Batch 722\n",
      "Loss for Batch(722): 0.0004515057080425322\n",
      "Batch 723\n",
      "Loss for Batch(723): 0.001382949179969728\n",
      "Batch 724\n",
      "Loss for Batch(724): 0.005841582547873259\n",
      "Batch 725\n",
      "Loss for Batch(725): 0.028677646070718765\n",
      "Batch 726\n",
      "Loss for Batch(726): 0.001120909582823515\n",
      "Batch 727\n",
      "Loss for Batch(727): 7.366509089479223e-05\n",
      "Batch 728\n",
      "Loss for Batch(728): 0.0015858658589422703\n",
      "Batch 729\n",
      "Loss for Batch(729): 0.0011393600143492222\n",
      "Batch 730\n",
      "Loss for Batch(730): 0.007163111586123705\n",
      "Batch 731\n",
      "Loss for Batch(731): 0.8566001057624817\n",
      "Batch 732\n",
      "Loss for Batch(732): 0.002021264052018523\n",
      "Batch 733\n",
      "Loss for Batch(733): 0.08634833991527557\n",
      "Batch 734\n",
      "Loss for Batch(734): 0.08730585873126984\n",
      "Batch 735\n",
      "Loss for Batch(735): 0.006744900718331337\n",
      "Batch 736\n",
      "Loss for Batch(736): 0.005206095986068249\n",
      "Batch 737\n",
      "Loss for Batch(737): 0.009123704396188259\n",
      "Batch 738\n",
      "Loss for Batch(738): 0.0021030495408922434\n",
      "Batch 739\n",
      "Loss for Batch(739): 0.0014306495431810617\n",
      "Batch 740\n",
      "Loss for Batch(740): 0.004847451578825712\n",
      "Batch 741\n",
      "Loss for Batch(741): 0.41996482014656067\n",
      "Batch 742\n",
      "Loss for Batch(742): 0.19975128769874573\n",
      "Batch 743\n",
      "Loss for Batch(743): 0.0010301622096449137\n",
      "Batch 744\n",
      "Loss for Batch(744): 6.288013537414372e-05\n",
      "Batch 745\n",
      "Loss for Batch(745): 0.04613617807626724\n",
      "Batch 746\n",
      "Loss for Batch(746): 0.006267722230404615\n",
      "Batch 747\n",
      "Loss for Batch(747): 0.06080413609743118\n",
      "Batch 748\n",
      "Loss for Batch(748): 0.0308080967515707\n",
      "Batch 749\n",
      "Loss for Batch(749): 0.045230306684970856\n",
      "Batch 750\n",
      "Loss for Batch(750): 0.014544036239385605\n",
      "Batch 751\n",
      "Loss for Batch(751): 0.0037297802045941353\n",
      "Batch 752\n",
      "Loss for Batch(752): 0.00029798445757478476\n",
      "Batch 753\n",
      "Loss for Batch(753): 7.056941103655845e-05\n",
      "Avg Loss for 754 Batches0.0267039020969825\n",
      "Epoch(97) Finished\n",
      "**********************************************\n",
      "Avg Test Loss:\n",
      "0.15674596983085176\n",
      "Test Accuracy:\n",
      "0.9455511288180611\n",
      "**********************************************\n",
      "******************Epoch(98):***********************\n",
      "Batch 1\n",
      "Loss for Batch(1): 0.00048826460260897875\n",
      "Batch 2\n",
      "Loss for Batch(2): 0.0020054145716130733\n",
      "Batch 3\n",
      "Loss for Batch(3): 0.0064889611676335335\n",
      "Batch 4\n",
      "Loss for Batch(4): 0.0018196339951828122\n",
      "Batch 5\n",
      "Loss for Batch(5): 0.01191974151879549\n",
      "Batch 6\n",
      "Loss for Batch(6): 0.0009515612036921084\n",
      "Batch 7\n",
      "Loss for Batch(7): 0.00029842177173122764\n",
      "Batch 8\n",
      "Loss for Batch(8): 0.0008159464923664927\n",
      "Batch 9\n",
      "Loss for Batch(9): 0.00482599064707756\n",
      "Batch 10\n",
      "Loss for Batch(10): 0.0001527508720755577\n",
      "Batch 11\n",
      "Loss for Batch(11): 0.025572974234819412\n",
      "Batch 12\n",
      "Loss for Batch(12): 0.0336582250893116\n",
      "Batch 13\n",
      "Loss for Batch(13): 0.006543031893670559\n",
      "Batch 14\n",
      "Loss for Batch(14): 0.00038099486846476793\n",
      "Batch 15\n",
      "Loss for Batch(15): 0.09431251883506775\n",
      "Batch 16\n",
      "Loss for Batch(16): 0.00813007541000843\n",
      "Batch 17\n",
      "Loss for Batch(17): 0.00022274479852057993\n",
      "Batch 18\n",
      "Loss for Batch(18): 0.0001439558545826003\n",
      "Batch 19\n",
      "Loss for Batch(19): 0.05408136919140816\n",
      "Batch 20\n",
      "Loss for Batch(20): 0.01758316345512867\n",
      "Batch 21\n",
      "Loss for Batch(21): 0.31841787695884705\n",
      "Batch 22\n",
      "Loss for Batch(22): 0.013408668339252472\n",
      "Batch 23\n",
      "Loss for Batch(23): 4.85463606310077e-05\n",
      "Batch 24\n",
      "Loss for Batch(24): 0.07206495106220245\n",
      "Batch 25\n",
      "Loss for Batch(25): 0.19335885345935822\n",
      "Batch 26\n",
      "Loss for Batch(26): 0.0017648086650297046\n",
      "Batch 27\n",
      "Loss for Batch(27): 0.000757065077777952\n",
      "Batch 28\n",
      "Loss for Batch(28): 0.0015595105942338705\n",
      "Batch 29\n",
      "Loss for Batch(29): 0.007028470281511545\n",
      "Batch 30\n",
      "Loss for Batch(30): 0.005201097112149\n",
      "Batch 31\n",
      "Loss for Batch(31): 9.387614227307495e-06\n",
      "Batch 32\n",
      "Loss for Batch(32): 0.000844249443616718\n",
      "Batch 33\n",
      "Loss for Batch(33): 0.0005213544936850667\n",
      "Batch 34\n",
      "Loss for Batch(34): 0.00043223658576607704\n",
      "Batch 35\n",
      "Loss for Batch(35): 0.0014555907109752297\n",
      "Batch 36\n",
      "Loss for Batch(36): 0.0001395099825458601\n",
      "Batch 37\n",
      "Loss for Batch(37): 0.0003551767731551081\n",
      "Batch 38\n",
      "Loss for Batch(38): 0.01673225872218609\n",
      "Batch 39\n",
      "Loss for Batch(39): 0.00042150201625190675\n",
      "Batch 40\n",
      "Loss for Batch(40): 0.0033339622896164656\n",
      "Batch 41\n",
      "Loss for Batch(41): 0.1306701898574829\n",
      "Batch 42\n",
      "Loss for Batch(42): 0.10740591585636139\n",
      "Batch 43\n",
      "Loss for Batch(43): 0.08288940042257309\n",
      "Batch 44\n",
      "Loss for Batch(44): 0.0020676366984844208\n",
      "Batch 45\n",
      "Loss for Batch(45): 0.0014819192001596093\n",
      "Batch 46\n",
      "Loss for Batch(46): 0.009990354999899864\n",
      "Batch 47\n",
      "Loss for Batch(47): 0.0020770635455846786\n",
      "Batch 48\n",
      "Loss for Batch(48): 0.06826195120811462\n",
      "Batch 49\n",
      "Loss for Batch(49): 5.5730019994371105e-06\n",
      "Batch 50\n",
      "Loss for Batch(50): 0.059373240917921066\n",
      "Batch 51\n",
      "Loss for Batch(51): 0.0019497149623930454\n",
      "Batch 52\n",
      "Loss for Batch(52): 0.0016980271320790052\n",
      "Batch 53\n",
      "Loss for Batch(53): 4.529938451014459e-06\n",
      "Batch 54\n",
      "Loss for Batch(54): 1.7672455214778893e-05\n",
      "Batch 55\n",
      "Loss for Batch(55): 0.0003526705550029874\n",
      "Batch 56\n",
      "Loss for Batch(56): 0.0005710344412364066\n",
      "Batch 57\n",
      "Loss for Batch(57): 0.006127578672021627\n",
      "Batch 58\n",
      "Loss for Batch(58): 0.009901552461087704\n",
      "Batch 59\n",
      "Loss for Batch(59): 0.03624627739191055\n",
      "Batch 60\n",
      "Loss for Batch(60): 0.0008323240908794105\n",
      "Batch 61\n",
      "Loss for Batch(61): 0.11866554617881775\n",
      "Batch 62\n",
      "Loss for Batch(62): 0.0001367301301797852\n",
      "Batch 63\n",
      "Loss for Batch(63): 0.02867703139781952\n",
      "Batch 64\n",
      "Loss for Batch(64): 0.00020542381389532238\n",
      "Batch 65\n",
      "Loss for Batch(65): 0.0007148812874220312\n",
      "Batch 66\n",
      "Loss for Batch(66): 0.0009486561757512391\n",
      "Batch 67\n",
      "Loss for Batch(67): 0.003329531755298376\n",
      "Batch 68\n",
      "Loss for Batch(68): 0.010667599737644196\n",
      "Batch 69\n",
      "Loss for Batch(69): 2.5599492801120505e-05\n",
      "Batch 70\n",
      "Loss for Batch(70): 0.019123846665024757\n",
      "Batch 71\n",
      "Loss for Batch(71): 0.07450226694345474\n",
      "Batch 72\n",
      "Loss for Batch(72): 0.002501566894352436\n",
      "Batch 73\n",
      "Loss for Batch(73): 0.013522776775062084\n",
      "Batch 74\n",
      "Loss for Batch(74): 0.008592694066464901\n",
      "Batch 75\n",
      "Loss for Batch(75): 0.0018345499411225319\n",
      "Batch 76\n",
      "Loss for Batch(76): 0.0003639589995145798\n",
      "Batch 77\n",
      "Loss for Batch(77): 6.106161890784279e-05\n",
      "Batch 78\n",
      "Loss for Batch(78): 0.0012094875564798713\n",
      "Batch 79\n",
      "Loss for Batch(79): 0.0021504852920770645\n",
      "Batch 80\n",
      "Loss for Batch(80): 0.062283508479595184\n",
      "Batch 81\n",
      "Loss for Batch(81): 0.013988856226205826\n",
      "Batch 82\n",
      "Loss for Batch(82): 0.018917275592684746\n",
      "Batch 83\n",
      "Loss for Batch(83): 0.023757807910442352\n",
      "Batch 84\n",
      "Loss for Batch(84): 0.024530155584216118\n",
      "Batch 85\n",
      "Loss for Batch(85): 0.000596139463596046\n",
      "Batch 86\n",
      "Loss for Batch(86): 0.0006468913052231073\n",
      "Batch 87\n",
      "Loss for Batch(87): 0.0022348295897245407\n",
      "Batch 88\n",
      "Loss for Batch(88): 0.012599429115653038\n",
      "Batch 89\n",
      "Loss for Batch(89): 0.00039303701487369835\n",
      "Batch 90\n",
      "Loss for Batch(90): 0.06435014307498932\n",
      "Batch 91\n",
      "Loss for Batch(91): 0.025117307901382446\n",
      "Batch 92\n",
      "Loss for Batch(92): 0.0029330714605748653\n",
      "Batch 93\n",
      "Loss for Batch(93): 0.0027794998604804277\n",
      "Batch 94\n",
      "Loss for Batch(94): 0.00041521358070895076\n",
      "Batch 95\n",
      "Loss for Batch(95): 0.01314982958137989\n",
      "Batch 96\n",
      "Loss for Batch(96): 0.007107194978743792\n",
      "Batch 97\n",
      "Loss for Batch(97): 0.019409650936722755\n",
      "Batch 98\n",
      "Loss for Batch(98): 0.0016485735541209579\n",
      "Batch 99\n",
      "Loss for Batch(99): 0.0006100445752963424\n",
      "Batch 100\n",
      "Loss for Batch(100): 0.04625973105430603\n",
      "Batch 101\n",
      "Loss for Batch(101): 0.03139365836977959\n",
      "Batch 102\n",
      "Loss for Batch(102): 0.012746430933475494\n",
      "Batch 103\n",
      "Loss for Batch(103): 0.005836308468133211\n",
      "Batch 104\n",
      "Loss for Batch(104): 0.00301586976274848\n",
      "Batch 105\n",
      "Loss for Batch(105): 0.0031608128920197487\n",
      "Batch 106\n",
      "Loss for Batch(106): 0.11415910720825195\n",
      "Batch 107\n",
      "Loss for Batch(107): 6.305857823463157e-05\n",
      "Batch 108\n",
      "Loss for Batch(108): 0.00016630138270556927\n",
      "Batch 109\n",
      "Loss for Batch(109): 0.0019344424363225698\n",
      "Batch 110\n",
      "Loss for Batch(110): 0.0016755897086113691\n",
      "Batch 111\n",
      "Loss for Batch(111): 1.5288438589777797e-05\n",
      "Batch 112\n",
      "Loss for Batch(112): 0.00011818029452115297\n",
      "Batch 113\n",
      "Loss for Batch(113): 0.07376543432474136\n",
      "Batch 114\n",
      "Loss for Batch(114): 0.005520769394934177\n",
      "Batch 115\n",
      "Loss for Batch(115): 0.0050333840772509575\n",
      "Batch 116\n",
      "Loss for Batch(116): 1.0200318098068237\n",
      "Batch 117\n",
      "Loss for Batch(117): 0.00044108927249908447\n",
      "Batch 118\n",
      "Loss for Batch(118): 0.11153566092252731\n",
      "Batch 119\n",
      "Loss for Batch(119): 0.00818368885666132\n",
      "Batch 120\n",
      "Loss for Batch(120): 0.005865432322025299\n",
      "Batch 121\n",
      "Loss for Batch(121): 0.0017722842749208212\n",
      "Batch 122\n",
      "Loss for Batch(122): 0.011985260993242264\n",
      "Batch 123\n",
      "Loss for Batch(123): 0.00720745837315917\n",
      "Batch 124\n",
      "Loss for Batch(124): 0.0884784534573555\n",
      "Batch 125\n",
      "Loss for Batch(125): 4.553445614874363e-05\n",
      "Batch 126\n",
      "Loss for Batch(126): 0.3939353823661804\n",
      "Batch 127\n",
      "Loss for Batch(127): 0.1261691153049469\n",
      "Batch 128\n",
      "Loss for Batch(128): 0.0065676504746079445\n",
      "Batch 129\n",
      "Loss for Batch(129): 0.05297774076461792\n",
      "Batch 130\n",
      "Loss for Batch(130): 0.27384570240974426\n",
      "Batch 131\n",
      "Loss for Batch(131): 0.08950140327215195\n",
      "Batch 132\n",
      "Loss for Batch(132): 0.0017018665093928576\n",
      "Batch 133\n",
      "Loss for Batch(133): 0.22589078545570374\n",
      "Batch 134\n",
      "Loss for Batch(134): 0.008761980570852757\n",
      "Batch 135\n",
      "Loss for Batch(135): 0.19710806012153625\n",
      "Batch 136\n",
      "Loss for Batch(136): 0.0022832760587334633\n",
      "Batch 137\n",
      "Loss for Batch(137): 0.03593754768371582\n",
      "Batch 138\n",
      "Loss for Batch(138): 0.0041232421062886715\n",
      "Batch 139\n",
      "Loss for Batch(139): 0.012823408469557762\n",
      "Batch 140\n",
      "Loss for Batch(140): 0.008238906040787697\n",
      "Batch 141\n",
      "Loss for Batch(141): 0.02964538149535656\n",
      "Batch 142\n",
      "Loss for Batch(142): 0.004035318735986948\n",
      "Batch 143\n",
      "Loss for Batch(143): 0.002020915737375617\n",
      "Batch 144\n",
      "Loss for Batch(144): 0.006942638196051121\n",
      "Batch 145\n",
      "Loss for Batch(145): 0.012796576134860516\n",
      "Batch 146\n",
      "Loss for Batch(146): 0.001531772781163454\n",
      "Batch 147\n",
      "Loss for Batch(147): 0.006045797374099493\n",
      "Batch 148\n",
      "Loss for Batch(148): 0.0066243731416761875\n",
      "Batch 149\n",
      "Loss for Batch(149): 0.0010006052907556295\n",
      "Batch 150\n",
      "Loss for Batch(150): 0.029786448925733566\n",
      "Batch 151\n",
      "Loss for Batch(151): 0.0001477258192608133\n",
      "Batch 152\n",
      "Loss for Batch(152): 0.00034039682941511273\n",
      "Batch 153\n",
      "Loss for Batch(153): 0.0005457890219986439\n",
      "Batch 154\n",
      "Loss for Batch(154): 0.000277771963737905\n",
      "Batch 155\n",
      "Loss for Batch(155): 0.0056618982926011086\n",
      "Batch 156\n",
      "Loss for Batch(156): 0.014979097992181778\n",
      "Batch 157\n",
      "Loss for Batch(157): 0.004684176761657\n",
      "Batch 158\n",
      "Loss for Batch(158): 0.032326195389032364\n",
      "Batch 159\n",
      "Loss for Batch(159): 0.00022864706988912076\n",
      "Batch 160\n",
      "Loss for Batch(160): 0.030874282121658325\n",
      "Batch 161\n",
      "Loss for Batch(161): 0.00048089379561133683\n",
      "Batch 162\n",
      "Loss for Batch(162): 0.00016401287575718015\n",
      "Batch 163\n",
      "Loss for Batch(163): 0.04405851289629936\n",
      "Batch 164\n",
      "Loss for Batch(164): 0.0013198712840676308\n",
      "Batch 165\n",
      "Loss for Batch(165): 0.016248174011707306\n",
      "Batch 166\n",
      "Loss for Batch(166): 0.0004358437145128846\n",
      "Batch 167\n",
      "Loss for Batch(167): 0.0004643668362405151\n",
      "Batch 168\n",
      "Loss for Batch(168): 0.00012815851368941367\n",
      "Batch 169\n",
      "Loss for Batch(169): 0.0010565649718046188\n",
      "Batch 170\n",
      "Loss for Batch(170): 0.0025819651782512665\n",
      "Batch 171\n",
      "Loss for Batch(171): 0.0017381610814481974\n",
      "Batch 172\n",
      "Loss for Batch(172): 0.0051575833931565285\n",
      "Batch 173\n",
      "Loss for Batch(173): 0.01869324967265129\n",
      "Batch 174\n",
      "Loss for Batch(174): 0.03714174032211304\n",
      "Batch 175\n",
      "Loss for Batch(175): 0.2049320489168167\n",
      "Batch 176\n",
      "Loss for Batch(176): 8.403536776313558e-05\n",
      "Batch 177\n",
      "Loss for Batch(177): 0.03515024855732918\n",
      "Batch 178\n",
      "Loss for Batch(178): 0.00018135472782887518\n",
      "Batch 179\n",
      "Loss for Batch(179): 0.0013300266582518816\n",
      "Batch 180\n",
      "Loss for Batch(180): 0.0010982271051034331\n",
      "Batch 181\n",
      "Loss for Batch(181): 0.053850360214710236\n",
      "Batch 182\n",
      "Loss for Batch(182): 0.00215429556556046\n",
      "Batch 183\n",
      "Loss for Batch(183): 0.007430883124470711\n",
      "Batch 184\n",
      "Loss for Batch(184): 0.0003635490720625967\n",
      "Batch 185\n",
      "Loss for Batch(185): 0.002983432961627841\n",
      "Batch 186\n",
      "Loss for Batch(186): 0.033108241856098175\n",
      "Batch 187\n",
      "Loss for Batch(187): 0.00010420406761113554\n",
      "Batch 188\n",
      "Loss for Batch(188): 0.003283141879364848\n",
      "Batch 189\n",
      "Loss for Batch(189): 0.005351025611162186\n",
      "Batch 190\n",
      "Loss for Batch(190): 0.02518409490585327\n",
      "Batch 191\n",
      "Loss for Batch(191): 0.3775348961353302\n",
      "Batch 192\n",
      "Loss for Batch(192): 0.03164474666118622\n",
      "Batch 193\n",
      "Loss for Batch(193): 0.04353847727179527\n",
      "Batch 194\n",
      "Loss for Batch(194): 0.02407195419073105\n",
      "Batch 195\n",
      "Loss for Batch(195): 0.01233820989727974\n",
      "Batch 196\n",
      "Loss for Batch(196): 0.004132118541747332\n",
      "Batch 197\n",
      "Loss for Batch(197): 0.0026514956261962652\n",
      "Batch 198\n",
      "Loss for Batch(198): 0.045396868139505386\n",
      "Batch 199\n",
      "Loss for Batch(199): 0.002168536651879549\n",
      "Batch 200\n",
      "Loss for Batch(200): 0.06125577539205551\n",
      "Batch 201\n",
      "Loss for Batch(201): 5.882648110855371e-05\n",
      "Batch 202\n",
      "Loss for Batch(202): 0.001127274939790368\n",
      "Batch 203\n",
      "Loss for Batch(203): 0.4383849799633026\n",
      "Batch 204\n",
      "Loss for Batch(204): 0.000753659987822175\n",
      "Batch 205\n",
      "Loss for Batch(205): 0.009187305346131325\n",
      "Batch 206\n",
      "Loss for Batch(206): 1.6599618902546354e-05\n",
      "Batch 207\n",
      "Loss for Batch(207): 0.006339163053780794\n",
      "Batch 208\n",
      "Loss for Batch(208): 0.00939665175974369\n",
      "Batch 209\n",
      "Loss for Batch(209): 0.10808780044317245\n",
      "Batch 210\n",
      "Loss for Batch(210): 0.0050914897583425045\n",
      "Batch 211\n",
      "Loss for Batch(211): 0.16243603825569153\n",
      "Batch 212\n",
      "Loss for Batch(212): 0.04073896259069443\n",
      "Batch 213\n",
      "Loss for Batch(213): 0.055634379386901855\n",
      "Batch 214\n",
      "Loss for Batch(214): 0.005269098095595837\n",
      "Batch 215\n",
      "Loss for Batch(215): 0.003723666537553072\n",
      "Batch 216\n",
      "Loss for Batch(216): 0.0009515921701677144\n",
      "Batch 217\n",
      "Loss for Batch(217): 0.006923801731318235\n",
      "Batch 218\n",
      "Loss for Batch(218): 0.11781659722328186\n",
      "Batch 219\n",
      "Loss for Batch(219): 0.0006915779667906463\n",
      "Batch 220\n",
      "Loss for Batch(220): 0.06135711446404457\n",
      "Batch 221\n",
      "Loss for Batch(221): 0.16748395562171936\n",
      "Batch 222\n",
      "Loss for Batch(222): 0.0024272422306239605\n",
      "Batch 223\n",
      "Loss for Batch(223): 0.03245667368173599\n",
      "Batch 224\n",
      "Loss for Batch(224): 0.0013263728469610214\n",
      "Batch 225\n",
      "Loss for Batch(225): 0.0008640668820589781\n",
      "Batch 226\n",
      "Loss for Batch(226): 0.001786967390216887\n",
      "Batch 227\n",
      "Loss for Batch(227): 0.0024810691829770803\n",
      "Batch 228\n",
      "Loss for Batch(228): 0.00011688837548717856\n",
      "Batch 229\n",
      "Loss for Batch(229): 0.0022994824685156345\n",
      "Batch 230\n",
      "Loss for Batch(230): 0.00029383928631432354\n",
      "Batch 231\n",
      "Loss for Batch(231): 0.0006489051738753915\n",
      "Batch 232\n",
      "Loss for Batch(232): 0.00911095179617405\n",
      "Batch 233\n",
      "Loss for Batch(233): 0.0016345076728612185\n",
      "Batch 234\n",
      "Loss for Batch(234): 0.0004004226066172123\n",
      "Batch 235\n",
      "Loss for Batch(235): 0.0016606716671958566\n",
      "Batch 236\n",
      "Loss for Batch(236): 0.0003436093684285879\n",
      "Batch 237\n",
      "Loss for Batch(237): 0.022698931396007538\n",
      "Batch 238\n",
      "Loss for Batch(238): 0.013162326067686081\n",
      "Batch 239\n",
      "Loss for Batch(239): 0.002220646943897009\n",
      "Batch 240\n",
      "Loss for Batch(240): 0.00082156783901155\n",
      "Batch 241\n",
      "Loss for Batch(241): 0.022097455337643623\n",
      "Batch 242\n",
      "Loss for Batch(242): 0.01135428436100483\n",
      "Batch 243\n",
      "Loss for Batch(243): 0.0034137917682528496\n",
      "Batch 244\n",
      "Loss for Batch(244): 0.007474645972251892\n",
      "Batch 245\n",
      "Loss for Batch(245): 0.004733863286674023\n",
      "Batch 246\n",
      "Loss for Batch(246): 0.0001457136240787804\n",
      "Batch 247\n",
      "Loss for Batch(247): 0.009801097214221954\n",
      "Batch 248\n",
      "Loss for Batch(248): 0.0003574073198251426\n",
      "Batch 249\n",
      "Loss for Batch(249): 0.00024032244982663542\n",
      "Batch 250\n",
      "Loss for Batch(250): 0.0052923401817679405\n",
      "Batch 251\n",
      "Loss for Batch(251): 0.0024864147417247295\n",
      "Batch 252\n",
      "Loss for Batch(252): 0.050462499260902405\n",
      "Batch 253\n",
      "Loss for Batch(253): 0.016088606789708138\n",
      "Batch 254\n",
      "Loss for Batch(254): 0.0017757873283699155\n",
      "Batch 255\n",
      "Loss for Batch(255): 0.0034977770410478115\n",
      "Batch 256\n",
      "Loss for Batch(256): 0.014783874154090881\n",
      "Batch 257\n",
      "Loss for Batch(257): 0.5236700773239136\n",
      "Batch 258\n",
      "Loss for Batch(258): 0.02489486150443554\n",
      "Batch 259\n",
      "Loss for Batch(259): 0.0006588520482182503\n",
      "Batch 260\n",
      "Loss for Batch(260): 0.012400821782648563\n",
      "Batch 261\n",
      "Loss for Batch(261): 0.003108797362074256\n",
      "Batch 262\n",
      "Loss for Batch(262): 0.00015221358626149595\n",
      "Batch 263\n",
      "Loss for Batch(263): 0.0001788786321412772\n",
      "Batch 264\n",
      "Loss for Batch(264): 0.000885724148247391\n",
      "Batch 265\n",
      "Loss for Batch(265): 0.009840336628258228\n",
      "Batch 266\n",
      "Loss for Batch(266): 0.0194662194699049\n",
      "Batch 267\n",
      "Loss for Batch(267): 0.00047181060654111207\n",
      "Batch 268\n",
      "Loss for Batch(268): 0.009888794273138046\n",
      "Batch 269\n",
      "Loss for Batch(269): 0.04450785368680954\n",
      "Batch 270\n",
      "Loss for Batch(270): 0.013207192532718182\n",
      "Batch 271\n",
      "Loss for Batch(271): 0.0018735502380877733\n",
      "Batch 272\n",
      "Loss for Batch(272): 0.02386922761797905\n",
      "Batch 273\n",
      "Loss for Batch(273): 0.05065301060676575\n",
      "Batch 274\n",
      "Loss for Batch(274): 0.002579494146630168\n",
      "Batch 275\n",
      "Loss for Batch(275): 0.0007319585420191288\n",
      "Batch 276\n",
      "Loss for Batch(276): 0.01980946585536003\n",
      "Batch 277\n",
      "Loss for Batch(277): 0.0010844318894669414\n",
      "Batch 278\n",
      "Loss for Batch(278): 0.00013736569962929934\n",
      "Batch 279\n",
      "Loss for Batch(279): 0.009488544426858425\n",
      "Batch 280\n",
      "Loss for Batch(280): 0.001189888920634985\n",
      "Batch 281\n",
      "Loss for Batch(281): 0.0015997060108929873\n",
      "Batch 282\n",
      "Loss for Batch(282): 0.014770048670470715\n",
      "Batch 283\n",
      "Loss for Batch(283): 0.0064212866127491\n",
      "Batch 284\n",
      "Loss for Batch(284): 0.0013404767960309982\n",
      "Batch 285\n",
      "Loss for Batch(285): 0.0002548031334299594\n",
      "Batch 286\n",
      "Loss for Batch(286): 0.00029033870669081807\n",
      "Batch 287\n",
      "Loss for Batch(287): 0.003393493127077818\n",
      "Batch 288\n",
      "Loss for Batch(288): 0.00012523475743364543\n",
      "Batch 289\n",
      "Loss for Batch(289): 0.005132295191287994\n",
      "Batch 290\n",
      "Loss for Batch(290): 0.006223393138498068\n",
      "Batch 291\n",
      "Loss for Batch(291): 0.0005488222232088447\n",
      "Batch 292\n",
      "Loss for Batch(292): 0.005406046751886606\n",
      "Batch 293\n",
      "Loss for Batch(293): 0.23814532160758972\n",
      "Batch 294\n",
      "Loss for Batch(294): 0.005364240147173405\n",
      "Batch 295\n",
      "Loss for Batch(295): 0.07504924386739731\n",
      "Batch 296\n",
      "Loss for Batch(296): 0.014583634212613106\n",
      "Batch 297\n",
      "Loss for Batch(297): 0.006220025010406971\n",
      "Batch 298\n",
      "Loss for Batch(298): 0.016307897865772247\n",
      "Batch 299\n",
      "Loss for Batch(299): 0.007444812450557947\n",
      "Batch 300\n",
      "Loss for Batch(300): 0.00016073521692305803\n",
      "Batch 301\n",
      "Loss for Batch(301): 0.01631908491253853\n",
      "Batch 302\n",
      "Loss for Batch(302): 0.0007266922038979828\n",
      "Batch 303\n",
      "Loss for Batch(303): 0.012872564606368542\n",
      "Batch 304\n",
      "Loss for Batch(304): 0.0004549133882392198\n",
      "Batch 305\n",
      "Loss for Batch(305): 0.001254834234714508\n",
      "Batch 306\n",
      "Loss for Batch(306): 0.0003836863616015762\n",
      "Batch 307\n",
      "Loss for Batch(307): 0.008713411167263985\n",
      "Batch 308\n",
      "Loss for Batch(308): 0.0043530031107366085\n",
      "Batch 309\n",
      "Loss for Batch(309): 0.0005762516520917416\n",
      "Batch 310\n",
      "Loss for Batch(310): 0.0025050316471606493\n",
      "Batch 311\n",
      "Loss for Batch(311): 0.03904663026332855\n",
      "Batch 312\n",
      "Loss for Batch(312): 0.0010362549219280481\n",
      "Batch 313\n",
      "Loss for Batch(313): 0.004531631711870432\n",
      "Batch 314\n",
      "Loss for Batch(314): 7.277264376170933e-05\n",
      "Batch 315\n",
      "Loss for Batch(315): 0.0002565058530308306\n",
      "Batch 316\n",
      "Loss for Batch(316): 0.00013764154573436826\n",
      "Batch 317\n",
      "Loss for Batch(317): 0.11279083043336868\n",
      "Batch 318\n",
      "Loss for Batch(318): 0.007861447520554066\n",
      "Batch 319\n",
      "Loss for Batch(319): 0.002229579258710146\n",
      "Batch 320\n",
      "Loss for Batch(320): 0.03007475472986698\n",
      "Batch 321\n",
      "Loss for Batch(321): 0.06312140822410583\n",
      "Batch 322\n",
      "Loss for Batch(322): 0.0009956277208402753\n",
      "Batch 323\n",
      "Loss for Batch(323): 0.058528050780296326\n",
      "Batch 324\n",
      "Loss for Batch(324): 0.0009224612731486559\n",
      "Batch 325\n",
      "Loss for Batch(325): 0.009584436193108559\n",
      "Batch 326\n",
      "Loss for Batch(326): 0.027785394340753555\n",
      "Batch 327\n",
      "Loss for Batch(327): 0.005288861691951752\n",
      "Batch 328\n",
      "Loss for Batch(328): 0.03710287809371948\n",
      "Batch 329\n",
      "Loss for Batch(329): 0.0026237554848194122\n",
      "Batch 330\n",
      "Loss for Batch(330): 0.00013251139898784459\n",
      "Batch 331\n",
      "Loss for Batch(331): 2.136735201929696e-05\n",
      "Batch 332\n",
      "Loss for Batch(332): 0.0020516065414994955\n",
      "Batch 333\n",
      "Loss for Batch(333): 0.01962755061686039\n",
      "Batch 334\n",
      "Loss for Batch(334): 0.0006825143937021494\n",
      "Batch 335\n",
      "Loss for Batch(335): 8.743343641981483e-05\n",
      "Batch 336\n",
      "Loss for Batch(336): 3.781733539653942e-05\n",
      "Batch 337\n",
      "Loss for Batch(337): 0.005180546082556248\n",
      "Batch 338\n",
      "Loss for Batch(338): 3.6298199120210484e-05\n",
      "Batch 339\n",
      "Loss for Batch(339): 0.03320102021098137\n",
      "Batch 340\n",
      "Loss for Batch(340): 0.01951778307557106\n",
      "Batch 341\n",
      "Loss for Batch(341): 0.0012046399060636759\n",
      "Batch 342\n",
      "Loss for Batch(342): 2.0354656953713857e-05\n",
      "Batch 343\n",
      "Loss for Batch(343): 0.0041170744225382805\n",
      "Batch 344\n",
      "Loss for Batch(344): 0.8247637748718262\n",
      "Batch 345\n",
      "Loss for Batch(345): 0.013527913019061089\n",
      "Batch 346\n",
      "Loss for Batch(346): 0.002289673313498497\n",
      "Batch 347\n",
      "Loss for Batch(347): 0.00019552184676285833\n",
      "Batch 348\n",
      "Loss for Batch(348): 0.004095923621207476\n",
      "Batch 349\n",
      "Loss for Batch(349): 0.0006860466091893613\n",
      "Batch 350\n",
      "Loss for Batch(350): 0.009272383525967598\n",
      "Batch 351\n",
      "Loss for Batch(351): 0.0823739767074585\n",
      "Batch 352\n",
      "Loss for Batch(352): 0.0004231758357491344\n",
      "Batch 353\n",
      "Loss for Batch(353): 0.001973791979253292\n",
      "Batch 354\n",
      "Loss for Batch(354): 0.009692969731986523\n",
      "Batch 355\n",
      "Loss for Batch(355): 0.003920882474631071\n",
      "Batch 356\n",
      "Loss for Batch(356): 0.0008307152893394232\n",
      "Batch 357\n",
      "Loss for Batch(357): 0.003091825172305107\n",
      "Batch 358\n",
      "Loss for Batch(358): 6.475573172792792e-05\n",
      "Batch 359\n",
      "Loss for Batch(359): 0.005600224249064922\n",
      "Batch 360\n",
      "Loss for Batch(360): 0.03673437982797623\n",
      "Batch 361\n",
      "Loss for Batch(361): 0.010713181458413601\n",
      "Batch 362\n",
      "Loss for Batch(362): 0.03650841861963272\n",
      "Batch 363\n",
      "Loss for Batch(363): 0.0011377352057024837\n",
      "Batch 364\n",
      "Loss for Batch(364): 0.005503385327756405\n",
      "Batch 365\n",
      "Loss for Batch(365): 8.421224629273638e-05\n",
      "Batch 366\n",
      "Loss for Batch(366): 0.0015113059198483825\n",
      "Batch 367\n",
      "Loss for Batch(367): 0.0006397702381946146\n",
      "Batch 368\n",
      "Loss for Batch(368): 0.0022621951065957546\n",
      "Batch 369\n",
      "Loss for Batch(369): 0.17916184663772583\n",
      "Batch 370\n",
      "Loss for Batch(370): 0.033953335136175156\n",
      "Batch 371\n",
      "Loss for Batch(371): 0.023243121802806854\n",
      "Batch 372\n",
      "Loss for Batch(372): 0.0003190133429598063\n",
      "Batch 373\n",
      "Loss for Batch(373): 0.008885703049600124\n",
      "Batch 374\n",
      "Loss for Batch(374): 0.007299554534256458\n",
      "Batch 375\n",
      "Loss for Batch(375): 0.0005735311424359679\n",
      "Batch 376\n",
      "Loss for Batch(376): 0.0006019624415785074\n",
      "Batch 377\n",
      "Loss for Batch(377): 0.006734898779541254\n",
      "Batch 378\n",
      "Loss for Batch(378): 0.008326597511768341\n",
      "Batch 379\n",
      "Loss for Batch(379): 0.014320465736091137\n",
      "Batch 380\n",
      "Loss for Batch(380): 0.0025514932349324226\n",
      "Batch 381\n",
      "Loss for Batch(381): 0.0006151475827209651\n",
      "Batch 382\n",
      "Loss for Batch(382): 0.0011329061817377806\n",
      "Batch 383\n",
      "Loss for Batch(383): 0.24637775123119354\n",
      "Batch 384\n",
      "Loss for Batch(384): 0.002615490695461631\n",
      "Batch 385\n",
      "Loss for Batch(385): 0.0008845865959301591\n",
      "Batch 386\n",
      "Loss for Batch(386): 0.002159285359084606\n",
      "Batch 387\n",
      "Loss for Batch(387): 0.0008887931471690536\n",
      "Batch 388\n",
      "Loss for Batch(388): 0.0928855687379837\n",
      "Batch 389\n",
      "Loss for Batch(389): 2.2291736968327314e-05\n",
      "Batch 390\n",
      "Loss for Batch(390): 0.00036677863681688905\n",
      "Batch 391\n",
      "Loss for Batch(391): 0.0002481089613866061\n",
      "Batch 392\n",
      "Loss for Batch(392): 0.00012065660848747939\n",
      "Batch 393\n",
      "Loss for Batch(393): 0.011846699751913548\n",
      "Batch 394\n",
      "Loss for Batch(394): 0.02710169367492199\n",
      "Batch 395\n",
      "Loss for Batch(395): 0.00028793441015295684\n",
      "Batch 396\n",
      "Loss for Batch(396): 0.00019578539649955928\n",
      "Batch 397\n",
      "Loss for Batch(397): 0.134037584066391\n",
      "Batch 398\n",
      "Loss for Batch(398): 0.0034673556219786406\n",
      "Batch 399\n",
      "Loss for Batch(399): 0.0012817634269595146\n",
      "Batch 400\n",
      "Loss for Batch(400): 0.003233242779970169\n",
      "Batch 401\n",
      "Loss for Batch(401): 0.044699545949697495\n",
      "Batch 402\n",
      "Loss for Batch(402): 0.0009955361019819975\n",
      "Batch 403\n",
      "Loss for Batch(403): 0.015006773173809052\n",
      "Batch 404\n",
      "Loss for Batch(404): 0.03259329870343208\n",
      "Batch 405\n",
      "Loss for Batch(405): 0.0009996138978749514\n",
      "Batch 406\n",
      "Loss for Batch(406): 0.10055061429738998\n",
      "Batch 407\n",
      "Loss for Batch(407): 0.0019340094877406955\n",
      "Batch 408\n",
      "Loss for Batch(408): 0.0001915409229695797\n",
      "Batch 409\n",
      "Loss for Batch(409): 0.00040872584213502705\n",
      "Batch 410\n",
      "Loss for Batch(410): 0.0272684246301651\n",
      "Batch 411\n",
      "Loss for Batch(411): 0.032563161104917526\n",
      "Batch 412\n",
      "Loss for Batch(412): 0.000575409852899611\n",
      "Batch 413\n",
      "Loss for Batch(413): 0.00011594509123824537\n",
      "Batch 414\n",
      "Loss for Batch(414): 0.00047138004447333515\n",
      "Batch 415\n",
      "Loss for Batch(415): 0.008541644550859928\n",
      "Batch 416\n",
      "Loss for Batch(416): 0.0002966331085190177\n",
      "Batch 417\n",
      "Loss for Batch(417): 0.00047299699508585036\n",
      "Batch 418\n",
      "Loss for Batch(418): 0.019037125632166862\n",
      "Batch 419\n",
      "Loss for Batch(419): 0.06263609975576401\n",
      "Batch 420\n",
      "Loss for Batch(420): 0.00017056615615729243\n",
      "Batch 421\n",
      "Loss for Batch(421): 0.003799792844802141\n",
      "Batch 422\n",
      "Loss for Batch(422): 0.00046562100760638714\n",
      "Batch 423\n",
      "Loss for Batch(423): 2.1606325390166603e-05\n",
      "Batch 424\n",
      "Loss for Batch(424): 0.0018501583253964782\n",
      "Batch 425\n",
      "Loss for Batch(425): 0.00013696761743631214\n",
      "Batch 426\n",
      "Loss for Batch(426): 0.0013333350652828813\n",
      "Batch 427\n",
      "Loss for Batch(427): 0.0008150038775056601\n",
      "Batch 428\n",
      "Loss for Batch(428): 0.23608237504959106\n",
      "Batch 429\n",
      "Loss for Batch(429): 0.004347463138401508\n",
      "Batch 430\n",
      "Loss for Batch(430): 0.004366244655102491\n",
      "Batch 431\n",
      "Loss for Batch(431): 0.05889526754617691\n",
      "Batch 432\n",
      "Loss for Batch(432): 0.0021366330329328775\n",
      "Batch 433\n",
      "Loss for Batch(433): 0.007655490655452013\n",
      "Batch 434\n",
      "Loss for Batch(434): 0.000813649850897491\n",
      "Batch 435\n",
      "Loss for Batch(435): 0.00046765810111537576\n",
      "Batch 436\n",
      "Loss for Batch(436): 0.03973884880542755\n",
      "Batch 437\n",
      "Loss for Batch(437): 0.30024465918540955\n",
      "Batch 438\n",
      "Loss for Batch(438): 0.029825134202837944\n",
      "Batch 439\n",
      "Loss for Batch(439): 0.6975746154785156\n",
      "Batch 440\n",
      "Loss for Batch(440): 0.007183271460235119\n",
      "Batch 441\n",
      "Loss for Batch(441): 0.02000443823635578\n",
      "Batch 442\n",
      "Loss for Batch(442): 0.01720566861331463\n",
      "Batch 443\n",
      "Loss for Batch(443): 0.000290492782369256\n",
      "Batch 444\n",
      "Loss for Batch(444): 6.910576485097408e-05\n",
      "Batch 445\n",
      "Loss for Batch(445): 0.00036203640047460794\n",
      "Batch 446\n",
      "Loss for Batch(446): 0.47016429901123047\n",
      "Batch 447\n",
      "Loss for Batch(447): 0.0009100714232772589\n",
      "Batch 448\n",
      "Loss for Batch(448): 0.21304193139076233\n",
      "Batch 449\n",
      "Loss for Batch(449): 0.009764421731233597\n",
      "Batch 450\n",
      "Loss for Batch(450): 0.009030451066792011\n",
      "Batch 451\n",
      "Loss for Batch(451): 0.005149591714143753\n",
      "Batch 452\n",
      "Loss for Batch(452): 0.003002229379490018\n",
      "Batch 453\n",
      "Loss for Batch(453): 0.05262866988778114\n",
      "Batch 454\n",
      "Loss for Batch(454): 0.02063027024269104\n",
      "Batch 455\n",
      "Loss for Batch(455): 0.0027287586126476526\n",
      "Batch 456\n",
      "Loss for Batch(456): 0.002417976502329111\n",
      "Batch 457\n",
      "Loss for Batch(457): 2.0384359231684357e-05\n",
      "Batch 458\n",
      "Loss for Batch(458): 0.005669442471116781\n",
      "Batch 459\n",
      "Loss for Batch(459): 0.0007615999202243984\n",
      "Batch 460\n",
      "Loss for Batch(460): 0.0006443694583140314\n",
      "Batch 461\n",
      "Loss for Batch(461): 0.009358951821923256\n",
      "Batch 462\n",
      "Loss for Batch(462): 0.00842655822634697\n",
      "Batch 463\n",
      "Loss for Batch(463): 0.0016809252556413412\n",
      "Batch 464\n",
      "Loss for Batch(464): 0.008732151240110397\n",
      "Batch 465\n",
      "Loss for Batch(465): 0.0008542597643099725\n",
      "Batch 466\n",
      "Loss for Batch(466): 0.006157380528748035\n",
      "Batch 467\n",
      "Loss for Batch(467): 0.00833859108388424\n",
      "Batch 468\n",
      "Loss for Batch(468): 0.001678159344010055\n",
      "Batch 469\n",
      "Loss for Batch(469): 0.002365236170589924\n",
      "Batch 470\n",
      "Loss for Batch(470): 0.020487653091549873\n",
      "Batch 471\n",
      "Loss for Batch(471): 0.001388921169564128\n",
      "Batch 472\n",
      "Loss for Batch(472): 0.028370918706059456\n",
      "Batch 473\n",
      "Loss for Batch(473): 0.052466921508312225\n",
      "Batch 474\n",
      "Loss for Batch(474): 0.0016724898014217615\n",
      "Batch 475\n",
      "Loss for Batch(475): 0.0007985301199369133\n",
      "Batch 476\n",
      "Loss for Batch(476): 0.00045639817835763097\n",
      "Batch 477\n",
      "Loss for Batch(477): 0.00612014951184392\n",
      "Batch 478\n",
      "Loss for Batch(478): 0.007467102259397507\n",
      "Batch 479\n",
      "Loss for Batch(479): 0.005841400474309921\n",
      "Batch 480\n",
      "Loss for Batch(480): 5.2120478358119726e-05\n",
      "Batch 481\n",
      "Loss for Batch(481): 0.01569521054625511\n",
      "Batch 482\n",
      "Loss for Batch(482): 0.00021404813742265105\n",
      "Batch 483\n",
      "Loss for Batch(483): 0.17789262533187866\n",
      "Batch 484\n",
      "Loss for Batch(484): 0.023335635662078857\n",
      "Batch 485\n",
      "Loss for Batch(485): 0.00011681265459628776\n",
      "Batch 486\n",
      "Loss for Batch(486): 0.020881609991192818\n",
      "Batch 487\n",
      "Loss for Batch(487): 0.00872782152146101\n",
      "Batch 488\n",
      "Loss for Batch(488): 0.0013567821588367224\n",
      "Batch 489\n",
      "Loss for Batch(489): 0.0039641764014959335\n",
      "Batch 490\n",
      "Loss for Batch(490): 0.034586101770401\n",
      "Batch 491\n",
      "Loss for Batch(491): 0.0012715462362393737\n",
      "Batch 492\n",
      "Loss for Batch(492): 2.2381114831659943e-05\n",
      "Batch 493\n",
      "Loss for Batch(493): 0.0016532561276108027\n",
      "Batch 494\n",
      "Loss for Batch(494): 0.023128768429160118\n",
      "Batch 495\n",
      "Loss for Batch(495): 0.0003152320859953761\n",
      "Batch 496\n",
      "Loss for Batch(496): 0.00017443535034544766\n",
      "Batch 497\n",
      "Loss for Batch(497): 0.001013981644064188\n",
      "Batch 498\n",
      "Loss for Batch(498): 0.0007888784166425467\n",
      "Batch 499\n",
      "Loss for Batch(499): 0.07361350208520889\n",
      "Batch 500\n",
      "Loss for Batch(500): 0.00012106142821721733\n",
      "Batch 501\n",
      "Loss for Batch(501): 0.0005466124275699258\n",
      "Batch 502\n",
      "Loss for Batch(502): 0.02561366930603981\n",
      "Batch 503\n",
      "Loss for Batch(503): 0.03203781321644783\n",
      "Batch 504\n",
      "Loss for Batch(504): 0.0002639509621076286\n",
      "Batch 505\n",
      "Loss for Batch(505): 0.00107331364415586\n",
      "Batch 506\n",
      "Loss for Batch(506): 0.00408130930736661\n",
      "Batch 507\n",
      "Loss for Batch(507): 0.000250128359766677\n",
      "Batch 508\n",
      "Loss for Batch(508): 0.004960807040333748\n",
      "Batch 509\n",
      "Loss for Batch(509): 0.0016586440615355968\n",
      "Batch 510\n",
      "Loss for Batch(510): 0.004403121303766966\n",
      "Batch 511\n",
      "Loss for Batch(511): 0.008596290834248066\n",
      "Batch 512\n",
      "Loss for Batch(512): 0.12038866430521011\n",
      "Batch 513\n",
      "Loss for Batch(513): 0.0003923096810467541\n",
      "Batch 514\n",
      "Loss for Batch(514): 0.02288963459432125\n",
      "Batch 515\n",
      "Loss for Batch(515): 6.851129728602245e-05\n",
      "Batch 516\n",
      "Loss for Batch(516): 0.00989357940852642\n",
      "Batch 517\n",
      "Loss for Batch(517): 0.03146938234567642\n",
      "Batch 518\n",
      "Loss for Batch(518): 0.00017302263586316258\n",
      "Batch 519\n",
      "Loss for Batch(519): 0.0005074359360150993\n",
      "Batch 520\n",
      "Loss for Batch(520): 0.000174093569512479\n",
      "Batch 521\n",
      "Loss for Batch(521): 0.0061652567237615585\n",
      "Batch 522\n",
      "Loss for Batch(522): 0.00023350806441158056\n",
      "Batch 523\n",
      "Loss for Batch(523): 0.02882304973900318\n",
      "Batch 524\n",
      "Loss for Batch(524): 0.0007936058100312948\n",
      "Batch 525\n",
      "Loss for Batch(525): 0.001589556341059506\n",
      "Batch 526\n",
      "Loss for Batch(526): 0.0027394085191190243\n",
      "Batch 527\n",
      "Loss for Batch(527): 9.219873754773289e-05\n",
      "Batch 528\n",
      "Loss for Batch(528): 0.028542587533593178\n",
      "Batch 529\n",
      "Loss for Batch(529): 0.016778895631432533\n",
      "Batch 530\n",
      "Loss for Batch(530): 0.005766498856246471\n",
      "Batch 531\n",
      "Loss for Batch(531): 0.05539613962173462\n",
      "Batch 532\n",
      "Loss for Batch(532): 0.32363930344581604\n",
      "Batch 533\n",
      "Loss for Batch(533): 0.03286292403936386\n",
      "Batch 534\n",
      "Loss for Batch(534): 0.014626204036176205\n",
      "Batch 535\n",
      "Loss for Batch(535): 0.003998087253421545\n",
      "Batch 536\n",
      "Loss for Batch(536): 0.0007447879761457443\n",
      "Batch 537\n",
      "Loss for Batch(537): 0.001340216607786715\n",
      "Batch 538\n",
      "Loss for Batch(538): 0.0011521197156980634\n",
      "Batch 539\n",
      "Loss for Batch(539): 0.007884891703724861\n",
      "Batch 540\n",
      "Loss for Batch(540): 0.009582141414284706\n",
      "Batch 541\n",
      "Loss for Batch(541): 0.019568979740142822\n",
      "Batch 542\n",
      "Loss for Batch(542): 0.0011750576086342335\n",
      "Batch 543\n",
      "Loss for Batch(543): 0.0006121380720287561\n",
      "Batch 544\n",
      "Loss for Batch(544): 0.006244286894798279\n",
      "Batch 545\n",
      "Loss for Batch(545): 0.07650868594646454\n",
      "Batch 546\n",
      "Loss for Batch(546): 0.0001563485711812973\n",
      "Batch 547\n",
      "Loss for Batch(547): 0.0023021369706839323\n",
      "Batch 548\n",
      "Loss for Batch(548): 0.012379402294754982\n",
      "Batch 549\n",
      "Loss for Batch(549): 0.0017137388931587338\n",
      "Batch 550\n",
      "Loss for Batch(550): 0.04255315288901329\n",
      "Batch 551\n",
      "Loss for Batch(551): 0.0581137090921402\n",
      "Batch 552\n",
      "Loss for Batch(552): 0.00038174405926838517\n",
      "Batch 553\n",
      "Loss for Batch(553): 0.0015454337699338794\n",
      "Batch 554\n",
      "Loss for Batch(554): 0.01586092822253704\n",
      "Batch 555\n",
      "Loss for Batch(555): 0.00025018691667355597\n",
      "Batch 556\n",
      "Loss for Batch(556): 0.0007140209199860692\n",
      "Batch 557\n",
      "Loss for Batch(557): 0.02511032298207283\n",
      "Batch 558\n",
      "Loss for Batch(558): 0.009682743810117245\n",
      "Batch 559\n",
      "Loss for Batch(559): 0.005326546262949705\n",
      "Batch 560\n",
      "Loss for Batch(560): 0.0001699963177088648\n",
      "Batch 561\n",
      "Loss for Batch(561): 0.0427221804857254\n",
      "Batch 562\n",
      "Loss for Batch(562): 0.005697824992239475\n",
      "Batch 563\n",
      "Loss for Batch(563): 0.006962829735130072\n",
      "Batch 564\n",
      "Loss for Batch(564): 0.008755181916058064\n",
      "Batch 565\n",
      "Loss for Batch(565): 0.025897301733493805\n",
      "Batch 566\n",
      "Loss for Batch(566): 4.073802483617328e-05\n",
      "Batch 567\n",
      "Loss for Batch(567): 0.008201085031032562\n",
      "Batch 568\n",
      "Loss for Batch(568): 0.004175888374447823\n",
      "Batch 569\n",
      "Loss for Batch(569): 0.0036539644934237003\n",
      "Batch 570\n",
      "Loss for Batch(570): 0.019284872338175774\n",
      "Batch 571\n",
      "Loss for Batch(571): 0.02550641819834709\n",
      "Batch 572\n",
      "Loss for Batch(572): 0.027868706732988358\n",
      "Batch 573\n",
      "Loss for Batch(573): 0.0037036375142633915\n",
      "Batch 574\n",
      "Loss for Batch(574): 0.003244042629376054\n",
      "Batch 575\n",
      "Loss for Batch(575): 0.002841493347659707\n",
      "Batch 576\n",
      "Loss for Batch(576): 0.0014102834975346923\n",
      "Batch 577\n",
      "Loss for Batch(577): 0.011786768212914467\n",
      "Batch 578\n",
      "Loss for Batch(578): 0.011714261025190353\n",
      "Batch 579\n",
      "Loss for Batch(579): 0.004573584534227848\n",
      "Batch 580\n",
      "Loss for Batch(580): 0.00019230239558964968\n",
      "Batch 581\n",
      "Loss for Batch(581): 0.012106264941394329\n",
      "Batch 582\n",
      "Loss for Batch(582): 0.0005124812596477568\n",
      "Batch 583\n",
      "Loss for Batch(583): 0.0012444608146324754\n",
      "Batch 584\n",
      "Loss for Batch(584): 1.9579758372856304e-05\n",
      "Batch 585\n",
      "Loss for Batch(585): 0.012667357921600342\n",
      "Batch 586\n",
      "Loss for Batch(586): 0.0025678162928670645\n",
      "Batch 587\n",
      "Loss for Batch(587): 0.03151305764913559\n",
      "Batch 588\n",
      "Loss for Batch(588): 0.010270127095282078\n",
      "Batch 589\n",
      "Loss for Batch(589): 0.0010694435331970453\n",
      "Batch 590\n",
      "Loss for Batch(590): 0.0007567627471871674\n",
      "Batch 591\n",
      "Loss for Batch(591): 0.01085280068218708\n",
      "Batch 592\n",
      "Loss for Batch(592): 0.03850047290325165\n",
      "Batch 593\n",
      "Loss for Batch(593): 0.02401501126587391\n",
      "Batch 594\n",
      "Loss for Batch(594): 0.014135866425931454\n",
      "Batch 595\n",
      "Loss for Batch(595): 7.718736014794558e-06\n",
      "Batch 596\n",
      "Loss for Batch(596): 0.26059097051620483\n",
      "Batch 597\n",
      "Loss for Batch(597): 0.01537453755736351\n",
      "Batch 598\n",
      "Loss for Batch(598): 0.04918304830789566\n",
      "Batch 599\n",
      "Loss for Batch(599): 0.00014411697338800877\n",
      "Batch 600\n",
      "Loss for Batch(600): 0.05537880212068558\n",
      "Batch 601\n",
      "Loss for Batch(601): 2.941330058092717e-05\n",
      "Batch 602\n",
      "Loss for Batch(602): 0.005454742815345526\n",
      "Batch 603\n",
      "Loss for Batch(603): 0.05386428162455559\n",
      "Batch 604\n",
      "Loss for Batch(604): 0.0012111904798075557\n",
      "Batch 605\n",
      "Loss for Batch(605): 0.01397704053670168\n",
      "Batch 606\n",
      "Loss for Batch(606): 0.0019481091294437647\n",
      "Batch 607\n",
      "Loss for Batch(607): 0.007606626488268375\n",
      "Batch 608\n",
      "Loss for Batch(608): 0.018954336643218994\n",
      "Batch 609\n",
      "Loss for Batch(609): 0.015839433297514915\n",
      "Batch 610\n",
      "Loss for Batch(610): 0.0035616611130535603\n",
      "Batch 611\n",
      "Loss for Batch(611): 6.943898824829375e-06\n",
      "Batch 612\n",
      "Loss for Batch(612): 0.017012041062116623\n",
      "Batch 613\n",
      "Loss for Batch(613): 0.02983272075653076\n",
      "Batch 614\n",
      "Loss for Batch(614): 0.00013350187509786338\n",
      "Batch 615\n",
      "Loss for Batch(615): 0.0031783515587449074\n",
      "Batch 616\n",
      "Loss for Batch(616): 0.004331798292696476\n",
      "Batch 617\n",
      "Loss for Batch(617): 0.00015810297918505967\n",
      "Batch 618\n",
      "Loss for Batch(618): 9.328075975645334e-06\n",
      "Batch 619\n",
      "Loss for Batch(619): 0.004926849622279406\n",
      "Batch 620\n",
      "Loss for Batch(620): 6.949457747396082e-05\n",
      "Batch 621\n",
      "Loss for Batch(621): 0.004319174215197563\n",
      "Batch 622\n",
      "Loss for Batch(622): 0.03150816634297371\n",
      "Batch 623\n",
      "Loss for Batch(623): 0.07025811076164246\n",
      "Batch 624\n",
      "Loss for Batch(624): 0.033724021166563034\n",
      "Batch 625\n",
      "Loss for Batch(625): 0.02374013513326645\n",
      "Batch 626\n",
      "Loss for Batch(626): 7.307225314434618e-05\n",
      "Batch 627\n",
      "Loss for Batch(627): 0.0003989426768384874\n",
      "Batch 628\n",
      "Loss for Batch(628): 0.0022970789577811956\n",
      "Batch 629\n",
      "Loss for Batch(629): 0.01055641658604145\n",
      "Batch 630\n",
      "Loss for Batch(630): 1.195061304315459e-05\n",
      "Batch 631\n",
      "Loss for Batch(631): 0.0004539852379821241\n",
      "Batch 632\n",
      "Loss for Batch(632): 0.02705550566315651\n",
      "Batch 633\n",
      "Loss for Batch(633): 0.009824885986745358\n",
      "Batch 634\n",
      "Loss for Batch(634): 0.012116078287363052\n",
      "Batch 635\n",
      "Loss for Batch(635): 0.0006414381787180901\n",
      "Batch 636\n",
      "Loss for Batch(636): 0.012933709658682346\n",
      "Batch 637\n",
      "Loss for Batch(637): 0.0011106692254543304\n",
      "Batch 638\n",
      "Loss for Batch(638): 0.005433940794318914\n",
      "Batch 639\n",
      "Loss for Batch(639): 0.02345561794936657\n",
      "Batch 640\n",
      "Loss for Batch(640): 0.0016490236157551408\n",
      "Batch 641\n",
      "Loss for Batch(641): 0.003120698034763336\n",
      "Batch 642\n",
      "Loss for Batch(642): 0.011584821157157421\n",
      "Batch 643\n",
      "Loss for Batch(643): 0.0013942266814410686\n",
      "Batch 644\n",
      "Loss for Batch(644): 0.014619974419474602\n",
      "Batch 645\n",
      "Loss for Batch(645): 8.42699155327864e-05\n",
      "Batch 646\n",
      "Loss for Batch(646): 0.0024854016955941916\n",
      "Batch 647\n",
      "Loss for Batch(647): 0.0014500604011118412\n",
      "Batch 648\n",
      "Loss for Batch(648): 0.0017213576938956976\n",
      "Batch 649\n",
      "Loss for Batch(649): 0.0019265504088252783\n",
      "Batch 650\n",
      "Loss for Batch(650): 0.014755706302821636\n",
      "Batch 651\n",
      "Loss for Batch(651): 0.019869966432452202\n",
      "Batch 652\n",
      "Loss for Batch(652): 0.0005803529638797045\n",
      "Batch 653\n",
      "Loss for Batch(653): 0.002052154392004013\n",
      "Batch 654\n",
      "Loss for Batch(654): 3.9040937735990155e-06\n",
      "Batch 655\n",
      "Loss for Batch(655): 0.0002446421713102609\n",
      "Batch 656\n",
      "Loss for Batch(656): 0.002629820490255952\n",
      "Batch 657\n",
      "Loss for Batch(657): 2.959236371680163e-05\n",
      "Batch 658\n",
      "Loss for Batch(658): 0.038332343101501465\n",
      "Batch 659\n",
      "Loss for Batch(659): 4.896234895568341e-05\n",
      "Batch 660\n",
      "Loss for Batch(660): 0.029026592150330544\n",
      "Batch 661\n",
      "Loss for Batch(661): 1.0728716006269678e-05\n",
      "Batch 662\n",
      "Loss for Batch(662): 2.345399116165936e-05\n",
      "Batch 663\n",
      "Loss for Batch(663): 0.00010921217472059652\n",
      "Batch 664\n",
      "Loss for Batch(664): 0.002184078097343445\n",
      "Batch 665\n",
      "Loss for Batch(665): 0.0007857558666728437\n",
      "Batch 666\n",
      "Loss for Batch(666): 0.0012222164077684283\n",
      "Batch 667\n",
      "Loss for Batch(667): 0.0024341947864741087\n",
      "Batch 668\n",
      "Loss for Batch(668): 0.0020175406243652105\n",
      "Batch 669\n",
      "Loss for Batch(669): 0.0059883068315684795\n",
      "Batch 670\n",
      "Loss for Batch(670): 0.21677088737487793\n",
      "Batch 671\n",
      "Loss for Batch(671): 0.04264308512210846\n",
      "Batch 672\n",
      "Loss for Batch(672): 0.01624772883951664\n",
      "Batch 673\n",
      "Loss for Batch(673): 0.079130619764328\n",
      "Batch 674\n",
      "Loss for Batch(674): 0.35431548953056335\n",
      "Batch 675\n",
      "Loss for Batch(675): 0.2188922017812729\n",
      "Batch 676\n",
      "Loss for Batch(676): 0.11848624050617218\n",
      "Batch 677\n",
      "Loss for Batch(677): 0.02832428365945816\n",
      "Batch 678\n",
      "Loss for Batch(678): 0.1500261425971985\n",
      "Batch 679\n",
      "Loss for Batch(679): 0.001634471700526774\n",
      "Batch 680\n",
      "Loss for Batch(680): 0.0007245854940265417\n",
      "Batch 681\n",
      "Loss for Batch(681): 0.00289468583650887\n",
      "Batch 682\n",
      "Loss for Batch(682): 0.025814281776547432\n",
      "Batch 683\n",
      "Loss for Batch(683): 0.012555638328194618\n",
      "Batch 684\n",
      "Loss for Batch(684): 0.0036300811916589737\n",
      "Batch 685\n",
      "Loss for Batch(685): 0.0035924604162573814\n",
      "Batch 686\n",
      "Loss for Batch(686): 0.023795122280716896\n",
      "Batch 687\n",
      "Loss for Batch(687): 0.0012706032721325755\n",
      "Batch 688\n",
      "Loss for Batch(688): 0.0002923193387687206\n",
      "Batch 689\n",
      "Loss for Batch(689): 0.0012207807740196586\n",
      "Batch 690\n",
      "Loss for Batch(690): 0.0011896973010152578\n",
      "Batch 691\n",
      "Loss for Batch(691): 0.0003283445257693529\n",
      "Batch 692\n",
      "Loss for Batch(692): 0.006914743222296238\n",
      "Batch 693\n",
      "Loss for Batch(693): 0.210919588804245\n",
      "Batch 694\n",
      "Loss for Batch(694): 0.04766453430056572\n",
      "Batch 695\n",
      "Loss for Batch(695): 0.00497699249535799\n",
      "Batch 696\n",
      "Loss for Batch(696): 0.0030734390020370483\n",
      "Batch 697\n",
      "Loss for Batch(697): 0.0076044658198952675\n",
      "Batch 698\n",
      "Loss for Batch(698): 0.0009694338077679276\n",
      "Batch 699\n",
      "Loss for Batch(699): 3.5076052881777287e-05\n",
      "Batch 700\n",
      "Loss for Batch(700): 0.007013671100139618\n",
      "Batch 701\n",
      "Loss for Batch(701): 0.16109590232372284\n",
      "Batch 702\n",
      "Loss for Batch(702): 0.0013342542806640267\n",
      "Batch 703\n",
      "Loss for Batch(703): 0.017910795286297798\n",
      "Batch 704\n",
      "Loss for Batch(704): 0.00986330397427082\n",
      "Batch 705\n",
      "Loss for Batch(705): 0.002301875501871109\n",
      "Batch 706\n",
      "Loss for Batch(706): 9.124928328674287e-05\n",
      "Batch 707\n",
      "Loss for Batch(707): 0.0736837089061737\n",
      "Batch 708\n",
      "Loss for Batch(708): 0.00935166422277689\n",
      "Batch 709\n",
      "Loss for Batch(709): 0.0024814028292894363\n",
      "Batch 710\n",
      "Loss for Batch(710): 0.0001446769165340811\n",
      "Batch 711\n",
      "Loss for Batch(711): 0.002112925983965397\n",
      "Batch 712\n",
      "Loss for Batch(712): 0.18605688214302063\n",
      "Batch 713\n",
      "Loss for Batch(713): 0.005834138952195644\n",
      "Batch 714\n",
      "Loss for Batch(714): 0.021882208064198494\n",
      "Batch 715\n",
      "Loss for Batch(715): 0.031374529004096985\n",
      "Batch 716\n",
      "Loss for Batch(716): 0.002004914917051792\n",
      "Batch 717\n",
      "Loss for Batch(717): 0.017987914383411407\n",
      "Batch 718\n",
      "Loss for Batch(718): 0.006397582590579987\n",
      "Batch 719\n",
      "Loss for Batch(719): 0.013170575723052025\n",
      "Batch 720\n",
      "Loss for Batch(720): 0.08126086741685867\n",
      "Batch 721\n",
      "Loss for Batch(721): 0.0014054605271667242\n",
      "Batch 722\n",
      "Loss for Batch(722): 0.0038323423359543085\n",
      "Batch 723\n",
      "Loss for Batch(723): 0.06412868201732635\n",
      "Batch 724\n",
      "Loss for Batch(724): 0.0010557803325355053\n",
      "Batch 725\n",
      "Loss for Batch(725): 0.002078521763905883\n",
      "Batch 726\n",
      "Loss for Batch(726): 0.3746868968009949\n",
      "Batch 727\n",
      "Loss for Batch(727): 0.021532554179430008\n",
      "Batch 728\n",
      "Loss for Batch(728): 0.00701203104108572\n",
      "Batch 729\n",
      "Loss for Batch(729): 0.0011754123261198401\n",
      "Batch 730\n",
      "Loss for Batch(730): 0.005232592578977346\n",
      "Batch 731\n",
      "Loss for Batch(731): 0.0505155585706234\n",
      "Batch 732\n",
      "Loss for Batch(732): 0.01448686234652996\n",
      "Batch 733\n",
      "Loss for Batch(733): 0.03191914036870003\n",
      "Batch 734\n",
      "Loss for Batch(734): 5.739576226915233e-05\n",
      "Batch 735\n",
      "Loss for Batch(735): 0.01871916465461254\n",
      "Batch 736\n",
      "Loss for Batch(736): 0.036105528473854065\n",
      "Batch 737\n",
      "Loss for Batch(737): 0.1057354062795639\n",
      "Batch 738\n",
      "Loss for Batch(738): 0.27560245990753174\n",
      "Batch 739\n",
      "Loss for Batch(739): 0.00860188901424408\n",
      "Batch 740\n",
      "Loss for Batch(740): 0.0031782295554876328\n",
      "Batch 741\n",
      "Loss for Batch(741): 0.003907141741365194\n",
      "Batch 742\n",
      "Loss for Batch(742): 0.0026496737264096737\n",
      "Batch 743\n",
      "Loss for Batch(743): 0.07517100125551224\n",
      "Batch 744\n",
      "Loss for Batch(744): 0.10688851773738861\n",
      "Batch 745\n",
      "Loss for Batch(745): 0.0019271785859018564\n",
      "Batch 746\n",
      "Loss for Batch(746): 0.03355702757835388\n",
      "Batch 747\n",
      "Loss for Batch(747): 0.058199021965265274\n",
      "Batch 748\n",
      "Loss for Batch(748): 0.000276950653642416\n",
      "Batch 749\n",
      "Loss for Batch(749): 0.012323694303631783\n",
      "Batch 750\n",
      "Loss for Batch(750): 0.0004007877432741225\n",
      "Batch 751\n",
      "Loss for Batch(751): 0.04238499328494072\n",
      "Batch 752\n",
      "Loss for Batch(752): 0.0814531147480011\n",
      "Batch 753\n",
      "Loss for Batch(753): 0.003296419745311141\n",
      "Avg Loss for 754 Batches0.02744008361405951\n",
      "Epoch(98) Finished\n",
      "**********************************************\n",
      "Avg Test Loss:\n",
      "0.1738425953296269\n",
      "Test Accuracy:\n",
      "0.9389110225763613\n",
      "**********************************************\n",
      "******************Epoch(99):***********************\n",
      "Batch 1\n",
      "Loss for Batch(1): 0.005647456739097834\n",
      "Batch 2\n",
      "Loss for Batch(2): 0.033198896795511246\n",
      "Batch 3\n",
      "Loss for Batch(3): 0.04527611285448074\n",
      "Batch 4\n",
      "Loss for Batch(4): 0.0021848888136446476\n",
      "Batch 5\n",
      "Loss for Batch(5): 0.013849491253495216\n",
      "Batch 6\n",
      "Loss for Batch(6): 0.0001952149032149464\n",
      "Batch 7\n",
      "Loss for Batch(7): 0.0011440356029197574\n",
      "Batch 8\n",
      "Loss for Batch(8): 0.00418781116604805\n",
      "Batch 9\n",
      "Loss for Batch(9): 0.02122104912996292\n",
      "Batch 10\n",
      "Loss for Batch(10): 0.012068995274603367\n",
      "Batch 11\n",
      "Loss for Batch(11): 0.006908460054546595\n",
      "Batch 12\n",
      "Loss for Batch(12): 0.00017090426990762353\n",
      "Batch 13\n",
      "Loss for Batch(13): 0.0005542550934478641\n",
      "Batch 14\n",
      "Loss for Batch(14): 0.0005498906830325723\n",
      "Batch 15\n",
      "Loss for Batch(15): 0.0037368307821452618\n",
      "Batch 16\n",
      "Loss for Batch(16): 0.0009702849783934653\n",
      "Batch 17\n",
      "Loss for Batch(17): 0.004140376579016447\n",
      "Batch 18\n",
      "Loss for Batch(18): 0.003020678414031863\n",
      "Batch 19\n",
      "Loss for Batch(19): 0.0018821267876774073\n",
      "Batch 20\n",
      "Loss for Batch(20): 0.04880809038877487\n",
      "Batch 21\n",
      "Loss for Batch(21): 0.08668380975723267\n",
      "Batch 22\n",
      "Loss for Batch(22): 0.0006092157564125955\n",
      "Batch 23\n",
      "Loss for Batch(23): 0.0035269418731331825\n",
      "Batch 24\n",
      "Loss for Batch(24): 0.0014831002335995436\n",
      "Batch 25\n",
      "Loss for Batch(25): 0.0007432425627484918\n",
      "Batch 26\n",
      "Loss for Batch(26): 0.0009120095637626946\n",
      "Batch 27\n",
      "Loss for Batch(27): 0.010057826526463032\n",
      "Batch 28\n",
      "Loss for Batch(28): 0.0013196521904319525\n",
      "Batch 29\n",
      "Loss for Batch(29): 0.02336396649479866\n",
      "Batch 30\n",
      "Loss for Batch(30): 0.00018107733922079206\n",
      "Batch 31\n",
      "Loss for Batch(31): 2.5182469471474178e-05\n",
      "Batch 32\n",
      "Loss for Batch(32): 0.0006235908367671072\n",
      "Batch 33\n",
      "Loss for Batch(33): 0.002120902994647622\n",
      "Batch 34\n",
      "Loss for Batch(34): 0.0005181371816433966\n",
      "Batch 35\n",
      "Loss for Batch(35): 0.00787273608148098\n",
      "Batch 36\n",
      "Loss for Batch(36): 0.0029182112775743008\n",
      "Batch 37\n",
      "Loss for Batch(37): 3.751864642254077e-05\n",
      "Batch 38\n",
      "Loss for Batch(38): 0.00023523869458585978\n",
      "Batch 39\n",
      "Loss for Batch(39): 0.00026872812304645777\n",
      "Batch 40\n",
      "Loss for Batch(40): 0.006807877216488123\n",
      "Batch 41\n",
      "Loss for Batch(41): 0.0008749987464398146\n",
      "Batch 42\n",
      "Loss for Batch(42): 0.01120627112686634\n",
      "Batch 43\n",
      "Loss for Batch(43): 0.0004128116415813565\n",
      "Batch 44\n",
      "Loss for Batch(44): 0.051690082997083664\n",
      "Batch 45\n",
      "Loss for Batch(45): 0.025444095954298973\n",
      "Batch 46\n",
      "Loss for Batch(46): 0.007180033717304468\n",
      "Batch 47\n",
      "Loss for Batch(47): 0.008736809715628624\n",
      "Batch 48\n",
      "Loss for Batch(48): 0.00018183377687819302\n",
      "Batch 49\n",
      "Loss for Batch(49): 4.8544854507781565e-05\n",
      "Batch 50\n",
      "Loss for Batch(50): 0.034495238214731216\n",
      "Batch 51\n",
      "Loss for Batch(51): 0.014765762723982334\n",
      "Batch 52\n",
      "Loss for Batch(52): 0.0009209486306644976\n",
      "Batch 53\n",
      "Loss for Batch(53): 0.004233134910464287\n",
      "Batch 54\n",
      "Loss for Batch(54): 1.61227162607247e-05\n",
      "Batch 55\n",
      "Loss for Batch(55): 0.008577479980885983\n",
      "Batch 56\n",
      "Loss for Batch(56): 0.00018694747996050864\n",
      "Batch 57\n",
      "Loss for Batch(57): 0.010984417051076889\n",
      "Batch 58\n",
      "Loss for Batch(58): 0.0030935879331082106\n",
      "Batch 59\n",
      "Loss for Batch(59): 0.007138099055737257\n",
      "Batch 60\n",
      "Loss for Batch(60): 0.0035067154094576836\n",
      "Batch 61\n",
      "Loss for Batch(61): 0.00020115448569413275\n",
      "Batch 62\n",
      "Loss for Batch(62): 0.0006620570784434676\n",
      "Batch 63\n",
      "Loss for Batch(63): 0.0045851366594433784\n",
      "Batch 64\n",
      "Loss for Batch(64): 2.214240339526441e-05\n",
      "Batch 65\n",
      "Loss for Batch(65): 0.003314128378406167\n",
      "Batch 66\n",
      "Loss for Batch(66): 0.04655114561319351\n",
      "Batch 67\n",
      "Loss for Batch(67): 0.0011398352216929197\n",
      "Batch 68\n",
      "Loss for Batch(68): 0.0022658861707895994\n",
      "Batch 69\n",
      "Loss for Batch(69): 0.0030464865267276764\n",
      "Batch 70\n",
      "Loss for Batch(70): 0.09775177389383316\n",
      "Batch 71\n",
      "Loss for Batch(71): 0.010380337946116924\n",
      "Batch 72\n",
      "Loss for Batch(72): 0.022958382964134216\n",
      "Batch 73\n",
      "Loss for Batch(73): 0.028659258037805557\n",
      "Batch 74\n",
      "Loss for Batch(74): 0.001587016973644495\n",
      "Batch 75\n",
      "Loss for Batch(75): 0.0005040657706558704\n",
      "Batch 76\n",
      "Loss for Batch(76): 0.0013250857591629028\n",
      "Batch 77\n",
      "Loss for Batch(77): 0.023676497861742973\n",
      "Batch 78\n",
      "Loss for Batch(78): 0.01029749121516943\n",
      "Batch 79\n",
      "Loss for Batch(79): 0.0015186788514256477\n",
      "Batch 80\n",
      "Loss for Batch(80): 0.011537153273820877\n",
      "Batch 81\n",
      "Loss for Batch(81): 0.00011787534458562732\n",
      "Batch 82\n",
      "Loss for Batch(82): 6.55016046948731e-05\n",
      "Batch 83\n",
      "Loss for Batch(83): 0.002921859035268426\n",
      "Batch 84\n",
      "Loss for Batch(84): 0.01789199188351631\n",
      "Batch 85\n",
      "Loss for Batch(85): 0.0016703908331692219\n",
      "Batch 86\n",
      "Loss for Batch(86): 0.01105266623198986\n",
      "Batch 87\n",
      "Loss for Batch(87): 0.0014978338731452823\n",
      "Batch 88\n",
      "Loss for Batch(88): 0.0007979266229085624\n",
      "Batch 89\n",
      "Loss for Batch(89): 0.006530088372528553\n",
      "Batch 90\n",
      "Loss for Batch(90): 0.0011086695594713092\n",
      "Batch 91\n",
      "Loss for Batch(91): 0.03651341423392296\n",
      "Batch 92\n",
      "Loss for Batch(92): 0.0010180940153077245\n",
      "Batch 93\n",
      "Loss for Batch(93): 0.003280959092080593\n",
      "Batch 94\n",
      "Loss for Batch(94): 0.0012615917949005961\n",
      "Batch 95\n",
      "Loss for Batch(95): 0.003644373966380954\n",
      "Batch 96\n",
      "Loss for Batch(96): 0.08775264769792557\n",
      "Batch 97\n",
      "Loss for Batch(97): 0.0003702441172208637\n",
      "Batch 98\n",
      "Loss for Batch(98): 0.007954923436045647\n",
      "Batch 99\n",
      "Loss for Batch(99): 0.0023721426259726286\n",
      "Batch 100\n",
      "Loss for Batch(100): 0.014276107773184776\n",
      "Batch 101\n",
      "Loss for Batch(101): 0.0010558288777247071\n",
      "Batch 102\n",
      "Loss for Batch(102): 0.01836451329290867\n",
      "Batch 103\n",
      "Loss for Batch(103): 0.010250234045088291\n",
      "Batch 104\n",
      "Loss for Batch(104): 0.0003181025094818324\n",
      "Batch 105\n",
      "Loss for Batch(105): 0.002297572325915098\n",
      "Batch 106\n",
      "Loss for Batch(106): 0.010258001275360584\n",
      "Batch 107\n",
      "Loss for Batch(107): 0.0020246070344001055\n",
      "Batch 108\n",
      "Loss for Batch(108): 0.004614676348865032\n",
      "Batch 109\n",
      "Loss for Batch(109): 0.00022784566681366414\n",
      "Batch 110\n",
      "Loss for Batch(110): 0.002540345536544919\n",
      "Batch 111\n",
      "Loss for Batch(111): 0.032158754765987396\n",
      "Batch 112\n",
      "Loss for Batch(112): 0.13019168376922607\n",
      "Batch 113\n",
      "Loss for Batch(113): 0.00019654291099868715\n",
      "Batch 114\n",
      "Loss for Batch(114): 0.0004594551573973149\n",
      "Batch 115\n",
      "Loss for Batch(115): 0.0009442446171306074\n",
      "Batch 116\n",
      "Loss for Batch(116): 0.005720546003431082\n",
      "Batch 117\n",
      "Loss for Batch(117): 0.00685534393414855\n",
      "Batch 118\n",
      "Loss for Batch(118): 0.00844551995396614\n",
      "Batch 119\n",
      "Loss for Batch(119): 0.013606512919068336\n",
      "Batch 120\n",
      "Loss for Batch(120): 0.001439258805476129\n",
      "Batch 121\n",
      "Loss for Batch(121): 0.008609548211097717\n",
      "Batch 122\n",
      "Loss for Batch(122): 0.05457494780421257\n",
      "Batch 123\n",
      "Loss for Batch(123): 0.05985450744628906\n",
      "Batch 124\n",
      "Loss for Batch(124): 0.001930120517499745\n",
      "Batch 125\n",
      "Loss for Batch(125): 0.04374349117279053\n",
      "Batch 126\n",
      "Loss for Batch(126): 0.021136190742254257\n",
      "Batch 127\n",
      "Loss for Batch(127): 0.005033661611378193\n",
      "Batch 128\n",
      "Loss for Batch(128): 0.010827078483998775\n",
      "Batch 129\n",
      "Loss for Batch(129): 0.0002793660678435117\n",
      "Batch 130\n",
      "Loss for Batch(130): 0.002570166951045394\n",
      "Batch 131\n",
      "Loss for Batch(131): 0.00016880051407497376\n",
      "Batch 132\n",
      "Loss for Batch(132): 0.0014677452854812145\n",
      "Batch 133\n",
      "Loss for Batch(133): 0.016606014221906662\n",
      "Batch 134\n",
      "Loss for Batch(134): 0.0039041710551828146\n",
      "Batch 135\n",
      "Loss for Batch(135): 0.032207611948251724\n",
      "Batch 136\n",
      "Loss for Batch(136): 0.023029973730444908\n",
      "Batch 137\n",
      "Loss for Batch(137): 0.0018416414968669415\n",
      "Batch 138\n",
      "Loss for Batch(138): 0.0011618334101513028\n",
      "Batch 139\n",
      "Loss for Batch(139): 0.0007236472447402775\n",
      "Batch 140\n",
      "Loss for Batch(140): 0.008469298481941223\n",
      "Batch 141\n",
      "Loss for Batch(141): 0.0071692210622131824\n",
      "Batch 142\n",
      "Loss for Batch(142): 0.03566718474030495\n",
      "Batch 143\n",
      "Loss for Batch(143): 9.499682346358895e-05\n",
      "Batch 144\n",
      "Loss for Batch(144): 0.045295678079128265\n",
      "Batch 145\n",
      "Loss for Batch(145): 0.01381439995020628\n",
      "Batch 146\n",
      "Loss for Batch(146): 0.022586895152926445\n",
      "Batch 147\n",
      "Loss for Batch(147): 0.029344864189624786\n",
      "Batch 148\n",
      "Loss for Batch(148): 0.00809989869594574\n",
      "Batch 149\n",
      "Loss for Batch(149): 0.0033907985780388117\n",
      "Batch 150\n",
      "Loss for Batch(150): 0.000329166476149112\n",
      "Batch 151\n",
      "Loss for Batch(151): 0.00016033806605264544\n",
      "Batch 152\n",
      "Loss for Batch(152): 0.007113434374332428\n",
      "Batch 153\n",
      "Loss for Batch(153): 0.035729922354221344\n",
      "Batch 154\n",
      "Loss for Batch(154): 0.6359689235687256\n",
      "Batch 155\n",
      "Loss for Batch(155): 0.018210042268037796\n",
      "Batch 156\n",
      "Loss for Batch(156): 9.81545599643141e-05\n",
      "Batch 157\n",
      "Loss for Batch(157): 0.010411275550723076\n",
      "Batch 158\n",
      "Loss for Batch(158): 0.004644234664738178\n",
      "Batch 159\n",
      "Loss for Batch(159): 0.06128905341029167\n",
      "Batch 160\n",
      "Loss for Batch(160): 0.14682190120220184\n",
      "Batch 161\n",
      "Loss for Batch(161): 0.0032720116432756186\n",
      "Batch 162\n",
      "Loss for Batch(162): 0.0004569069715216756\n",
      "Batch 163\n",
      "Loss for Batch(163): 0.00020833106827922165\n",
      "Batch 164\n",
      "Loss for Batch(164): 0.00016714035882614553\n",
      "Batch 165\n",
      "Loss for Batch(165): 0.0005483534187078476\n",
      "Batch 166\n",
      "Loss for Batch(166): 0.003459894098341465\n",
      "Batch 167\n",
      "Loss for Batch(167): 9.315250645158812e-05\n",
      "Batch 168\n",
      "Loss for Batch(168): 0.00024149715318344533\n",
      "Batch 169\n",
      "Loss for Batch(169): 0.0007466858951374888\n",
      "Batch 170\n",
      "Loss for Batch(170): 0.17342472076416016\n",
      "Batch 171\n",
      "Loss for Batch(171): 0.03967927396297455\n",
      "Batch 172\n",
      "Loss for Batch(172): 0.013454701751470566\n",
      "Batch 173\n",
      "Loss for Batch(173): 0.022136060521006584\n",
      "Batch 174\n",
      "Loss for Batch(174): 0.012580770067870617\n",
      "Batch 175\n",
      "Loss for Batch(175): 0.006384775973856449\n",
      "Batch 176\n",
      "Loss for Batch(176): 0.00011293483839835972\n",
      "Batch 177\n",
      "Loss for Batch(177): 0.004425545688718557\n",
      "Batch 178\n",
      "Loss for Batch(178): 0.0004916524630971253\n",
      "Batch 179\n",
      "Loss for Batch(179): 0.0014532579807564616\n",
      "Batch 180\n",
      "Loss for Batch(180): 0.0026500998064875603\n",
      "Batch 181\n",
      "Loss for Batch(181): 0.09804412722587585\n",
      "Batch 182\n",
      "Loss for Batch(182): 0.07889718562364578\n",
      "Batch 183\n",
      "Loss for Batch(183): 0.008991106413304806\n",
      "Batch 184\n",
      "Loss for Batch(184): 0.0017985219601541758\n",
      "Batch 185\n",
      "Loss for Batch(185): 0.0005797133781015873\n",
      "Batch 186\n",
      "Loss for Batch(186): 0.0013435852015390992\n",
      "Batch 187\n",
      "Loss for Batch(187): 0.00040543213253840804\n",
      "Batch 188\n",
      "Loss for Batch(188): 0.00017709427629597485\n",
      "Batch 189\n",
      "Loss for Batch(189): 0.0004654988006222993\n",
      "Batch 190\n",
      "Loss for Batch(190): 0.0005557466065511107\n",
      "Batch 191\n",
      "Loss for Batch(191): 0.007399708963930607\n",
      "Batch 192\n",
      "Loss for Batch(192): 0.0129221947863698\n",
      "Batch 193\n",
      "Loss for Batch(193): 0.3026832044124603\n",
      "Batch 194\n",
      "Loss for Batch(194): 0.012697409838438034\n",
      "Batch 195\n",
      "Loss for Batch(195): 0.0144620630890131\n",
      "Batch 196\n",
      "Loss for Batch(196): 0.00020561898418236524\n",
      "Batch 197\n",
      "Loss for Batch(197): 0.0010156177449971437\n",
      "Batch 198\n",
      "Loss for Batch(198): 0.004010622855275869\n",
      "Batch 199\n",
      "Loss for Batch(199): 0.005342195276170969\n",
      "Batch 200\n",
      "Loss for Batch(200): 0.047356538474559784\n",
      "Batch 201\n",
      "Loss for Batch(201): 0.0009067527716979384\n",
      "Batch 202\n",
      "Loss for Batch(202): 0.004409773275256157\n",
      "Batch 203\n",
      "Loss for Batch(203): 0.005646234378218651\n",
      "Batch 204\n",
      "Loss for Batch(204): 0.006145270075649023\n",
      "Batch 205\n",
      "Loss for Batch(205): 0.0004112448950763792\n",
      "Batch 206\n",
      "Loss for Batch(206): 0.00023301024339161813\n",
      "Batch 207\n",
      "Loss for Batch(207): 0.02657359465956688\n",
      "Batch 208\n",
      "Loss for Batch(208): 0.0019427620572969317\n",
      "Batch 209\n",
      "Loss for Batch(209): 0.05921078845858574\n",
      "Batch 210\n",
      "Loss for Batch(210): 0.031325362622737885\n",
      "Batch 211\n",
      "Loss for Batch(211): 0.00019925972446799278\n",
      "Batch 212\n",
      "Loss for Batch(212): 0.005270841531455517\n",
      "Batch 213\n",
      "Loss for Batch(213): 0.001478673773817718\n",
      "Batch 214\n",
      "Loss for Batch(214): 9.81810298981145e-05\n",
      "Batch 215\n",
      "Loss for Batch(215): 0.020617680624127388\n",
      "Batch 216\n",
      "Loss for Batch(216): 0.03560486435890198\n",
      "Batch 217\n",
      "Loss for Batch(217): 0.014322839677333832\n",
      "Batch 218\n",
      "Loss for Batch(218): 0.23356063663959503\n",
      "Batch 219\n",
      "Loss for Batch(219): 0.00010979963553836569\n",
      "Batch 220\n",
      "Loss for Batch(220): 0.0007182137342169881\n",
      "Batch 221\n",
      "Loss for Batch(221): 0.00019303648150525987\n",
      "Batch 222\n",
      "Loss for Batch(222): 0.0064963120967149734\n",
      "Batch 223\n",
      "Loss for Batch(223): 0.005491487216204405\n",
      "Batch 224\n",
      "Loss for Batch(224): 0.0005824017571285367\n",
      "Batch 225\n",
      "Loss for Batch(225): 3.576263452487183e-06\n",
      "Batch 226\n",
      "Loss for Batch(226): 0.0005647309008054435\n",
      "Batch 227\n",
      "Loss for Batch(227): 7.65276636229828e-05\n",
      "Batch 228\n",
      "Loss for Batch(228): 0.07406722754240036\n",
      "Batch 229\n",
      "Loss for Batch(229): 0.00035789087996818125\n",
      "Batch 230\n",
      "Loss for Batch(230): 0.0002805060357786715\n",
      "Batch 231\n",
      "Loss for Batch(231): 0.0007856606971472502\n",
      "Batch 232\n",
      "Loss for Batch(232): 7.750750228296965e-05\n",
      "Batch 233\n",
      "Loss for Batch(233): 0.0002474675129633397\n",
      "Batch 234\n",
      "Loss for Batch(234): 0.2117813676595688\n",
      "Batch 235\n",
      "Loss for Batch(235): 0.00022710024495609105\n",
      "Batch 236\n",
      "Loss for Batch(236): 0.0021957363933324814\n",
      "Batch 237\n",
      "Loss for Batch(237): 0.0006471216329373419\n",
      "Batch 238\n",
      "Loss for Batch(238): 0.04789412394165993\n",
      "Batch 239\n",
      "Loss for Batch(239): 7.071561412885785e-05\n",
      "Batch 240\n",
      "Loss for Batch(240): 0.004443437792360783\n",
      "Batch 241\n",
      "Loss for Batch(241): 2.5092642317758873e-05\n",
      "Batch 242\n",
      "Loss for Batch(242): 0.025602033361792564\n",
      "Batch 243\n",
      "Loss for Batch(243): 0.0001078416098607704\n",
      "Batch 244\n",
      "Loss for Batch(244): 0.0019157493952661753\n",
      "Batch 245\n",
      "Loss for Batch(245): 0.01582571119070053\n",
      "Batch 246\n",
      "Loss for Batch(246): 0.001340026967227459\n",
      "Batch 247\n",
      "Loss for Batch(247): 0.000753957312554121\n",
      "Batch 248\n",
      "Loss for Batch(248): 0.00023911897733341902\n",
      "Batch 249\n",
      "Loss for Batch(249): 0.035794518887996674\n",
      "Batch 250\n",
      "Loss for Batch(250): 0.016757924109697342\n",
      "Batch 251\n",
      "Loss for Batch(251): 0.0002580279251560569\n",
      "Batch 252\n",
      "Loss for Batch(252): 0.01018687803298235\n",
      "Batch 253\n",
      "Loss for Batch(253): 0.010078348219394684\n",
      "Batch 254\n",
      "Loss for Batch(254): 0.003428294323384762\n",
      "Batch 255\n",
      "Loss for Batch(255): 0.001109674689359963\n",
      "Batch 256\n",
      "Loss for Batch(256): 0.0018998642917722464\n",
      "Batch 257\n",
      "Loss for Batch(257): 0.030368050560355186\n",
      "Batch 258\n",
      "Loss for Batch(258): 0.007582637015730143\n",
      "Batch 259\n",
      "Loss for Batch(259): 6.219057831913233e-05\n",
      "Batch 260\n",
      "Loss for Batch(260): 0.0047838520258665085\n",
      "Batch 261\n",
      "Loss for Batch(261): 0.00046703737461939454\n",
      "Batch 262\n",
      "Loss for Batch(262): 0.005773440003395081\n",
      "Batch 263\n",
      "Loss for Batch(263): 0.0038357404991984367\n",
      "Batch 264\n",
      "Loss for Batch(264): 0.0986279845237732\n",
      "Batch 265\n",
      "Loss for Batch(265): 0.0010013538412749767\n",
      "Batch 266\n",
      "Loss for Batch(266): 0.019472727552056313\n",
      "Batch 267\n",
      "Loss for Batch(267): 0.01106061227619648\n",
      "Batch 268\n",
      "Loss for Batch(268): 0.0194195955991745\n",
      "Batch 269\n",
      "Loss for Batch(269): 0.08940766006708145\n",
      "Batch 270\n",
      "Loss for Batch(270): 0.003366891760379076\n",
      "Batch 271\n",
      "Loss for Batch(271): 0.0004031416028738022\n",
      "Batch 272\n",
      "Loss for Batch(272): 0.0031339095439761877\n",
      "Batch 273\n",
      "Loss for Batch(273): 0.02717108651995659\n",
      "Batch 274\n",
      "Loss for Batch(274): 0.008371973410248756\n",
      "Batch 275\n",
      "Loss for Batch(275): 0.0866541936993599\n",
      "Batch 276\n",
      "Loss for Batch(276): 0.002634025877341628\n",
      "Batch 277\n",
      "Loss for Batch(277): 0.021199408918619156\n",
      "Batch 278\n",
      "Loss for Batch(278): 0.0020936643704771996\n",
      "Batch 279\n",
      "Loss for Batch(279): 0.0025139874778687954\n",
      "Batch 280\n",
      "Loss for Batch(280): 0.00011694715794874355\n",
      "Batch 281\n",
      "Loss for Batch(281): 0.0002152997039956972\n",
      "Batch 282\n",
      "Loss for Batch(282): 0.0027878654655069113\n",
      "Batch 283\n",
      "Loss for Batch(283): 0.0033241042401641607\n",
      "Batch 284\n",
      "Loss for Batch(284): 0.025335900485515594\n",
      "Batch 285\n",
      "Loss for Batch(285): 0.0033463037107139826\n",
      "Batch 286\n",
      "Loss for Batch(286): 5.2746407163795084e-05\n",
      "Batch 287\n",
      "Loss for Batch(287): 0.004575636703521013\n",
      "Batch 288\n",
      "Loss for Batch(288): 0.00835736095905304\n",
      "Batch 289\n",
      "Loss for Batch(289): 0.0029934742487967014\n",
      "Batch 290\n",
      "Loss for Batch(290): 0.005754953250288963\n",
      "Batch 291\n",
      "Loss for Batch(291): 0.007031886838376522\n",
      "Batch 292\n",
      "Loss for Batch(292): 0.00033704290399327874\n",
      "Batch 293\n",
      "Loss for Batch(293): 0.003862356301397085\n",
      "Batch 294\n",
      "Loss for Batch(294): 0.003970920108258724\n",
      "Batch 295\n",
      "Loss for Batch(295): 0.00013046110689174384\n",
      "Batch 296\n",
      "Loss for Batch(296): 0.0020650201477110386\n",
      "Batch 297\n",
      "Loss for Batch(297): 0.007943447679281235\n",
      "Batch 298\n",
      "Loss for Batch(298): 0.028543995693325996\n",
      "Batch 299\n",
      "Loss for Batch(299): 6.079644663259387e-06\n",
      "Batch 300\n",
      "Loss for Batch(300): 0.00013613674673251808\n",
      "Batch 301\n",
      "Loss for Batch(301): 0.023710962384939194\n",
      "Batch 302\n",
      "Loss for Batch(302): 0.033750269562006\n",
      "Batch 303\n",
      "Loss for Batch(303): 5.346001125872135e-05\n",
      "Batch 304\n",
      "Loss for Batch(304): 0.00026666439953260124\n",
      "Batch 305\n",
      "Loss for Batch(305): 0.00047196264495141804\n",
      "Batch 306\n",
      "Loss for Batch(306): 0.019027436152100563\n",
      "Batch 307\n",
      "Loss for Batch(307): 0.004152541048824787\n",
      "Batch 308\n",
      "Loss for Batch(308): 0.0027743608225136995\n",
      "Batch 309\n",
      "Loss for Batch(309): 0.009447388350963593\n",
      "Batch 310\n",
      "Loss for Batch(310): 0.019339434802532196\n",
      "Batch 311\n",
      "Loss for Batch(311): 0.01804313249886036\n",
      "Batch 312\n",
      "Loss for Batch(312): 0.003442260203883052\n",
      "Batch 313\n",
      "Loss for Batch(313): 0.0011638823198154569\n",
      "Batch 314\n",
      "Loss for Batch(314): 0.0024101396556943655\n",
      "Batch 315\n",
      "Loss for Batch(315): 0.0004314066027291119\n",
      "Batch 316\n",
      "Loss for Batch(316): 0.0068914396688342094\n",
      "Batch 317\n",
      "Loss for Batch(317): 0.000643078179564327\n",
      "Batch 318\n",
      "Loss for Batch(318): 0.0038032259326428175\n",
      "Batch 319\n",
      "Loss for Batch(319): 0.0029906015843153\n",
      "Batch 320\n",
      "Loss for Batch(320): 0.0005974353989586234\n",
      "Batch 321\n",
      "Loss for Batch(321): 0.11361537873744965\n",
      "Batch 322\n",
      "Loss for Batch(322): 0.06655369699001312\n",
      "Batch 323\n",
      "Loss for Batch(323): 0.007103976793587208\n",
      "Batch 324\n",
      "Loss for Batch(324): 0.005683405790477991\n",
      "Batch 325\n",
      "Loss for Batch(325): 0.010004361160099506\n",
      "Batch 326\n",
      "Loss for Batch(326): 0.0009418912813998759\n",
      "Batch 327\n",
      "Loss for Batch(327): 0.0009467887575738132\n",
      "Batch 328\n",
      "Loss for Batch(328): 0.00027228990802541375\n",
      "Batch 329\n",
      "Loss for Batch(329): 5.4834010370541364e-05\n",
      "Batch 330\n",
      "Loss for Batch(330): 0.008417623117566109\n",
      "Batch 331\n",
      "Loss for Batch(331): 0.004931806121021509\n",
      "Batch 332\n",
      "Loss for Batch(332): 0.0005028073210269213\n",
      "Batch 333\n",
      "Loss for Batch(333): 0.0007065359968692064\n",
      "Batch 334\n",
      "Loss for Batch(334): 0.04536817595362663\n",
      "Batch 335\n",
      "Loss for Batch(335): 0.0010794305708259344\n",
      "Batch 336\n",
      "Loss for Batch(336): 0.019741619005799294\n",
      "Batch 337\n",
      "Loss for Batch(337): 0.0005786654073745012\n",
      "Batch 338\n",
      "Loss for Batch(338): 0.0004633591161109507\n",
      "Batch 339\n",
      "Loss for Batch(339): 0.008098467253148556\n",
      "Batch 340\n",
      "Loss for Batch(340): 0.012432782910764217\n",
      "Batch 341\n",
      "Loss for Batch(341): 3.176816608174704e-05\n",
      "Batch 342\n",
      "Loss for Batch(342): 0.001947046141140163\n",
      "Batch 343\n",
      "Loss for Batch(343): 0.00758410943672061\n",
      "Batch 344\n",
      "Loss for Batch(344): 0.004646478220820427\n",
      "Batch 345\n",
      "Loss for Batch(345): 0.2985396981239319\n",
      "Batch 346\n",
      "Loss for Batch(346): 0.006117419805377722\n",
      "Batch 347\n",
      "Loss for Batch(347): 0.013934268616139889\n",
      "Batch 348\n",
      "Loss for Batch(348): 0.005877759773284197\n",
      "Batch 349\n",
      "Loss for Batch(349): 0.0014130225172266364\n",
      "Batch 350\n",
      "Loss for Batch(350): 0.0016168189467862248\n",
      "Batch 351\n",
      "Loss for Batch(351): 0.004877557046711445\n",
      "Batch 352\n",
      "Loss for Batch(352): 0.00763062434270978\n",
      "Batch 353\n",
      "Loss for Batch(353): 0.00348436227068305\n",
      "Batch 354\n",
      "Loss for Batch(354): 0.005428931675851345\n",
      "Batch 355\n",
      "Loss for Batch(355): 1.017256736755371\n",
      "Batch 356\n",
      "Loss for Batch(356): 0.13333047926425934\n",
      "Batch 357\n",
      "Loss for Batch(357): 0.0002304452791577205\n",
      "Batch 358\n",
      "Loss for Batch(358): 0.00031647938885726035\n",
      "Batch 359\n",
      "Loss for Batch(359): 9.043834143085405e-05\n",
      "Batch 360\n",
      "Loss for Batch(360): 0.0641489326953888\n",
      "Batch 361\n",
      "Loss for Batch(361): 0.023263325914740562\n",
      "Batch 362\n",
      "Loss for Batch(362): 2.5986717446357943e-05\n",
      "Batch 363\n",
      "Loss for Batch(363): 0.4441453218460083\n",
      "Batch 364\n",
      "Loss for Batch(364): 0.2885209023952484\n",
      "Batch 365\n",
      "Loss for Batch(365): 0.0066394442692399025\n",
      "Batch 366\n",
      "Loss for Batch(366): 0.009002196602523327\n",
      "Batch 367\n",
      "Loss for Batch(367): 0.18623343110084534\n",
      "Batch 368\n",
      "Loss for Batch(368): 0.22279642522335052\n",
      "Batch 369\n",
      "Loss for Batch(369): 0.002327343914657831\n",
      "Batch 370\n",
      "Loss for Batch(370): 0.005414783023297787\n",
      "Batch 371\n",
      "Loss for Batch(371): 0.0001465633831685409\n",
      "Batch 372\n",
      "Loss for Batch(372): 0.0011170947691425681\n",
      "Batch 373\n",
      "Loss for Batch(373): 0.0005884282290935516\n",
      "Batch 374\n",
      "Loss for Batch(374): 0.014912229031324387\n",
      "Batch 375\n",
      "Loss for Batch(375): 0.027350667864084244\n",
      "Batch 376\n",
      "Loss for Batch(376): 0.0011511719785630703\n",
      "Batch 377\n",
      "Loss for Batch(377): 0.004321807064116001\n",
      "Batch 378\n",
      "Loss for Batch(378): 0.019835224375128746\n",
      "Batch 379\n",
      "Loss for Batch(379): 3.7459485611179844e-05\n",
      "Batch 380\n",
      "Loss for Batch(380): 0.003433084115386009\n",
      "Batch 381\n",
      "Loss for Batch(381): 0.00013909721747040749\n",
      "Batch 382\n",
      "Loss for Batch(382): 0.0005323434015735984\n",
      "Batch 383\n",
      "Loss for Batch(383): 0.0013777486747130752\n",
      "Batch 384\n",
      "Loss for Batch(384): 0.005968090146780014\n",
      "Batch 385\n",
      "Loss for Batch(385): 0.033610422164201736\n",
      "Batch 386\n",
      "Loss for Batch(386): 0.0006120146135799587\n",
      "Batch 387\n",
      "Loss for Batch(387): 0.00038152479100972414\n",
      "Batch 388\n",
      "Loss for Batch(388): 0.00219273054972291\n",
      "Batch 389\n",
      "Loss for Batch(389): 0.005319496151059866\n",
      "Batch 390\n",
      "Loss for Batch(390): 0.0008042035042308271\n",
      "Batch 391\n",
      "Loss for Batch(391): 0.0008247767109423876\n",
      "Batch 392\n",
      "Loss for Batch(392): 0.12511298060417175\n",
      "Batch 393\n",
      "Loss for Batch(393): 0.38497310876846313\n",
      "Batch 394\n",
      "Loss for Batch(394): 0.008929267525672913\n",
      "Batch 395\n",
      "Loss for Batch(395): 0.009410178288817406\n",
      "Batch 396\n",
      "Loss for Batch(396): 0.0008364244131371379\n",
      "Batch 397\n",
      "Loss for Batch(397): 0.0005792503943666816\n",
      "Batch 398\n",
      "Loss for Batch(398): 0.008571996353566647\n",
      "Batch 399\n",
      "Loss for Batch(399): 9.568811219651252e-05\n",
      "Batch 400\n",
      "Loss for Batch(400): 0.008358932100236416\n",
      "Batch 401\n",
      "Loss for Batch(401): 0.0573410764336586\n",
      "Batch 402\n",
      "Loss for Batch(402): 0.02330896630883217\n",
      "Batch 403\n",
      "Loss for Batch(403): 0.002065747044980526\n",
      "Batch 404\n",
      "Loss for Batch(404): 0.005276785697788\n",
      "Batch 405\n",
      "Loss for Batch(405): 0.0035890170838683844\n",
      "Batch 406\n",
      "Loss for Batch(406): 2.783480886137113e-05\n",
      "Batch 407\n",
      "Loss for Batch(407): 0.03117591142654419\n",
      "Batch 408\n",
      "Loss for Batch(408): 0.07381343841552734\n",
      "Batch 409\n",
      "Loss for Batch(409): 0.006310608237981796\n",
      "Batch 410\n",
      "Loss for Batch(410): 0.0008712773560546339\n",
      "Batch 411\n",
      "Loss for Batch(411): 0.004710542503744364\n",
      "Batch 412\n",
      "Loss for Batch(412): 0.002022179076448083\n",
      "Batch 413\n",
      "Loss for Batch(413): 0.0027813012711703777\n",
      "Batch 414\n",
      "Loss for Batch(414): 0.0324014350771904\n",
      "Batch 415\n",
      "Loss for Batch(415): 0.0012193849543109536\n",
      "Batch 416\n",
      "Loss for Batch(416): 0.027875490486621857\n",
      "Batch 417\n",
      "Loss for Batch(417): 0.1473373919725418\n",
      "Batch 418\n",
      "Loss for Batch(418): 0.008148173801600933\n",
      "Batch 419\n",
      "Loss for Batch(419): 0.00010677317914087325\n",
      "Batch 420\n",
      "Loss for Batch(420): 0.0027494323439896107\n",
      "Batch 421\n",
      "Loss for Batch(421): 0.18392479419708252\n",
      "Batch 422\n",
      "Loss for Batch(422): 0.0017180773429572582\n",
      "Batch 423\n",
      "Loss for Batch(423): 0.00423992658033967\n",
      "Batch 424\n",
      "Loss for Batch(424): 0.03752777725458145\n",
      "Batch 425\n",
      "Loss for Batch(425): 0.003078552894294262\n",
      "Batch 426\n",
      "Loss for Batch(426): 0.0018793413182720542\n",
      "Batch 427\n",
      "Loss for Batch(427): 0.03839200362563133\n",
      "Batch 428\n",
      "Loss for Batch(428): 0.034150004386901855\n",
      "Batch 429\n",
      "Loss for Batch(429): 0.0028733345679938793\n",
      "Batch 430\n",
      "Loss for Batch(430): 0.004880237393081188\n",
      "Batch 431\n",
      "Loss for Batch(431): 0.0029038963839411736\n",
      "Batch 432\n",
      "Loss for Batch(432): 0.0008284237701445818\n",
      "Batch 433\n",
      "Loss for Batch(433): 0.0004815482534468174\n",
      "Batch 434\n",
      "Loss for Batch(434): 0.006302474532276392\n",
      "Batch 435\n",
      "Loss for Batch(435): 0.0450165793299675\n",
      "Batch 436\n",
      "Loss for Batch(436): 0.006825578864663839\n",
      "Batch 437\n",
      "Loss for Batch(437): 1.2487069398048334e-05\n",
      "Batch 438\n",
      "Loss for Batch(438): 0.0005633223918266594\n",
      "Batch 439\n",
      "Loss for Batch(439): 0.007447892799973488\n",
      "Batch 440\n",
      "Loss for Batch(440): 1.3619504898088053e-05\n",
      "Batch 441\n",
      "Loss for Batch(441): 0.00019892238196916878\n",
      "Batch 442\n",
      "Loss for Batch(442): 0.008119544014334679\n",
      "Batch 443\n",
      "Loss for Batch(443): 0.00027448570472188294\n",
      "Batch 444\n",
      "Loss for Batch(444): 0.011532779783010483\n",
      "Batch 445\n",
      "Loss for Batch(445): 0.0008801674703136086\n",
      "Batch 446\n",
      "Loss for Batch(446): 0.004685382824391127\n",
      "Batch 447\n",
      "Loss for Batch(447): 0.011088233441114426\n",
      "Batch 448\n",
      "Loss for Batch(448): 0.0017899505328387022\n",
      "Batch 449\n",
      "Loss for Batch(449): 0.001891902880743146\n",
      "Batch 450\n",
      "Loss for Batch(450): 0.00036553567042574286\n",
      "Batch 451\n",
      "Loss for Batch(451): 0.028428886085748672\n",
      "Batch 452\n",
      "Loss for Batch(452): 0.0038024932146072388\n",
      "Batch 453\n",
      "Loss for Batch(453): 0.014508449472486973\n",
      "Batch 454\n",
      "Loss for Batch(454): 0.0004049729323014617\n",
      "Batch 455\n",
      "Loss for Batch(455): 0.0024845206644386053\n",
      "Batch 456\n",
      "Loss for Batch(456): 0.0001791950926417485\n",
      "Batch 457\n",
      "Loss for Batch(457): 0.002154494868591428\n",
      "Batch 458\n",
      "Loss for Batch(458): 0.0005508881877176464\n",
      "Batch 459\n",
      "Loss for Batch(459): 0.003414490493014455\n",
      "Batch 460\n",
      "Loss for Batch(460): 0.009435814805328846\n",
      "Batch 461\n",
      "Loss for Batch(461): 1.722530578263104e-05\n",
      "Batch 462\n",
      "Loss for Batch(462): 0.02723078615963459\n",
      "Batch 463\n",
      "Loss for Batch(463): 0.06764564663171768\n",
      "Batch 464\n",
      "Loss for Batch(464): 0.012924980372190475\n",
      "Batch 465\n",
      "Loss for Batch(465): 0.0007658146787434816\n",
      "Batch 466\n",
      "Loss for Batch(466): 0.0001937381166499108\n",
      "Batch 467\n",
      "Loss for Batch(467): 7.172984624048695e-05\n",
      "Batch 468\n",
      "Loss for Batch(468): 0.058887775987386703\n",
      "Batch 469\n",
      "Loss for Batch(469): 0.0025809204671531916\n",
      "Batch 470\n",
      "Loss for Batch(470): 0.0007302789017558098\n",
      "Batch 471\n",
      "Loss for Batch(471): 0.004833962768316269\n",
      "Batch 472\n",
      "Loss for Batch(472): 0.023256639018654823\n",
      "Batch 473\n",
      "Loss for Batch(473): 0.00265944073908031\n",
      "Batch 474\n",
      "Loss for Batch(474): 0.001176880206912756\n",
      "Batch 475\n",
      "Loss for Batch(475): 0.0006596890743821859\n",
      "Batch 476\n",
      "Loss for Batch(476): 0.0011609378270804882\n",
      "Batch 477\n",
      "Loss for Batch(477): 0.06398212164640427\n",
      "Batch 478\n",
      "Loss for Batch(478): 0.0012964275665581226\n",
      "Batch 479\n",
      "Loss for Batch(479): 0.002761749317869544\n",
      "Batch 480\n",
      "Loss for Batch(480): 0.026172969490289688\n",
      "Batch 481\n",
      "Loss for Batch(481): 0.0036087529733777046\n",
      "Batch 482\n",
      "Loss for Batch(482): 0.005326743703335524\n",
      "Batch 483\n",
      "Loss for Batch(483): 0.057910315692424774\n",
      "Batch 484\n",
      "Loss for Batch(484): 0.008794847875833511\n",
      "Batch 485\n",
      "Loss for Batch(485): 0.0012025970499962568\n",
      "Batch 486\n",
      "Loss for Batch(486): 0.0008267968078143895\n",
      "Batch 487\n",
      "Loss for Batch(487): 0.016169454902410507\n",
      "Batch 488\n",
      "Loss for Batch(488): 0.02230503410100937\n",
      "Batch 489\n",
      "Loss for Batch(489): 0.03234274312853813\n",
      "Batch 490\n",
      "Loss for Batch(490): 0.006263934075832367\n",
      "Batch 491\n",
      "Loss for Batch(491): 0.0034214272163808346\n",
      "Batch 492\n",
      "Loss for Batch(492): 0.027625765651464462\n",
      "Batch 493\n",
      "Loss for Batch(493): 0.007040371187031269\n",
      "Batch 494\n",
      "Loss for Batch(494): 0.009944160468876362\n",
      "Batch 495\n",
      "Loss for Batch(495): 0.004053971264511347\n",
      "Batch 496\n",
      "Loss for Batch(496): 0.00022210049792192876\n",
      "Batch 497\n",
      "Loss for Batch(497): 0.031849995255470276\n",
      "Batch 498\n",
      "Loss for Batch(498): 0.00132844562176615\n",
      "Batch 499\n",
      "Loss for Batch(499): 5.5340486142085865e-05\n",
      "Batch 500\n",
      "Loss for Batch(500): 0.006732579320669174\n",
      "Batch 501\n",
      "Loss for Batch(501): 0.02056349441409111\n",
      "Batch 502\n",
      "Loss for Batch(502): 0.004194383975118399\n",
      "Batch 503\n",
      "Loss for Batch(503): 0.000504783121868968\n",
      "Batch 504\n",
      "Loss for Batch(504): 0.020574169233441353\n",
      "Batch 505\n",
      "Loss for Batch(505): 0.0031759897246956825\n",
      "Batch 506\n",
      "Loss for Batch(506): 0.00023372331634163857\n",
      "Batch 507\n",
      "Loss for Batch(507): 0.052668988704681396\n",
      "Batch 508\n",
      "Loss for Batch(508): 0.025639308616518974\n",
      "Batch 509\n",
      "Loss for Batch(509): 0.00020520863472484052\n",
      "Batch 510\n",
      "Loss for Batch(510): 0.001597858383320272\n",
      "Batch 511\n",
      "Loss for Batch(511): 0.008289596065878868\n",
      "Batch 512\n",
      "Loss for Batch(512): 5.974730447633192e-05\n",
      "Batch 513\n",
      "Loss for Batch(513): 0.00174897990655154\n",
      "Batch 514\n",
      "Loss for Batch(514): 0.014975110068917274\n",
      "Batch 515\n",
      "Loss for Batch(515): 0.035167332738637924\n",
      "Batch 516\n",
      "Loss for Batch(516): 0.0076253172010183334\n",
      "Batch 517\n",
      "Loss for Batch(517): 0.05864657461643219\n",
      "Batch 518\n",
      "Loss for Batch(518): 0.0015721775125712156\n",
      "Batch 519\n",
      "Loss for Batch(519): 0.04785548523068428\n",
      "Batch 520\n",
      "Loss for Batch(520): 0.018494170159101486\n",
      "Batch 521\n",
      "Loss for Batch(521): 0.001135889906436205\n",
      "Batch 522\n",
      "Loss for Batch(522): 0.003195530502125621\n",
      "Batch 523\n",
      "Loss for Batch(523): 0.001738994033075869\n",
      "Batch 524\n",
      "Loss for Batch(524): 0.0010070408461615443\n",
      "Batch 525\n",
      "Loss for Batch(525): 0.0002860161184798926\n",
      "Batch 526\n",
      "Loss for Batch(526): 0.20397253334522247\n",
      "Batch 527\n",
      "Loss for Batch(527): 3.546347943483852e-05\n",
      "Batch 528\n",
      "Loss for Batch(528): 0.0003010720538441092\n",
      "Batch 529\n",
      "Loss for Batch(529): 0.00036674991133622825\n",
      "Batch 530\n",
      "Loss for Batch(530): 3.6476201785262674e-05\n",
      "Batch 531\n",
      "Loss for Batch(531): 0.016713086515665054\n",
      "Batch 532\n",
      "Loss for Batch(532): 3.257259959354997e-05\n",
      "Batch 533\n",
      "Loss for Batch(533): 0.0005068009486421943\n",
      "Batch 534\n",
      "Loss for Batch(534): 0.0003354331711307168\n",
      "Batch 535\n",
      "Loss for Batch(535): 0.003956792876124382\n",
      "Batch 536\n",
      "Loss for Batch(536): 0.1628696173429489\n",
      "Batch 537\n",
      "Loss for Batch(537): 0.013874702155590057\n",
      "Batch 538\n",
      "Loss for Batch(538): 0.001248796470463276\n",
      "Batch 539\n",
      "Loss for Batch(539): 0.03491233289241791\n",
      "Batch 540\n",
      "Loss for Batch(540): 0.0017602706793695688\n",
      "Batch 541\n",
      "Loss for Batch(541): 0.0017243907786905766\n",
      "Batch 542\n",
      "Loss for Batch(542): 0.0007661429117433727\n",
      "Batch 543\n",
      "Loss for Batch(543): 0.012306719087064266\n",
      "Batch 544\n",
      "Loss for Batch(544): 0.0009116483270190656\n",
      "Batch 545\n",
      "Loss for Batch(545): 0.0024151508696377277\n",
      "Batch 546\n",
      "Loss for Batch(546): 0.0002634869597386569\n",
      "Batch 547\n",
      "Loss for Batch(547): 0.0029209754429757595\n",
      "Batch 548\n",
      "Loss for Batch(548): 3.3586158679099753e-05\n",
      "Batch 549\n",
      "Loss for Batch(549): 0.0005528288893401623\n",
      "Batch 550\n",
      "Loss for Batch(550): 0.01220691204071045\n",
      "Batch 551\n",
      "Loss for Batch(551): 0.0265209898352623\n",
      "Batch 552\n",
      "Loss for Batch(552): 0.006960781291127205\n",
      "Batch 553\n",
      "Loss for Batch(553): 0.09077367186546326\n",
      "Batch 554\n",
      "Loss for Batch(554): 0.0005968862678855658\n",
      "Batch 555\n",
      "Loss for Batch(555): 0.009898368269205093\n",
      "Batch 556\n",
      "Loss for Batch(556): 0.0002120985882356763\n",
      "Batch 557\n",
      "Loss for Batch(557): 0.0003311902401037514\n",
      "Batch 558\n",
      "Loss for Batch(558): 0.00011841795640066266\n",
      "Batch 559\n",
      "Loss for Batch(559): 0.0015074346447363496\n",
      "Batch 560\n",
      "Loss for Batch(560): 0.022333601489663124\n",
      "Batch 561\n",
      "Loss for Batch(561): 0.029790623113512993\n",
      "Batch 562\n",
      "Loss for Batch(562): 0.027252960950136185\n",
      "Batch 563\n",
      "Loss for Batch(563): 0.004301770590245724\n",
      "Batch 564\n",
      "Loss for Batch(564): 0.0006684738327749074\n",
      "Batch 565\n",
      "Loss for Batch(565): 0.02467644028365612\n",
      "Batch 566\n",
      "Loss for Batch(566): 0.002407797845080495\n",
      "Batch 567\n",
      "Loss for Batch(567): 0.0005778149934485555\n",
      "Batch 568\n",
      "Loss for Batch(568): 7.178954547271132e-05\n",
      "Batch 569\n",
      "Loss for Batch(569): 0.01847236044704914\n",
      "Batch 570\n",
      "Loss for Batch(570): 0.0007279508281499147\n",
      "Batch 571\n",
      "Loss for Batch(571): 0.020733583718538284\n",
      "Batch 572\n",
      "Loss for Batch(572): 0.012642397545278072\n",
      "Batch 573\n",
      "Loss for Batch(573): 0.002231461927294731\n",
      "Batch 574\n",
      "Loss for Batch(574): 0.0003990644763689488\n",
      "Batch 575\n",
      "Loss for Batch(575): 0.001504823681898415\n",
      "Batch 576\n",
      "Loss for Batch(576): 1.9430790416663513e-05\n",
      "Batch 577\n",
      "Loss for Batch(577): 0.0016604089178144932\n",
      "Batch 578\n",
      "Loss for Batch(578): 0.0031645959243178368\n",
      "Batch 579\n",
      "Loss for Batch(579): 0.0036461299750953913\n",
      "Batch 580\n",
      "Loss for Batch(580): 0.009357656352221966\n",
      "Batch 581\n",
      "Loss for Batch(581): 0.0016899564070627093\n",
      "Batch 582\n",
      "Loss for Batch(582): 0.08186499774456024\n",
      "Batch 583\n",
      "Loss for Batch(583): 0.002458499278873205\n",
      "Batch 584\n",
      "Loss for Batch(584): 0.006428059656172991\n",
      "Batch 585\n",
      "Loss for Batch(585): 0.01782187819480896\n",
      "Batch 586\n",
      "Loss for Batch(586): 4.3806590838357806e-05\n",
      "Batch 587\n",
      "Loss for Batch(587): 0.0005739417392760515\n",
      "Batch 588\n",
      "Loss for Batch(588): 0.02013670839369297\n",
      "Batch 589\n",
      "Loss for Batch(589): 7.53915446694009e-05\n",
      "Batch 590\n",
      "Loss for Batch(590): 0.0036977315321564674\n",
      "Batch 591\n",
      "Loss for Batch(591): 0.008052458055317402\n",
      "Batch 592\n",
      "Loss for Batch(592): 0.0333908312022686\n",
      "Batch 593\n",
      "Loss for Batch(593): 0.0015994380228221416\n",
      "Batch 594\n",
      "Loss for Batch(594): 8.087575406534597e-05\n",
      "Batch 595\n",
      "Loss for Batch(595): 3.1738261895952746e-05\n",
      "Batch 596\n",
      "Loss for Batch(596): 0.0028640481177717447\n",
      "Batch 597\n",
      "Loss for Batch(597): 0.00039433164056390524\n",
      "Batch 598\n",
      "Loss for Batch(598): 0.00012941451859660447\n",
      "Batch 599\n",
      "Loss for Batch(599): 0.00021253532031551003\n",
      "Batch 600\n",
      "Loss for Batch(600): 0.00012992575648240745\n",
      "Batch 601\n",
      "Loss for Batch(601): 0.03952794149518013\n",
      "Batch 602\n",
      "Loss for Batch(602): 0.00057886604918167\n",
      "Batch 603\n",
      "Loss for Batch(603): 0.0001889218983706087\n",
      "Batch 604\n",
      "Loss for Batch(604): 0.024115219712257385\n",
      "Batch 605\n",
      "Loss for Batch(605): 0.007962565869092941\n",
      "Batch 606\n",
      "Loss for Batch(606): 0.00435933331027627\n",
      "Batch 607\n",
      "Loss for Batch(607): 0.01085294783115387\n",
      "Batch 608\n",
      "Loss for Batch(608): 0.0005391177255660295\n",
      "Batch 609\n",
      "Loss for Batch(609): 0.01322912611067295\n",
      "Batch 610\n",
      "Loss for Batch(610): 4.842557245865464e-05\n",
      "Batch 611\n",
      "Loss for Batch(611): 0.003308864776045084\n",
      "Batch 612\n",
      "Loss for Batch(612): 0.07951316237449646\n",
      "Batch 613\n",
      "Loss for Batch(613): 0.00474892882630229\n",
      "Batch 614\n",
      "Loss for Batch(614): 0.002659362740814686\n",
      "Batch 615\n",
      "Loss for Batch(615): 0.0001246700412593782\n",
      "Batch 616\n",
      "Loss for Batch(616): 0.04991736635565758\n",
      "Batch 617\n",
      "Loss for Batch(617): 0.0024153871927410364\n",
      "Batch 618\n",
      "Loss for Batch(618): 0.0011631519300863147\n",
      "Batch 619\n",
      "Loss for Batch(619): 9.491216042079031e-05\n",
      "Batch 620\n",
      "Loss for Batch(620): 0.0008215877460315824\n",
      "Batch 621\n",
      "Loss for Batch(621): 0.00985906831920147\n",
      "Batch 622\n",
      "Loss for Batch(622): 0.007290810812264681\n",
      "Batch 623\n",
      "Loss for Batch(623): 8.13596216175938e-06\n",
      "Batch 624\n",
      "Loss for Batch(624): 0.009821058250963688\n",
      "Batch 625\n",
      "Loss for Batch(625): 0.004257798660546541\n",
      "Batch 626\n",
      "Loss for Batch(626): 4.3150808778591454e-05\n",
      "Batch 627\n",
      "Loss for Batch(627): 0.0019346619956195354\n",
      "Batch 628\n",
      "Loss for Batch(628): 0.0423845574259758\n",
      "Batch 629\n",
      "Loss for Batch(629): 0.0024295509792864323\n",
      "Batch 630\n",
      "Loss for Batch(630): 0.006933961529284716\n",
      "Batch 631\n",
      "Loss for Batch(631): 6.049829607945867e-06\n",
      "Batch 632\n",
      "Loss for Batch(632): 0.5540617108345032\n",
      "Batch 633\n",
      "Loss for Batch(633): 0.00012491374218370765\n",
      "Batch 634\n",
      "Loss for Batch(634): 0.25728583335876465\n",
      "Batch 635\n",
      "Loss for Batch(635): 0.030005743727087975\n",
      "Batch 636\n",
      "Loss for Batch(636): 0.006825906224548817\n",
      "Batch 637\n",
      "Loss for Batch(637): 0.001065624412149191\n",
      "Batch 638\n",
      "Loss for Batch(638): 0.10038716346025467\n",
      "Batch 639\n",
      "Loss for Batch(639): 0.0013678462710231543\n",
      "Batch 640\n",
      "Loss for Batch(640): 0.00037599087227135897\n",
      "Batch 641\n",
      "Loss for Batch(641): 0.00015143162454478443\n",
      "Batch 642\n",
      "Loss for Batch(642): 0.001887819031253457\n",
      "Batch 643\n",
      "Loss for Batch(643): 0.0354151576757431\n",
      "Batch 644\n",
      "Loss for Batch(644): 0.00034115728340111673\n",
      "Batch 645\n",
      "Loss for Batch(645): 0.022503504529595375\n",
      "Batch 646\n",
      "Loss for Batch(646): 0.00494347931817174\n",
      "Batch 647\n",
      "Loss for Batch(647): 0.004520679358392954\n",
      "Batch 648\n",
      "Loss for Batch(648): 0.019198337569832802\n",
      "Batch 649\n",
      "Loss for Batch(649): 0.07569631189107895\n",
      "Batch 650\n",
      "Loss for Batch(650): 0.00013531427248381078\n",
      "Batch 651\n",
      "Loss for Batch(651): 0.020950989797711372\n",
      "Batch 652\n",
      "Loss for Batch(652): 0.08879557996988297\n",
      "Batch 653\n",
      "Loss for Batch(653): 0.014465812593698502\n",
      "Batch 654\n",
      "Loss for Batch(654): 0.0493781715631485\n",
      "Batch 655\n",
      "Loss for Batch(655): 0.49476680159568787\n",
      "Batch 656\n",
      "Loss for Batch(656): 0.0028585188556462526\n",
      "Batch 657\n",
      "Loss for Batch(657): 0.0025179339572787285\n",
      "Batch 658\n",
      "Loss for Batch(658): 0.0013110660947859287\n",
      "Batch 659\n",
      "Loss for Batch(659): 0.33633023500442505\n",
      "Batch 660\n",
      "Loss for Batch(660): 0.015459039248526096\n",
      "Batch 661\n",
      "Loss for Batch(661): 0.10545296221971512\n",
      "Batch 662\n",
      "Loss for Batch(662): 0.00790739618241787\n",
      "Batch 663\n",
      "Loss for Batch(663): 0.003059685230255127\n",
      "Batch 664\n",
      "Loss for Batch(664): 7.113043830031529e-05\n",
      "Batch 665\n",
      "Loss for Batch(665): 0.04362395405769348\n",
      "Batch 666\n",
      "Loss for Batch(666): 0.0010915043530985713\n",
      "Batch 667\n",
      "Loss for Batch(667): 0.015313503332436085\n",
      "Batch 668\n",
      "Loss for Batch(668): 0.068417027592659\n",
      "Batch 669\n",
      "Loss for Batch(669): 0.05486064404249191\n",
      "Batch 670\n",
      "Loss for Batch(670): 0.037579189985990524\n",
      "Batch 671\n",
      "Loss for Batch(671): 0.010112863965332508\n",
      "Batch 672\n",
      "Loss for Batch(672): 0.0015667773550376296\n",
      "Batch 673\n",
      "Loss for Batch(673): 0.002222367562353611\n",
      "Batch 674\n",
      "Loss for Batch(674): 0.011057657189667225\n",
      "Batch 675\n",
      "Loss for Batch(675): 0.02094900794327259\n",
      "Batch 676\n",
      "Loss for Batch(676): 0.0009699742076918483\n",
      "Batch 677\n",
      "Loss for Batch(677): 0.0008625657646916807\n",
      "Batch 678\n",
      "Loss for Batch(678): 0.00019172322936356068\n",
      "Batch 679\n",
      "Loss for Batch(679): 0.013566640205681324\n",
      "Batch 680\n",
      "Loss for Batch(680): 5.906580918235704e-05\n",
      "Batch 681\n",
      "Loss for Batch(681): 1.788115332601592e-05\n",
      "Batch 682\n",
      "Loss for Batch(682): 0.002126675099134445\n",
      "Batch 683\n",
      "Loss for Batch(683): 0.0008199582807719707\n",
      "Batch 684\n",
      "Loss for Batch(684): 0.0024973906110972166\n",
      "Batch 685\n",
      "Loss for Batch(685): 0.022583825513720512\n",
      "Batch 686\n",
      "Loss for Batch(686): 0.006444156635552645\n",
      "Batch 687\n",
      "Loss for Batch(687): 0.029811352491378784\n",
      "Batch 688\n",
      "Loss for Batch(688): 0.16897383332252502\n",
      "Batch 689\n",
      "Loss for Batch(689): 0.10683713108301163\n",
      "Batch 690\n",
      "Loss for Batch(690): 0.000327031739288941\n",
      "Batch 691\n",
      "Loss for Batch(691): 6.835797103121877e-05\n",
      "Batch 692\n",
      "Loss for Batch(692): 0.03793719783425331\n",
      "Batch 693\n",
      "Loss for Batch(693): 0.24427127838134766\n",
      "Batch 694\n",
      "Loss for Batch(694): 0.001183979562483728\n",
      "Batch 695\n",
      "Loss for Batch(695): 0.0009088479564525187\n",
      "Batch 696\n",
      "Loss for Batch(696): 0.00014967945753596723\n",
      "Batch 697\n",
      "Loss for Batch(697): 0.0004918742924928665\n",
      "Batch 698\n",
      "Loss for Batch(698): 0.1109543889760971\n",
      "Batch 699\n",
      "Loss for Batch(699): 0.0005881646648049355\n",
      "Batch 700\n",
      "Loss for Batch(700): 0.0029427080880850554\n",
      "Batch 701\n",
      "Loss for Batch(701): 0.004651892464607954\n",
      "Batch 702\n",
      "Loss for Batch(702): 0.0038175268564373255\n",
      "Batch 703\n",
      "Loss for Batch(703): 0.47598960995674133\n",
      "Batch 704\n",
      "Loss for Batch(704): 0.021749382838606834\n",
      "Batch 705\n",
      "Loss for Batch(705): 0.00019733331282623112\n",
      "Batch 706\n",
      "Loss for Batch(706): 0.2246047407388687\n",
      "Batch 707\n",
      "Loss for Batch(707): 0.004934607073664665\n",
      "Batch 708\n",
      "Loss for Batch(708): 0.12431160360574722\n",
      "Batch 709\n",
      "Loss for Batch(709): 0.0009443837334401906\n",
      "Batch 710\n",
      "Loss for Batch(710): 0.004087972454726696\n",
      "Batch 711\n",
      "Loss for Batch(711): 0.00032566036679781973\n",
      "Batch 712\n",
      "Loss for Batch(712): 0.05135726183652878\n",
      "Batch 713\n",
      "Loss for Batch(713): 0.21253205835819244\n",
      "Batch 714\n",
      "Loss for Batch(714): 0.23008349537849426\n",
      "Batch 715\n",
      "Loss for Batch(715): 0.0002922773128375411\n",
      "Batch 716\n",
      "Loss for Batch(716): 0.059309568256139755\n",
      "Batch 717\n",
      "Loss for Batch(717): 4.330108276917599e-05\n",
      "Batch 718\n",
      "Loss for Batch(718): 0.007425412070006132\n",
      "Batch 719\n",
      "Loss for Batch(719): 0.011356092058122158\n",
      "Batch 720\n",
      "Loss for Batch(720): 0.0008272071718238294\n",
      "Batch 721\n",
      "Loss for Batch(721): 0.03615555539727211\n",
      "Batch 722\n",
      "Loss for Batch(722): 6.648385897278786e-05\n",
      "Batch 723\n",
      "Loss for Batch(723): 0.004969398491084576\n",
      "Batch 724\n",
      "Loss for Batch(724): 0.020894739776849747\n",
      "Batch 725\n",
      "Loss for Batch(725): 0.13582180440425873\n",
      "Batch 726\n",
      "Loss for Batch(726): 0.09578175842761993\n",
      "Batch 727\n",
      "Loss for Batch(727): 0.0002840078086592257\n",
      "Batch 728\n",
      "Loss for Batch(728): 0.005063326098024845\n",
      "Batch 729\n",
      "Loss for Batch(729): 0.00812201201915741\n",
      "Batch 730\n",
      "Loss for Batch(730): 0.010390540584921837\n",
      "Batch 731\n",
      "Loss for Batch(731): 0.003553827293217182\n",
      "Batch 732\n",
      "Loss for Batch(732): 0.029764629900455475\n",
      "Batch 733\n",
      "Loss for Batch(733): 0.005820693913847208\n",
      "Batch 734\n",
      "Loss for Batch(734): 3.388404002180323e-05\n",
      "Batch 735\n",
      "Loss for Batch(735): 0.0030825678259134293\n",
      "Batch 736\n",
      "Loss for Batch(736): 0.0002960696292575449\n",
      "Batch 737\n",
      "Loss for Batch(737): 0.0010480189230293036\n",
      "Batch 738\n",
      "Loss for Batch(738): 0.0006089433445595205\n",
      "Batch 739\n",
      "Loss for Batch(739): 0.00028363161254674196\n",
      "Batch 740\n",
      "Loss for Batch(740): 0.008541250601410866\n",
      "Batch 741\n",
      "Loss for Batch(741): 0.01513352245092392\n",
      "Batch 742\n",
      "Loss for Batch(742): 0.036587223410606384\n",
      "Batch 743\n",
      "Loss for Batch(743): 0.009522088803350925\n",
      "Batch 744\n",
      "Loss for Batch(744): 0.03999647498130798\n",
      "Batch 745\n",
      "Loss for Batch(745): 0.012161042541265488\n",
      "Batch 746\n",
      "Loss for Batch(746): 0.0015632249414920807\n",
      "Batch 747\n",
      "Loss for Batch(747): 0.17475271224975586\n",
      "Batch 748\n",
      "Loss for Batch(748): 0.05519447848200798\n",
      "Batch 749\n",
      "Loss for Batch(749): 2.6046236598631367e-05\n",
      "Batch 750\n",
      "Loss for Batch(750): 0.0820271372795105\n",
      "Batch 751\n",
      "Loss for Batch(751): 0.1395176351070404\n",
      "Batch 752\n",
      "Loss for Batch(752): 0.0016339583089575171\n",
      "Batch 753\n",
      "Loss for Batch(753): 0.0025516352616250515\n",
      "Avg Loss for 754 Batches0.02352290905982115\n",
      "Epoch(99) Finished\n",
      "**********************************************\n",
      "Avg Test Loss:\n",
      "0.15761709437905636\n",
      "Test Accuracy:\n",
      "0.9455511288180611\n",
      "**********************************************\n",
      "******************Epoch(100):***********************\n",
      "Batch 1\n",
      "Loss for Batch(1): 0.0011528653558343649\n",
      "Batch 2\n",
      "Loss for Batch(2): 0.14724266529083252\n",
      "Batch 3\n",
      "Loss for Batch(3): 0.0015645876992493868\n",
      "Batch 4\n",
      "Loss for Batch(4): 9.702912939246744e-05\n",
      "Batch 5\n",
      "Loss for Batch(5): 0.004726180341094732\n",
      "Batch 6\n",
      "Loss for Batch(6): 0.046247340738773346\n",
      "Batch 7\n",
      "Loss for Batch(7): 0.018583400174975395\n",
      "Batch 8\n",
      "Loss for Batch(8): 0.03367772698402405\n",
      "Batch 9\n",
      "Loss for Batch(9): 0.0020388467237353325\n",
      "Batch 10\n",
      "Loss for Batch(10): 0.007479577325284481\n",
      "Batch 11\n",
      "Loss for Batch(11): 0.038211025297641754\n",
      "Batch 12\n",
      "Loss for Batch(12): 0.007476255297660828\n",
      "Batch 13\n",
      "Loss for Batch(13): 0.1063113808631897\n",
      "Batch 14\n",
      "Loss for Batch(14): 0.0019546989351511\n",
      "Batch 15\n",
      "Loss for Batch(15): 0.0057611772790551186\n",
      "Batch 16\n",
      "Loss for Batch(16): 0.00038698335993103683\n",
      "Batch 17\n",
      "Loss for Batch(17): 0.0007296120747923851\n",
      "Batch 18\n",
      "Loss for Batch(18): 0.010715021751821041\n",
      "Batch 19\n",
      "Loss for Batch(19): 0.00024942882009781897\n",
      "Batch 20\n",
      "Loss for Batch(20): 0.00040255303611047566\n",
      "Batch 21\n",
      "Loss for Batch(21): 0.004686630330979824\n",
      "Batch 22\n",
      "Loss for Batch(22): 0.003177855396643281\n",
      "Batch 23\n",
      "Loss for Batch(23): 0.00017845626280177385\n",
      "Batch 24\n",
      "Loss for Batch(24): 0.012404661625623703\n",
      "Batch 25\n",
      "Loss for Batch(25): 0.0012832239735871553\n",
      "Batch 26\n",
      "Loss for Batch(26): 0.010661711916327477\n",
      "Batch 27\n",
      "Loss for Batch(27): 0.040963925421237946\n",
      "Batch 28\n",
      "Loss for Batch(28): 1.7881047824630514e-05\n",
      "Batch 29\n",
      "Loss for Batch(29): 0.00020580773707479239\n",
      "Batch 30\n",
      "Loss for Batch(30): 0.012849778868258\n",
      "Batch 31\n",
      "Loss for Batch(31): 0.0074902367778122425\n",
      "Batch 32\n",
      "Loss for Batch(32): 0.001526857609860599\n",
      "Batch 33\n",
      "Loss for Batch(33): 0.0005942283314652741\n",
      "Batch 34\n",
      "Loss for Batch(34): 0.03691992163658142\n",
      "Batch 35\n",
      "Loss for Batch(35): 0.0001242187718162313\n",
      "Batch 36\n",
      "Loss for Batch(36): 0.01189324539154768\n",
      "Batch 37\n",
      "Loss for Batch(37): 0.011014461517333984\n",
      "Batch 38\n",
      "Loss for Batch(38): 0.14602124691009521\n",
      "Batch 39\n",
      "Loss for Batch(39): 0.031985294073820114\n",
      "Batch 40\n",
      "Loss for Batch(40): 0.16796506941318512\n",
      "Batch 41\n",
      "Loss for Batch(41): 0.04387849196791649\n",
      "Batch 42\n",
      "Loss for Batch(42): 0.007812188472598791\n",
      "Batch 43\n",
      "Loss for Batch(43): 0.004323121160268784\n",
      "Batch 44\n",
      "Loss for Batch(44): 0.0370146706700325\n",
      "Batch 45\n",
      "Loss for Batch(45): 0.00203142617829144\n",
      "Batch 46\n",
      "Loss for Batch(46): 0.00419077230617404\n",
      "Batch 47\n",
      "Loss for Batch(47): 0.001712145167402923\n",
      "Batch 48\n",
      "Loss for Batch(48): 0.051371753215789795\n",
      "Batch 49\n",
      "Loss for Batch(49): 0.005841064266860485\n",
      "Batch 50\n",
      "Loss for Batch(50): 0.05817616730928421\n",
      "Batch 51\n",
      "Loss for Batch(51): 0.008972398936748505\n",
      "Batch 52\n",
      "Loss for Batch(52): 0.026031050831079483\n",
      "Batch 53\n",
      "Loss for Batch(53): 0.08476021885871887\n",
      "Batch 54\n",
      "Loss for Batch(54): 0.004497922025620937\n",
      "Batch 55\n",
      "Loss for Batch(55): 0.001479866448789835\n",
      "Batch 56\n",
      "Loss for Batch(56): 0.0011083695571869612\n",
      "Batch 57\n",
      "Loss for Batch(57): 0.0023160963319242\n",
      "Batch 58\n",
      "Loss for Batch(58): 0.00044067041017115116\n",
      "Batch 59\n",
      "Loss for Batch(59): 0.0014264507917687297\n",
      "Batch 60\n",
      "Loss for Batch(60): 0.0028969377744942904\n",
      "Batch 61\n",
      "Loss for Batch(61): 0.004500324837863445\n",
      "Batch 62\n",
      "Loss for Batch(62): 0.003767964895814657\n",
      "Batch 63\n",
      "Loss for Batch(63): 0.005992155522108078\n",
      "Batch 64\n",
      "Loss for Batch(64): 0.00048168786452151835\n",
      "Batch 65\n",
      "Loss for Batch(65): 0.0025688912719488144\n",
      "Batch 66\n",
      "Loss for Batch(66): 0.073633573949337\n",
      "Batch 67\n",
      "Loss for Batch(67): 0.01909784972667694\n",
      "Batch 68\n",
      "Loss for Batch(68): 6.669294816674665e-05\n",
      "Batch 69\n",
      "Loss for Batch(69): 0.006836959160864353\n",
      "Batch 70\n",
      "Loss for Batch(70): 0.012600516900420189\n",
      "Batch 71\n",
      "Loss for Batch(71): 0.04625474289059639\n",
      "Batch 72\n",
      "Loss for Batch(72): 0.0038106199353933334\n",
      "Batch 73\n",
      "Loss for Batch(73): 0.00012422856525518\n",
      "Batch 74\n",
      "Loss for Batch(74): 0.006491514854133129\n",
      "Batch 75\n",
      "Loss for Batch(75): 0.010867759585380554\n",
      "Batch 76\n",
      "Loss for Batch(76): 0.0006764886202290654\n",
      "Batch 77\n",
      "Loss for Batch(77): 0.0009775171056389809\n",
      "Batch 78\n",
      "Loss for Batch(78): 3.010026148331235e-06\n",
      "Batch 79\n",
      "Loss for Batch(79): 0.013726772740483284\n",
      "Batch 80\n",
      "Loss for Batch(80): 0.0029916849453002214\n",
      "Batch 81\n",
      "Loss for Batch(81): 0.01230045035481453\n",
      "Batch 82\n",
      "Loss for Batch(82): 0.00689349789172411\n",
      "Batch 83\n",
      "Loss for Batch(83): 0.019602658227086067\n",
      "Batch 84\n",
      "Loss for Batch(84): 0.0008950307965278625\n",
      "Batch 85\n",
      "Loss for Batch(85): 0.01296045258641243\n",
      "Batch 86\n",
      "Loss for Batch(86): 4.0171773434849456e-05\n",
      "Batch 87\n",
      "Loss for Batch(87): 0.00154760736040771\n",
      "Batch 88\n",
      "Loss for Batch(88): 0.0006891355151310563\n",
      "Batch 89\n",
      "Loss for Batch(89): 0.0019118917407467961\n",
      "Batch 90\n",
      "Loss for Batch(90): 0.0058536529541015625\n",
      "Batch 91\n",
      "Loss for Batch(91): 0.0001394756545778364\n",
      "Batch 92\n",
      "Loss for Batch(92): 0.006143718957901001\n",
      "Batch 93\n",
      "Loss for Batch(93): 0.0035975943319499493\n",
      "Batch 94\n",
      "Loss for Batch(94): 0.00011632582754828036\n",
      "Batch 95\n",
      "Loss for Batch(95): 0.0010120354127138853\n",
      "Batch 96\n",
      "Loss for Batch(96): 0.0001937400083988905\n",
      "Batch 97\n",
      "Loss for Batch(97): 0.002559636253863573\n",
      "Batch 98\n",
      "Loss for Batch(98): 0.0016553723253309727\n",
      "Batch 99\n",
      "Loss for Batch(99): 0.002931451192125678\n",
      "Batch 100\n",
      "Loss for Batch(100): 0.023589882999658585\n",
      "Batch 101\n",
      "Loss for Batch(101): 0.0007518751081079245\n",
      "Batch 102\n",
      "Loss for Batch(102): 0.004244598094373941\n",
      "Batch 103\n",
      "Loss for Batch(103): 0.005021480843424797\n",
      "Batch 104\n",
      "Loss for Batch(104): 0.0011181274894624949\n",
      "Batch 105\n",
      "Loss for Batch(105): 0.0007676598615944386\n",
      "Batch 106\n",
      "Loss for Batch(106): 0.000974015099927783\n",
      "Batch 107\n",
      "Loss for Batch(107): 0.18368017673492432\n",
      "Batch 108\n",
      "Loss for Batch(108): 0.003098993096500635\n",
      "Batch 109\n",
      "Loss for Batch(109): 0.0017463674303144217\n",
      "Batch 110\n",
      "Loss for Batch(110): 0.0015042232116684318\n",
      "Batch 111\n",
      "Loss for Batch(111): 0.005157649517059326\n",
      "Batch 112\n",
      "Loss for Batch(112): 0.007217928301542997\n",
      "Batch 113\n",
      "Loss for Batch(113): 0.10369977355003357\n",
      "Batch 114\n",
      "Loss for Batch(114): 0.0014411845477297902\n",
      "Batch 115\n",
      "Loss for Batch(115): 0.006950227543711662\n",
      "Batch 116\n",
      "Loss for Batch(116): 0.0033169365487992764\n",
      "Batch 117\n",
      "Loss for Batch(117): 0.03984697535634041\n",
      "Batch 118\n",
      "Loss for Batch(118): 0.00030785935814492404\n",
      "Batch 119\n",
      "Loss for Batch(119): 0.018775340169668198\n",
      "Batch 120\n",
      "Loss for Batch(120): 0.0009810125920921564\n",
      "Batch 121\n",
      "Loss for Batch(121): 0.014394618570804596\n",
      "Batch 122\n",
      "Loss for Batch(122): 0.10682079941034317\n",
      "Batch 123\n",
      "Loss for Batch(123): 0.0005550169153138995\n",
      "Batch 124\n",
      "Loss for Batch(124): 0.0011961654527112842\n",
      "Batch 125\n",
      "Loss for Batch(125): 0.04478096961975098\n",
      "Batch 126\n",
      "Loss for Batch(126): 0.051117319613695145\n",
      "Batch 127\n",
      "Loss for Batch(127): 0.03180814906954765\n",
      "Batch 128\n",
      "Loss for Batch(128): 0.002556879771873355\n",
      "Batch 129\n",
      "Loss for Batch(129): 0.0052200742065906525\n",
      "Batch 130\n",
      "Loss for Batch(130): 0.0003571668639779091\n",
      "Batch 131\n",
      "Loss for Batch(131): 0.00023153837537392974\n",
      "Batch 132\n",
      "Loss for Batch(132): 0.047406092286109924\n",
      "Batch 133\n",
      "Loss for Batch(133): 5.942079587839544e-05\n",
      "Batch 134\n",
      "Loss for Batch(134): 0.1045001968741417\n",
      "Batch 135\n",
      "Loss for Batch(135): 0.003094477578997612\n",
      "Batch 136\n",
      "Loss for Batch(136): 0.0013075987808406353\n",
      "Batch 137\n",
      "Loss for Batch(137): 0.008135944604873657\n",
      "Batch 138\n",
      "Loss for Batch(138): 0.0006675982149317861\n",
      "Batch 139\n",
      "Loss for Batch(139): 0.011029938235878944\n",
      "Batch 140\n",
      "Loss for Batch(140): 0.0021720281802117825\n",
      "Batch 141\n",
      "Loss for Batch(141): 0.0015565246576443315\n",
      "Batch 142\n",
      "Loss for Batch(142): 0.008786600083112717\n",
      "Batch 143\n",
      "Loss for Batch(143): 0.002274140017107129\n",
      "Batch 144\n",
      "Loss for Batch(144): 0.012459130957722664\n",
      "Batch 145\n",
      "Loss for Batch(145): 0.0001774465199559927\n",
      "Batch 146\n",
      "Loss for Batch(146): 0.013167083263397217\n",
      "Batch 147\n",
      "Loss for Batch(147): 0.02673128992319107\n",
      "Batch 148\n",
      "Loss for Batch(148): 0.007802565116435289\n",
      "Batch 149\n",
      "Loss for Batch(149): 0.004593151155859232\n",
      "Batch 150\n",
      "Loss for Batch(150): 0.0016845052596181631\n",
      "Batch 151\n",
      "Loss for Batch(151): 0.00036590948002412915\n",
      "Batch 152\n",
      "Loss for Batch(152): 0.0034871650859713554\n",
      "Batch 153\n",
      "Loss for Batch(153): 0.0019512989092618227\n",
      "Batch 154\n",
      "Loss for Batch(154): 0.0016268104081973433\n",
      "Batch 155\n",
      "Loss for Batch(155): 0.0020980234257876873\n",
      "Batch 156\n",
      "Loss for Batch(156): 0.00042760977521538734\n",
      "Batch 157\n",
      "Loss for Batch(157): 0.12042813748121262\n",
      "Batch 158\n",
      "Loss for Batch(158): 0.2206670045852661\n",
      "Batch 159\n",
      "Loss for Batch(159): 0.003713908139616251\n",
      "Batch 160\n",
      "Loss for Batch(160): 0.00987155269831419\n",
      "Batch 161\n",
      "Loss for Batch(161): 0.04395183175802231\n",
      "Batch 162\n",
      "Loss for Batch(162): 0.0009415930253453553\n",
      "Batch 163\n",
      "Loss for Batch(163): 0.0019765207543969154\n",
      "Batch 164\n",
      "Loss for Batch(164): 0.00317001692019403\n",
      "Batch 165\n",
      "Loss for Batch(165): 0.0011508973548188806\n",
      "Batch 166\n",
      "Loss for Batch(166): 0.010852858424186707\n",
      "Batch 167\n",
      "Loss for Batch(167): 0.012649121694266796\n",
      "Batch 168\n",
      "Loss for Batch(168): 0.010621486231684685\n",
      "Batch 169\n",
      "Loss for Batch(169): 0.0002990968059748411\n",
      "Batch 170\n",
      "Loss for Batch(170): 0.048294611275196075\n",
      "Batch 171\n",
      "Loss for Batch(171): 0.0008381283842027187\n",
      "Batch 172\n",
      "Loss for Batch(172): 0.005382947623729706\n",
      "Batch 173\n",
      "Loss for Batch(173): 0.0030757393687963486\n",
      "Batch 174\n",
      "Loss for Batch(174): 0.10788044333457947\n",
      "Batch 175\n",
      "Loss for Batch(175): 0.0007095183245837688\n",
      "Batch 176\n",
      "Loss for Batch(176): 0.00137759477365762\n",
      "Batch 177\n",
      "Loss for Batch(177): 0.01954556629061699\n",
      "Batch 178\n",
      "Loss for Batch(178): 0.00012406843598000705\n",
      "Batch 179\n",
      "Loss for Batch(179): 0.00014329346595332026\n",
      "Batch 180\n",
      "Loss for Batch(180): 0.0014121615095064044\n",
      "Batch 181\n",
      "Loss for Batch(181): 0.0048419516533613205\n",
      "Batch 182\n",
      "Loss for Batch(182): 0.027760867029428482\n",
      "Batch 183\n",
      "Loss for Batch(183): 0.005559486337006092\n",
      "Batch 184\n",
      "Loss for Batch(184): 3.734031633939594e-05\n",
      "Batch 185\n",
      "Loss for Batch(185): 0.0033846967853605747\n",
      "Batch 186\n",
      "Loss for Batch(186): 0.009113957174122334\n",
      "Batch 187\n",
      "Loss for Batch(187): 2.9413737138384022e-05\n",
      "Batch 188\n",
      "Loss for Batch(188): 0.0008106022141873837\n",
      "Batch 189\n",
      "Loss for Batch(189): 0.10601048916578293\n",
      "Batch 190\n",
      "Loss for Batch(190): 0.0034022866748273373\n",
      "Batch 191\n",
      "Loss for Batch(191): 0.00021149648819118738\n",
      "Batch 192\n",
      "Loss for Batch(192): 0.014979367144405842\n",
      "Batch 193\n",
      "Loss for Batch(193): 0.014344568364322186\n",
      "Batch 194\n",
      "Loss for Batch(194): 0.01479166280478239\n",
      "Batch 195\n",
      "Loss for Batch(195): 0.0012745566200464964\n",
      "Batch 196\n",
      "Loss for Batch(196): 0.015704862773418427\n",
      "Batch 197\n",
      "Loss for Batch(197): 0.02207323908805847\n",
      "Batch 198\n",
      "Loss for Batch(198): 0.0047734081745147705\n",
      "Batch 199\n",
      "Loss for Batch(199): 0.00358140142634511\n",
      "Batch 200\n",
      "Loss for Batch(200): 0.0001951471931533888\n",
      "Batch 201\n",
      "Loss for Batch(201): 0.003438967280089855\n",
      "Batch 202\n",
      "Loss for Batch(202): 0.07410100847482681\n",
      "Batch 203\n",
      "Loss for Batch(203): 0.02390354871749878\n",
      "Batch 204\n",
      "Loss for Batch(204): 0.0002557896077632904\n",
      "Batch 205\n",
      "Loss for Batch(205): 0.020033711567521095\n",
      "Batch 206\n",
      "Loss for Batch(206): 0.0004215315857436508\n",
      "Batch 207\n",
      "Loss for Batch(207): 0.00646551325917244\n",
      "Batch 208\n",
      "Loss for Batch(208): 0.15061263740062714\n",
      "Batch 209\n",
      "Loss for Batch(209): 2.148701241821982e-05\n",
      "Batch 210\n",
      "Loss for Batch(210): 7.28022787370719e-05\n",
      "Batch 211\n",
      "Loss for Batch(211): 0.0008583440212532878\n",
      "Batch 212\n",
      "Loss for Batch(212): 0.017766471952199936\n",
      "Batch 213\n",
      "Loss for Batch(213): 0.05533193051815033\n",
      "Batch 214\n",
      "Loss for Batch(214): 0.00046058904263190925\n",
      "Batch 215\n",
      "Loss for Batch(215): 0.10118350386619568\n",
      "Batch 216\n",
      "Loss for Batch(216): 0.009425923228263855\n",
      "Batch 217\n",
      "Loss for Batch(217): 0.06623987853527069\n",
      "Batch 218\n",
      "Loss for Batch(218): 0.011486687697470188\n",
      "Batch 219\n",
      "Loss for Batch(219): 0.0051374477334320545\n",
      "Batch 220\n",
      "Loss for Batch(220): 0.0007287498447112739\n",
      "Batch 221\n",
      "Loss for Batch(221): 0.00010035650484496728\n",
      "Batch 222\n",
      "Loss for Batch(222): 0.005874942988157272\n",
      "Batch 223\n",
      "Loss for Batch(223): 0.00024230936833191663\n",
      "Batch 224\n",
      "Loss for Batch(224): 0.004818891640752554\n",
      "Batch 225\n",
      "Loss for Batch(225): 0.009300919249653816\n",
      "Batch 226\n",
      "Loss for Batch(226): 0.0001799194433260709\n",
      "Batch 227\n",
      "Loss for Batch(227): 0.026437504217028618\n",
      "Batch 228\n",
      "Loss for Batch(228): 0.014839718118309975\n",
      "Batch 229\n",
      "Loss for Batch(229): 0.03957630321383476\n",
      "Batch 230\n",
      "Loss for Batch(230): 0.031538233160972595\n",
      "Batch 231\n",
      "Loss for Batch(231): 0.005540140438824892\n",
      "Batch 232\n",
      "Loss for Batch(232): 0.019665434956550598\n",
      "Batch 233\n",
      "Loss for Batch(233): 0.015062489546835423\n",
      "Batch 234\n",
      "Loss for Batch(234): 0.0005190704832784832\n",
      "Batch 235\n",
      "Loss for Batch(235): 0.0033784094266593456\n",
      "Batch 236\n",
      "Loss for Batch(236): 0.016779493540525436\n",
      "Batch 237\n",
      "Loss for Batch(237): 0.0005694839637726545\n",
      "Batch 238\n",
      "Loss for Batch(238): 0.03526167944073677\n",
      "Batch 239\n",
      "Loss for Batch(239): 0.0014060306129977107\n",
      "Batch 240\n",
      "Loss for Batch(240): 0.011177719570696354\n",
      "Batch 241\n",
      "Loss for Batch(241): 0.00067521893652156\n",
      "Batch 242\n",
      "Loss for Batch(242): 0.0062180873937904835\n",
      "Batch 243\n",
      "Loss for Batch(243): 0.0003363178693689406\n",
      "Batch 244\n",
      "Loss for Batch(244): 0.0016184860141947865\n",
      "Batch 245\n",
      "Loss for Batch(245): 0.06780736893415451\n",
      "Batch 246\n",
      "Loss for Batch(246): 5.68310497328639e-05\n",
      "Batch 247\n",
      "Loss for Batch(247): 0.056262604892253876\n",
      "Batch 248\n",
      "Loss for Batch(248): 0.009742322377860546\n",
      "Batch 249\n",
      "Loss for Batch(249): 0.000960641773417592\n",
      "Batch 250\n",
      "Loss for Batch(250): 0.00026007674750871956\n",
      "Batch 251\n",
      "Loss for Batch(251): 0.00023400818463414907\n",
      "Batch 252\n",
      "Loss for Batch(252): 0.004279151558876038\n",
      "Batch 253\n",
      "Loss for Batch(253): 0.01600080356001854\n",
      "Batch 254\n",
      "Loss for Batch(254): 0.019880974665284157\n",
      "Batch 255\n",
      "Loss for Batch(255): 0.023239586502313614\n",
      "Batch 256\n",
      "Loss for Batch(256): 0.0018183584325015545\n",
      "Batch 257\n",
      "Loss for Batch(257): 0.002778898226097226\n",
      "Batch 258\n",
      "Loss for Batch(258): 0.0034785843454301357\n",
      "Batch 259\n",
      "Loss for Batch(259): 0.0008664884371683002\n",
      "Batch 260\n",
      "Loss for Batch(260): 0.038469307124614716\n",
      "Batch 261\n",
      "Loss for Batch(261): 0.0033567307982593775\n",
      "Batch 262\n",
      "Loss for Batch(262): 0.015512963756918907\n",
      "Batch 263\n",
      "Loss for Batch(263): 0.02891215682029724\n",
      "Batch 264\n",
      "Loss for Batch(264): 0.00030446730670519173\n",
      "Batch 265\n",
      "Loss for Batch(265): 0.0040006618946790695\n",
      "Batch 266\n",
      "Loss for Batch(266): 0.0008894407656043768\n",
      "Batch 267\n",
      "Loss for Batch(267): 2.568896525190212e-05\n",
      "Batch 268\n",
      "Loss for Batch(268): 0.02185305394232273\n",
      "Batch 269\n",
      "Loss for Batch(269): 0.00015122603508643806\n",
      "Batch 270\n",
      "Loss for Batch(270): 0.0011239306768402457\n",
      "Batch 271\n",
      "Loss for Batch(271): 0.0033620777539908886\n",
      "Batch 272\n",
      "Loss for Batch(272): 0.015516486018896103\n",
      "Batch 273\n",
      "Loss for Batch(273): 0.09139575064182281\n",
      "Batch 274\n",
      "Loss for Batch(274): 0.00014883463154546916\n",
      "Batch 275\n",
      "Loss for Batch(275): 0.018438003957271576\n",
      "Batch 276\n",
      "Loss for Batch(276): 0.015666183084249496\n",
      "Batch 277\n",
      "Loss for Batch(277): 0.05726710334420204\n",
      "Batch 278\n",
      "Loss for Batch(278): 0.0021943883039057255\n",
      "Batch 279\n",
      "Loss for Batch(279): 0.013206539675593376\n",
      "Batch 280\n",
      "Loss for Batch(280): 0.004881945438683033\n",
      "Batch 281\n",
      "Loss for Batch(281): 0.0015686587430536747\n",
      "Batch 282\n",
      "Loss for Batch(282): 0.002528809942305088\n",
      "Batch 283\n",
      "Loss for Batch(283): 0.014337126165628433\n",
      "Batch 284\n",
      "Loss for Batch(284): 0.31778639554977417\n",
      "Batch 285\n",
      "Loss for Batch(285): 0.1951635181903839\n",
      "Batch 286\n",
      "Loss for Batch(286): 0.006201738491654396\n",
      "Batch 287\n",
      "Loss for Batch(287): 0.04574020951986313\n",
      "Batch 288\n",
      "Loss for Batch(288): 0.0006205538520589471\n",
      "Batch 289\n",
      "Loss for Batch(289): 0.001124712871387601\n",
      "Batch 290\n",
      "Loss for Batch(290): 0.046735040843486786\n",
      "Batch 291\n",
      "Loss for Batch(291): 0.00274623348377645\n",
      "Batch 292\n",
      "Loss for Batch(292): 0.00234318058937788\n",
      "Batch 293\n",
      "Loss for Batch(293): 6.645500252489e-05\n",
      "Batch 294\n",
      "Loss for Batch(294): 9.646356920711696e-05\n",
      "Batch 295\n",
      "Loss for Batch(295): 0.05550607293844223\n",
      "Batch 296\n",
      "Loss for Batch(296): 0.005431712605059147\n",
      "Batch 297\n",
      "Loss for Batch(297): 0.03957876190543175\n",
      "Batch 298\n",
      "Loss for Batch(298): 0.00024625155492685735\n",
      "Batch 299\n",
      "Loss for Batch(299): 0.0036098232958465815\n",
      "Batch 300\n",
      "Loss for Batch(300): 0.00030640739714726806\n",
      "Batch 301\n",
      "Loss for Batch(301): 0.0004276971740182489\n",
      "Batch 302\n",
      "Loss for Batch(302): 0.00017804234812501818\n",
      "Batch 303\n",
      "Loss for Batch(303): 0.030461668968200684\n",
      "Batch 304\n",
      "Loss for Batch(304): 0.07438067346811295\n",
      "Batch 305\n",
      "Loss for Batch(305): 0.0028408479411154985\n",
      "Batch 306\n",
      "Loss for Batch(306): 0.007093076594173908\n",
      "Batch 307\n",
      "Loss for Batch(307): 0.002320632105693221\n",
      "Batch 308\n",
      "Loss for Batch(308): 0.0024807897862046957\n",
      "Batch 309\n",
      "Loss for Batch(309): 0.020510388538241386\n",
      "Batch 310\n",
      "Loss for Batch(310): 0.0011070966720581055\n",
      "Batch 311\n",
      "Loss for Batch(311): 0.022686969488859177\n",
      "Batch 312\n",
      "Loss for Batch(312): 0.0009082926553674042\n",
      "Batch 313\n",
      "Loss for Batch(313): 0.0018986240029335022\n",
      "Batch 314\n",
      "Loss for Batch(314): 0.0026268078945577145\n",
      "Batch 315\n",
      "Loss for Batch(315): 0.004408358596265316\n",
      "Batch 316\n",
      "Loss for Batch(316): 0.00044370198156684637\n",
      "Batch 317\n",
      "Loss for Batch(317): 0.0013582115061581135\n",
      "Batch 318\n",
      "Loss for Batch(318): 0.014134513214230537\n",
      "Batch 319\n",
      "Loss for Batch(319): 0.0001293402601731941\n",
      "Batch 320\n",
      "Loss for Batch(320): 0.019334418699145317\n",
      "Batch 321\n",
      "Loss for Batch(321): 0.004864952061325312\n",
      "Batch 322\n",
      "Loss for Batch(322): 0.03309539332985878\n",
      "Batch 323\n",
      "Loss for Batch(323): 0.0034675945062190294\n",
      "Batch 324\n",
      "Loss for Batch(324): 0.0007050237618386745\n",
      "Batch 325\n",
      "Loss for Batch(325): 0.0013163168914616108\n",
      "Batch 326\n",
      "Loss for Batch(326): 0.016056109219789505\n",
      "Batch 327\n",
      "Loss for Batch(327): 0.0041529331356287\n",
      "Batch 328\n",
      "Loss for Batch(328): 0.030570317059755325\n",
      "Batch 329\n",
      "Loss for Batch(329): 7.845805521355942e-05\n",
      "Batch 330\n",
      "Loss for Batch(330): 0.005653101950883865\n",
      "Batch 331\n",
      "Loss for Batch(331): 0.0011792705627158284\n",
      "Batch 332\n",
      "Loss for Batch(332): 2.1099665900692344e-05\n",
      "Batch 333\n",
      "Loss for Batch(333): 0.0751304179430008\n",
      "Batch 334\n",
      "Loss for Batch(334): 0.006196955218911171\n",
      "Batch 335\n",
      "Loss for Batch(335): 0.017556048929691315\n",
      "Batch 336\n",
      "Loss for Batch(336): 0.0033283191733062267\n",
      "Batch 337\n",
      "Loss for Batch(337): 0.0029989874456077814\n",
      "Batch 338\n",
      "Loss for Batch(338): 0.055312324315309525\n",
      "Batch 339\n",
      "Loss for Batch(339): 0.004684867803007364\n",
      "Batch 340\n",
      "Loss for Batch(340): 0.004111190792173147\n",
      "Batch 341\n",
      "Loss for Batch(341): 0.010304906405508518\n",
      "Batch 342\n",
      "Loss for Batch(342): 0.011087429709732533\n",
      "Batch 343\n",
      "Loss for Batch(343): 0.03681173920631409\n",
      "Batch 344\n",
      "Loss for Batch(344): 0.030384976416826248\n",
      "Batch 345\n",
      "Loss for Batch(345): 0.018200455233454704\n",
      "Batch 346\n",
      "Loss for Batch(346): 0.0018777013756334782\n",
      "Batch 347\n",
      "Loss for Batch(347): 0.045497018843889236\n",
      "Batch 348\n",
      "Loss for Batch(348): 0.00015398702817037702\n",
      "Batch 349\n",
      "Loss for Batch(349): 0.0065578194335103035\n",
      "Batch 350\n",
      "Loss for Batch(350): 0.0033232453279197216\n",
      "Batch 351\n",
      "Loss for Batch(351): 1.0549945727689192e-05\n",
      "Batch 352\n",
      "Loss for Batch(352): 0.0028234526980668306\n",
      "Batch 353\n",
      "Loss for Batch(353): 0.0011196249397471547\n",
      "Batch 354\n",
      "Loss for Batch(354): 0.0006515517015941441\n",
      "Batch 355\n",
      "Loss for Batch(355): 0.004738089628517628\n",
      "Batch 356\n",
      "Loss for Batch(356): 0.0008084490546025336\n",
      "Batch 357\n",
      "Loss for Batch(357): 0.0006003060843795538\n",
      "Batch 358\n",
      "Loss for Batch(358): 0.00026100047398358583\n",
      "Batch 359\n",
      "Loss for Batch(359): 0.00011326819367241114\n",
      "Batch 360\n",
      "Loss for Batch(360): 9.907562343869358e-05\n",
      "Batch 361\n",
      "Loss for Batch(361): 0.003146786242723465\n",
      "Batch 362\n",
      "Loss for Batch(362): 0.04849975183606148\n",
      "Batch 363\n",
      "Loss for Batch(363): 0.023991679772734642\n",
      "Batch 364\n",
      "Loss for Batch(364): 0.00044391950359568\n",
      "Batch 365\n",
      "Loss for Batch(365): 0.045500122010707855\n",
      "Batch 366\n",
      "Loss for Batch(366): 0.0006095259450376034\n",
      "Batch 367\n",
      "Loss for Batch(367): 0.029024604707956314\n",
      "Batch 368\n",
      "Loss for Batch(368): 0.0009673961321823299\n",
      "Batch 369\n",
      "Loss for Batch(369): 0.00025494518922641873\n",
      "Batch 370\n",
      "Loss for Batch(370): 0.0017039976082742214\n",
      "Batch 371\n",
      "Loss for Batch(371): 0.0015034012030810118\n",
      "Batch 372\n",
      "Loss for Batch(372): 0.002845761366188526\n",
      "Batch 373\n",
      "Loss for Batch(373): 6.746788130840287e-05\n",
      "Batch 374\n",
      "Loss for Batch(374): 0.0002999600546900183\n",
      "Batch 375\n",
      "Loss for Batch(375): 0.09366104751825333\n",
      "Batch 376\n",
      "Loss for Batch(376): 0.00041768886148929596\n",
      "Batch 377\n",
      "Loss for Batch(377): 0.010504025965929031\n",
      "Batch 378\n",
      "Loss for Batch(378): 0.0036913249641656876\n",
      "Batch 379\n",
      "Loss for Batch(379): 0.01879417523741722\n",
      "Batch 380\n",
      "Loss for Batch(380): 0.009101585485041142\n",
      "Batch 381\n",
      "Loss for Batch(381): 0.005093778483569622\n",
      "Batch 382\n",
      "Loss for Batch(382): 0.00287570059299469\n",
      "Batch 383\n",
      "Loss for Batch(383): 4.175179128651507e-05\n",
      "Batch 384\n",
      "Loss for Batch(384): 0.07108990848064423\n",
      "Batch 385\n",
      "Loss for Batch(385): 4.771154635818675e-05\n",
      "Batch 386\n",
      "Loss for Batch(386): 0.00990236084908247\n",
      "Batch 387\n",
      "Loss for Batch(387): 9.920305456034839e-05\n",
      "Batch 388\n",
      "Loss for Batch(388): 0.009505152702331543\n",
      "Batch 389\n",
      "Loss for Batch(389): 0.00021191198902670294\n",
      "Batch 390\n",
      "Loss for Batch(390): 0.007097744382917881\n",
      "Batch 391\n",
      "Loss for Batch(391): 0.0020954611245542765\n",
      "Batch 392\n",
      "Loss for Batch(392): 0.0005454242345876992\n",
      "Batch 393\n",
      "Loss for Batch(393): 0.3422318994998932\n",
      "Batch 394\n",
      "Loss for Batch(394): 0.09145642817020416\n",
      "Batch 395\n",
      "Loss for Batch(395): 0.07326623052358627\n",
      "Batch 396\n",
      "Loss for Batch(396): 0.017787959426641464\n",
      "Batch 397\n",
      "Loss for Batch(397): 8.600282308179885e-05\n",
      "Batch 398\n",
      "Loss for Batch(398): 0.010525962337851524\n",
      "Batch 399\n",
      "Loss for Batch(399): 0.0006369163165800273\n",
      "Batch 400\n",
      "Loss for Batch(400): 0.002351633971557021\n",
      "Batch 401\n",
      "Loss for Batch(401): 0.5252092480659485\n",
      "Batch 402\n",
      "Loss for Batch(402): 0.01474087592214346\n",
      "Batch 403\n",
      "Loss for Batch(403): 9.491386299487203e-05\n",
      "Batch 404\n",
      "Loss for Batch(404): 0.00012733537005260587\n",
      "Batch 405\n",
      "Loss for Batch(405): 0.000465909339254722\n",
      "Batch 406\n",
      "Loss for Batch(406): 0.003752159420400858\n",
      "Batch 407\n",
      "Loss for Batch(407): 0.00026673745014704764\n",
      "Batch 408\n",
      "Loss for Batch(408): 0.0006072738906368613\n",
      "Batch 409\n",
      "Loss for Batch(409): 0.0034335420932620764\n",
      "Batch 410\n",
      "Loss for Batch(410): 0.08673571795225143\n",
      "Batch 411\n",
      "Loss for Batch(411): 0.008809400722384453\n",
      "Batch 412\n",
      "Loss for Batch(412): 0.0432923287153244\n",
      "Batch 413\n",
      "Loss for Batch(413): 0.024002443999052048\n",
      "Batch 414\n",
      "Loss for Batch(414): 0.00532161258161068\n",
      "Batch 415\n",
      "Loss for Batch(415): 0.0015029546339064837\n",
      "Batch 416\n",
      "Loss for Batch(416): 1.9609384253271855e-05\n",
      "Batch 417\n",
      "Loss for Batch(417): 9.626083738112357e-06\n",
      "Batch 418\n",
      "Loss for Batch(418): 0.6770226359367371\n",
      "Batch 419\n",
      "Loss for Batch(419): 0.0035554710775613785\n",
      "Batch 420\n",
      "Loss for Batch(420): 2.6910784072242677e-05\n",
      "Batch 421\n",
      "Loss for Batch(421): 0.15259619057178497\n",
      "Batch 422\n",
      "Loss for Batch(422): 0.004229755140841007\n",
      "Batch 423\n",
      "Loss for Batch(423): 0.03176506236195564\n",
      "Batch 424\n",
      "Loss for Batch(424): 4.300323416828178e-05\n",
      "Batch 425\n",
      "Loss for Batch(425): 0.0006377153913490474\n",
      "Batch 426\n",
      "Loss for Batch(426): 0.12675724923610687\n",
      "Batch 427\n",
      "Loss for Batch(427): 0.049311134964227676\n",
      "Batch 428\n",
      "Loss for Batch(428): 0.0001298537536058575\n",
      "Batch 429\n",
      "Loss for Batch(429): 0.0004289590287953615\n",
      "Batch 430\n",
      "Loss for Batch(430): 0.09150592982769012\n",
      "Batch 431\n",
      "Loss for Batch(431): 0.0057581630535423756\n",
      "Batch 432\n",
      "Loss for Batch(432): 0.0019633169285953045\n",
      "Batch 433\n",
      "Loss for Batch(433): 0.02606184408068657\n",
      "Batch 434\n",
      "Loss for Batch(434): 0.0037450212985277176\n",
      "Batch 435\n",
      "Loss for Batch(435): 0.0003871279477607459\n",
      "Batch 436\n",
      "Loss for Batch(436): 0.04996681585907936\n",
      "Batch 437\n",
      "Loss for Batch(437): 8.72246382641606e-05\n",
      "Batch 438\n",
      "Loss for Batch(438): 0.0018024258315563202\n",
      "Batch 439\n",
      "Loss for Batch(439): 0.03291773051023483\n",
      "Batch 440\n",
      "Loss for Batch(440): 9.023284655995667e-05\n",
      "Batch 441\n",
      "Loss for Batch(441): 8.296251326100901e-05\n",
      "Batch 442\n",
      "Loss for Batch(442): 0.012021391652524471\n",
      "Batch 443\n",
      "Loss for Batch(443): 0.0004060924402438104\n",
      "Batch 444\n",
      "Loss for Batch(444): 0.00689726322889328\n",
      "Batch 445\n",
      "Loss for Batch(445): 4.342081228969619e-05\n",
      "Batch 446\n",
      "Loss for Batch(446): 0.0027468381449580193\n",
      "Batch 447\n",
      "Loss for Batch(447): 0.0678008645772934\n",
      "Batch 448\n",
      "Loss for Batch(448): 0.07566826790571213\n",
      "Batch 449\n",
      "Loss for Batch(449): 0.0172735545784235\n",
      "Batch 450\n",
      "Loss for Batch(450): 0.017983801662921906\n",
      "Batch 451\n",
      "Loss for Batch(451): 0.03856294974684715\n",
      "Batch 452\n",
      "Loss for Batch(452): 0.00012708999565802515\n",
      "Batch 453\n",
      "Loss for Batch(453): 0.0030683064833283424\n",
      "Batch 454\n",
      "Loss for Batch(454): 5.364384378481191e-06\n",
      "Batch 455\n",
      "Loss for Batch(455): 0.000638565281406045\n",
      "Batch 456\n",
      "Loss for Batch(456): 0.0030636393930763006\n",
      "Batch 457\n",
      "Loss for Batch(457): 0.0046543278731405735\n",
      "Batch 458\n",
      "Loss for Batch(458): 0.0018219866324216127\n",
      "Batch 459\n",
      "Loss for Batch(459): 0.0002173836692236364\n",
      "Batch 460\n",
      "Loss for Batch(460): 0.005990573670715094\n",
      "Batch 461\n",
      "Loss for Batch(461): 0.001504056272096932\n",
      "Batch 462\n",
      "Loss for Batch(462): 0.0004638649115804583\n",
      "Batch 463\n",
      "Loss for Batch(463): 1.7910959286382422e-05\n",
      "Batch 464\n",
      "Loss for Batch(464): 0.0009196443716064095\n",
      "Batch 465\n",
      "Loss for Batch(465): 0.00043386302422732115\n",
      "Batch 466\n",
      "Loss for Batch(466): 0.008528875187039375\n",
      "Batch 467\n",
      "Loss for Batch(467): 0.0005268434761092067\n",
      "Batch 468\n",
      "Loss for Batch(468): 0.00014502705016639084\n",
      "Batch 469\n",
      "Loss for Batch(469): 0.03281373903155327\n",
      "Batch 470\n",
      "Loss for Batch(470): 2.443720404698979e-05\n",
      "Batch 471\n",
      "Loss for Batch(471): 0.006230202503502369\n",
      "Batch 472\n",
      "Loss for Batch(472): 0.00021765712881460786\n",
      "Batch 473\n",
      "Loss for Batch(473): 7.714780804235488e-05\n",
      "Batch 474\n",
      "Loss for Batch(474): 0.01896926946938038\n",
      "Batch 475\n",
      "Loss for Batch(475): 0.0015820353291928768\n",
      "Batch 476\n",
      "Loss for Batch(476): 0.00026736341533251107\n",
      "Batch 477\n",
      "Loss for Batch(477): 0.0012324308045208454\n",
      "Batch 478\n",
      "Loss for Batch(478): 0.00016615870117675513\n",
      "Batch 479\n",
      "Loss for Batch(479): 0.0005682862247340381\n",
      "Batch 480\n",
      "Loss for Batch(480): 0.000694049580488354\n",
      "Batch 481\n",
      "Loss for Batch(481): 0.011785776354372501\n",
      "Batch 482\n",
      "Loss for Batch(482): 0.004617289174348116\n",
      "Batch 483\n",
      "Loss for Batch(483): 0.0005979908746667206\n",
      "Batch 484\n",
      "Loss for Batch(484): 0.0001866720267571509\n",
      "Batch 485\n",
      "Loss for Batch(485): 0.01937563344836235\n",
      "Batch 486\n",
      "Loss for Batch(486): 0.00016441175830550492\n",
      "Batch 487\n",
      "Loss for Batch(487): 0.0028451569378376007\n",
      "Batch 488\n",
      "Loss for Batch(488): 0.0071466839872300625\n",
      "Batch 489\n",
      "Loss for Batch(489): 0.15367697179317474\n",
      "Batch 490\n",
      "Loss for Batch(490): 0.005457717459648848\n",
      "Batch 491\n",
      "Loss for Batch(491): 0.0026380219496786594\n",
      "Batch 492\n",
      "Loss for Batch(492): 0.01611841656267643\n",
      "Batch 493\n",
      "Loss for Batch(493): 0.007772596552968025\n",
      "Batch 494\n",
      "Loss for Batch(494): 0.042718395590782166\n",
      "Batch 495\n",
      "Loss for Batch(495): 0.005708961747586727\n",
      "Batch 496\n",
      "Loss for Batch(496): 0.016500156372785568\n",
      "Batch 497\n",
      "Loss for Batch(497): 0.010727237910032272\n",
      "Batch 498\n",
      "Loss for Batch(498): 0.0002970564819406718\n",
      "Batch 499\n",
      "Loss for Batch(499): 0.00018894881941378117\n",
      "Batch 500\n",
      "Loss for Batch(500): 0.022984836250543594\n",
      "Batch 501\n",
      "Loss for Batch(501): 0.0073147127404809\n",
      "Batch 502\n",
      "Loss for Batch(502): 0.0028144398238509893\n",
      "Batch 503\n",
      "Loss for Batch(503): 0.00457735825330019\n",
      "Batch 504\n",
      "Loss for Batch(504): 2.5063367502298206e-05\n",
      "Batch 505\n",
      "Loss for Batch(505): 0.0022821996826678514\n",
      "Batch 506\n",
      "Loss for Batch(506): 0.016464155167341232\n",
      "Batch 507\n",
      "Loss for Batch(507): 0.14627397060394287\n",
      "Batch 508\n",
      "Loss for Batch(508): 0.09105144441127777\n",
      "Batch 509\n",
      "Loss for Batch(509): 5.990247700538021e-06\n",
      "Batch 510\n",
      "Loss for Batch(510): 0.0013409877428784966\n",
      "Batch 511\n",
      "Loss for Batch(511): 0.000798203400336206\n",
      "Batch 512\n",
      "Loss for Batch(512): 0.03957599774003029\n",
      "Batch 513\n",
      "Loss for Batch(513): 0.04984356835484505\n",
      "Batch 514\n",
      "Loss for Batch(514): 0.004295841790735722\n",
      "Batch 515\n",
      "Loss for Batch(515): 0.07104051858186722\n",
      "Batch 516\n",
      "Loss for Batch(516): 0.10774452239274979\n",
      "Batch 517\n",
      "Loss for Batch(517): 0.00040605233516544104\n",
      "Batch 518\n",
      "Loss for Batch(518): 5.197000064072199e-05\n",
      "Batch 519\n",
      "Loss for Batch(519): 0.0009387085447087884\n",
      "Batch 520\n",
      "Loss for Batch(520): 0.00044242560397833586\n",
      "Batch 521\n",
      "Loss for Batch(521): 0.00039917821413837373\n",
      "Batch 522\n",
      "Loss for Batch(522): 1.5854469893383794e-05\n",
      "Batch 523\n",
      "Loss for Batch(523): 0.0030692291911691427\n",
      "Batch 524\n",
      "Loss for Batch(524): 0.00018676661420613527\n",
      "Batch 525\n",
      "Loss for Batch(525): 0.016146739944815636\n",
      "Batch 526\n",
      "Loss for Batch(526): 0.004062413237988949\n",
      "Batch 527\n",
      "Loss for Batch(527): 0.004372905474156141\n",
      "Batch 528\n",
      "Loss for Batch(528): 0.000201209302758798\n",
      "Batch 529\n",
      "Loss for Batch(529): 0.0003742970002349466\n",
      "Batch 530\n",
      "Loss for Batch(530): 0.00019563968817237765\n",
      "Batch 531\n",
      "Loss for Batch(531): 0.00024265114916488528\n",
      "Batch 532\n",
      "Loss for Batch(532): 1.6391256849601632e-06\n",
      "Batch 533\n",
      "Loss for Batch(533): 7.875820301705971e-05\n",
      "Batch 534\n",
      "Loss for Batch(534): 7.798591104801744e-05\n",
      "Batch 535\n",
      "Loss for Batch(535): 0.05582171678543091\n",
      "Batch 536\n",
      "Loss for Batch(536): 0.14970646798610687\n",
      "Batch 537\n",
      "Loss for Batch(537): 3.3823638659669086e-05\n",
      "Batch 538\n",
      "Loss for Batch(538): 0.0010878320317715406\n",
      "Batch 539\n",
      "Loss for Batch(539): 0.00038131672772578895\n",
      "Batch 540\n",
      "Loss for Batch(540): 0.004395202733576298\n",
      "Batch 541\n",
      "Loss for Batch(541): 0.014925639145076275\n",
      "Batch 542\n",
      "Loss for Batch(542): 0.007981219328939915\n",
      "Batch 543\n",
      "Loss for Batch(543): 0.0038206996396183968\n",
      "Batch 544\n",
      "Loss for Batch(544): 0.06284899264574051\n",
      "Batch 545\n",
      "Loss for Batch(545): 0.07924847304821014\n",
      "Batch 546\n",
      "Loss for Batch(546): 0.052201248705387115\n",
      "Batch 547\n",
      "Loss for Batch(547): 0.01130937971174717\n",
      "Batch 548\n",
      "Loss for Batch(548): 0.0032555246725678444\n",
      "Batch 549\n",
      "Loss for Batch(549): 0.00011778440966736525\n",
      "Batch 550\n",
      "Loss for Batch(550): 0.0054986318573355675\n",
      "Batch 551\n",
      "Loss for Batch(551): 0.003609262639656663\n",
      "Batch 552\n",
      "Loss for Batch(552): 0.024546807631850243\n",
      "Batch 553\n",
      "Loss for Batch(553): 0.00424021203070879\n",
      "Batch 554\n",
      "Loss for Batch(554): 0.0003460135485511273\n",
      "Batch 555\n",
      "Loss for Batch(555): 0.1420438438653946\n",
      "Batch 556\n",
      "Loss for Batch(556): 0.0011057615047320724\n",
      "Batch 557\n",
      "Loss for Batch(557): 0.02462330088019371\n",
      "Batch 558\n",
      "Loss for Batch(558): 0.0007095224573276937\n",
      "Batch 559\n",
      "Loss for Batch(559): 0.0057670678943395615\n",
      "Batch 560\n",
      "Loss for Batch(560): 0.0037588649429380894\n",
      "Batch 561\n",
      "Loss for Batch(561): 0.006039952859282494\n",
      "Batch 562\n",
      "Loss for Batch(562): 0.006613362580537796\n",
      "Batch 563\n",
      "Loss for Batch(563): 7.60793627705425e-05\n",
      "Batch 564\n",
      "Loss for Batch(564): 0.005993686616420746\n",
      "Batch 565\n",
      "Loss for Batch(565): 0.2773788571357727\n",
      "Batch 566\n",
      "Loss for Batch(566): 0.004330058116465807\n",
      "Batch 567\n",
      "Loss for Batch(567): 0.0008055761572904885\n",
      "Batch 568\n",
      "Loss for Batch(568): 0.007538721896708012\n",
      "Batch 569\n",
      "Loss for Batch(569): 0.00013008997484575957\n",
      "Batch 570\n",
      "Loss for Batch(570): 0.00010521466901991516\n",
      "Batch 571\n",
      "Loss for Batch(571): 0.00032621712307445705\n",
      "Batch 572\n",
      "Loss for Batch(572): 0.008554402738809586\n",
      "Batch 573\n",
      "Loss for Batch(573): 0.017899002879858017\n",
      "Batch 574\n",
      "Loss for Batch(574): 0.0008087008027359843\n",
      "Batch 575\n",
      "Loss for Batch(575): 0.010211143642663956\n",
      "Batch 576\n",
      "Loss for Batch(576): 0.022997483611106873\n",
      "Batch 577\n",
      "Loss for Batch(577): 0.00034308870090171695\n",
      "Batch 578\n",
      "Loss for Batch(578): 0.12118110060691833\n",
      "Batch 579\n",
      "Loss for Batch(579): 0.009835760109126568\n",
      "Batch 580\n",
      "Loss for Batch(580): 0.009913245216012001\n",
      "Batch 581\n",
      "Loss for Batch(581): 0.01777556724846363\n",
      "Batch 582\n",
      "Loss for Batch(582): 0.0005907858139835298\n",
      "Batch 583\n",
      "Loss for Batch(583): 0.01117819081991911\n",
      "Batch 584\n",
      "Loss for Batch(584): 6.4372616179753095e-06\n",
      "Batch 585\n",
      "Loss for Batch(585): 0.008548094891011715\n",
      "Batch 586\n",
      "Loss for Batch(586): 7.291753718163818e-05\n",
      "Batch 587\n",
      "Loss for Batch(587): 0.027454685419797897\n",
      "Batch 588\n",
      "Loss for Batch(588): 0.0010849472600966692\n",
      "Batch 589\n",
      "Loss for Batch(589): 0.07160855829715729\n",
      "Batch 590\n",
      "Loss for Batch(590): 0.00010652868513716385\n",
      "Batch 591\n",
      "Loss for Batch(591): 0.2585396468639374\n",
      "Batch 592\n",
      "Loss for Batch(592): 0.003201862098649144\n",
      "Batch 593\n",
      "Loss for Batch(593): 0.0019660387188196182\n",
      "Batch 594\n",
      "Loss for Batch(594): 0.010853981599211693\n",
      "Batch 595\n",
      "Loss for Batch(595): 0.001132492907345295\n",
      "Batch 596\n",
      "Loss for Batch(596): 2.9145921871531755e-05\n",
      "Batch 597\n",
      "Loss for Batch(597): 0.00942645501345396\n",
      "Batch 598\n",
      "Loss for Batch(598): 0.0017457501962780952\n",
      "Batch 599\n",
      "Loss for Batch(599): 0.0221778005361557\n",
      "Batch 600\n",
      "Loss for Batch(600): 0.08150489628314972\n",
      "Batch 601\n",
      "Loss for Batch(601): 0.00022087813704274595\n",
      "Batch 602\n",
      "Loss for Batch(602): 0.051890674978494644\n",
      "Batch 603\n",
      "Loss for Batch(603): 0.0002854799386113882\n",
      "Batch 604\n",
      "Loss for Batch(604): 0.00043090994586236775\n",
      "Batch 605\n",
      "Loss for Batch(605): 0.00974759180098772\n",
      "Batch 606\n",
      "Loss for Batch(606): 0.0013969893334433436\n",
      "Batch 607\n",
      "Loss for Batch(607): 0.0020553888753056526\n",
      "Batch 608\n",
      "Loss for Batch(608): 0.010938740335404873\n",
      "Batch 609\n",
      "Loss for Batch(609): 0.0008402186213061213\n",
      "Batch 610\n",
      "Loss for Batch(610): 0.02502044290304184\n",
      "Batch 611\n",
      "Loss for Batch(611): 0.00602297205477953\n",
      "Batch 612\n",
      "Loss for Batch(612): 6.847846088930964e-05\n",
      "Batch 613\n",
      "Loss for Batch(613): 0.024701258167624474\n",
      "Batch 614\n",
      "Loss for Batch(614): 0.020219698548316956\n",
      "Batch 615\n",
      "Loss for Batch(615): 0.03597392141819\n",
      "Batch 616\n",
      "Loss for Batch(616): 0.0131148099899292\n",
      "Batch 617\n",
      "Loss for Batch(617): 0.00017001719970721751\n",
      "Batch 618\n",
      "Loss for Batch(618): 0.007698694244027138\n",
      "Batch 619\n",
      "Loss for Batch(619): 0.0031100388150662184\n",
      "Batch 620\n",
      "Loss for Batch(620): 0.022130781784653664\n",
      "Batch 621\n",
      "Loss for Batch(621): 3.6029854527441785e-05\n",
      "Batch 622\n",
      "Loss for Batch(622): 0.000101195924798958\n",
      "Batch 623\n",
      "Loss for Batch(623): 0.000640758138615638\n",
      "Batch 624\n",
      "Loss for Batch(624): 0.002786611672490835\n",
      "Batch 625\n",
      "Loss for Batch(625): 0.00013552469317801297\n",
      "Batch 626\n",
      "Loss for Batch(626): 0.000231635058298707\n",
      "Batch 627\n",
      "Loss for Batch(627): 0.0032981669064611197\n",
      "Batch 628\n",
      "Loss for Batch(628): 0.028241051360964775\n",
      "Batch 629\n",
      "Loss for Batch(629): 0.05427905172109604\n",
      "Batch 630\n",
      "Loss for Batch(630): 0.0034329488407820463\n",
      "Batch 631\n",
      "Loss for Batch(631): 0.2690684199333191\n",
      "Batch 632\n",
      "Loss for Batch(632): 0.06493870913982391\n",
      "Batch 633\n",
      "Loss for Batch(633): 0.001509146997705102\n",
      "Batch 634\n",
      "Loss for Batch(634): 0.0006115902797318995\n",
      "Batch 635\n",
      "Loss for Batch(635): 0.00010447563545312732\n",
      "Batch 636\n",
      "Loss for Batch(636): 0.019875550642609596\n",
      "Batch 637\n",
      "Loss for Batch(637): 0.4662629961967468\n",
      "Batch 638\n",
      "Loss for Batch(638): 0.00518384762108326\n",
      "Batch 639\n",
      "Loss for Batch(639): 0.008086217567324638\n",
      "Batch 640\n",
      "Loss for Batch(640): 0.0016816639108583331\n",
      "Batch 641\n",
      "Loss for Batch(641): 0.0009714175248518586\n",
      "Batch 642\n",
      "Loss for Batch(642): 0.003950797487050295\n",
      "Batch 643\n",
      "Loss for Batch(643): 0.01019902341067791\n",
      "Batch 644\n",
      "Loss for Batch(644): 0.0022241752594709396\n",
      "Batch 645\n",
      "Loss for Batch(645): 0.012111220508813858\n",
      "Batch 646\n",
      "Loss for Batch(646): 0.010595165193080902\n",
      "Batch 647\n",
      "Loss for Batch(647): 0.1541062891483307\n",
      "Batch 648\n",
      "Loss for Batch(648): 0.010636596009135246\n",
      "Batch 649\n",
      "Loss for Batch(649): 0.0038548563607037067\n",
      "Batch 650\n",
      "Loss for Batch(650): 0.005975741893053055\n",
      "Batch 651\n",
      "Loss for Batch(651): 0.0009922372410073876\n",
      "Batch 652\n",
      "Loss for Batch(652): 0.02284446731209755\n",
      "Batch 653\n",
      "Loss for Batch(653): 0.08377274870872498\n",
      "Batch 654\n",
      "Loss for Batch(654): 0.000280602223938331\n",
      "Batch 655\n",
      "Loss for Batch(655): 6.8213019403629e-05\n",
      "Batch 656\n",
      "Loss for Batch(656): 0.0008831720915623009\n",
      "Batch 657\n",
      "Loss for Batch(657): 0.00036981646553613245\n",
      "Batch 658\n",
      "Loss for Batch(658): 0.0002486165030859411\n",
      "Batch 659\n",
      "Loss for Batch(659): 0.972295343875885\n",
      "Batch 660\n",
      "Loss for Batch(660): 0.0014975799713283777\n",
      "Batch 661\n",
      "Loss for Batch(661): 0.010134050622582436\n",
      "Batch 662\n",
      "Loss for Batch(662): 0.002265490358695388\n",
      "Batch 663\n",
      "Loss for Batch(663): 0.05521493777632713\n",
      "Batch 664\n",
      "Loss for Batch(664): 0.015425443649291992\n",
      "Batch 665\n",
      "Loss for Batch(665): 0.001238253666087985\n",
      "Batch 666\n",
      "Loss for Batch(666): 0.0017130619380623102\n",
      "Batch 667\n",
      "Loss for Batch(667): 0.0023906612768769264\n",
      "Batch 668\n",
      "Loss for Batch(668): 0.0003017100680153817\n",
      "Batch 669\n",
      "Loss for Batch(669): 0.08400517702102661\n",
      "Batch 670\n",
      "Loss for Batch(670): 0.0019794590771198273\n",
      "Batch 671\n",
      "Loss for Batch(671): 0.018660468980669975\n",
      "Batch 672\n",
      "Loss for Batch(672): 0.0037668219301849604\n",
      "Batch 673\n",
      "Loss for Batch(673): 0.020892350003123283\n",
      "Batch 674\n",
      "Loss for Batch(674): 0.002743110526353121\n",
      "Batch 675\n",
      "Loss for Batch(675): 0.00046345542068593204\n",
      "Batch 676\n",
      "Loss for Batch(676): 0.01040356419980526\n",
      "Batch 677\n",
      "Loss for Batch(677): 0.004720823373645544\n",
      "Batch 678\n",
      "Loss for Batch(678): 0.0024201548658311367\n",
      "Batch 679\n",
      "Loss for Batch(679): 0.0011194137623533607\n",
      "Batch 680\n",
      "Loss for Batch(680): 0.00028310567722655833\n",
      "Batch 681\n",
      "Loss for Batch(681): 0.00019070951384492218\n",
      "Batch 682\n",
      "Loss for Batch(682): 0.0027990080416202545\n",
      "Batch 683\n",
      "Loss for Batch(683): 0.0012495954288169742\n",
      "Batch 684\n",
      "Loss for Batch(684): 0.05233859270811081\n",
      "Batch 685\n",
      "Loss for Batch(685): 0.0033068007323890924\n",
      "Batch 686\n",
      "Loss for Batch(686): 0.002511494792997837\n",
      "Batch 687\n",
      "Loss for Batch(687): 0.0009465224575251341\n",
      "Batch 688\n",
      "Loss for Batch(688): 0.009570645168423653\n",
      "Batch 689\n",
      "Loss for Batch(689): 0.019196586683392525\n",
      "Batch 690\n",
      "Loss for Batch(690): 0.0004371738759800792\n",
      "Batch 691\n",
      "Loss for Batch(691): 0.0007239473634399474\n",
      "Batch 692\n",
      "Loss for Batch(692): 0.004744023084640503\n",
      "Batch 693\n",
      "Loss for Batch(693): 0.0025410435628145933\n",
      "Batch 694\n",
      "Loss for Batch(694): 1.1622774763964117e-05\n",
      "Batch 695\n",
      "Loss for Batch(695): 0.0011609125649556518\n",
      "Batch 696\n",
      "Loss for Batch(696): 3.993344944319688e-05\n",
      "Batch 697\n",
      "Loss for Batch(697): 0.0024192873388528824\n",
      "Batch 698\n",
      "Loss for Batch(698): 0.014565343037247658\n",
      "Batch 699\n",
      "Loss for Batch(699): 0.0033230942208319902\n",
      "Batch 700\n",
      "Loss for Batch(700): 0.00726282550022006\n",
      "Batch 701\n",
      "Loss for Batch(701): 0.00010867541277548298\n",
      "Batch 702\n",
      "Loss for Batch(702): 0.006324763875454664\n",
      "Batch 703\n",
      "Loss for Batch(703): 0.034236591309309006\n",
      "Batch 704\n",
      "Loss for Batch(704): 0.00019063807849306613\n",
      "Batch 705\n",
      "Loss for Batch(705): 0.09183087199926376\n",
      "Batch 706\n",
      "Loss for Batch(706): 0.013774803839623928\n",
      "Batch 707\n",
      "Loss for Batch(707): 0.004409296438097954\n",
      "Batch 708\n",
      "Loss for Batch(708): 0.13059930503368378\n",
      "Batch 709\n",
      "Loss for Batch(709): 0.0013379426673054695\n",
      "Batch 710\n",
      "Loss for Batch(710): 0.02428748644888401\n",
      "Batch 711\n",
      "Loss for Batch(711): 0.201358824968338\n",
      "Batch 712\n",
      "Loss for Batch(712): 7.40824470994994e-05\n",
      "Batch 713\n",
      "Loss for Batch(713): 0.00030185459763742983\n",
      "Batch 714\n",
      "Loss for Batch(714): 0.06146470457315445\n",
      "Batch 715\n",
      "Loss for Batch(715): 0.014288056641817093\n",
      "Batch 716\n",
      "Loss for Batch(716): 0.003913974855095148\n",
      "Batch 717\n",
      "Loss for Batch(717): 0.0002201950119342655\n",
      "Batch 718\n",
      "Loss for Batch(718): 0.0007641268311999738\n",
      "Batch 719\n",
      "Loss for Batch(719): 1.7255079001188278e-05\n",
      "Batch 720\n",
      "Loss for Batch(720): 0.04714540019631386\n",
      "Batch 721\n",
      "Loss for Batch(721): 0.0004645547887776047\n",
      "Batch 722\n",
      "Loss for Batch(722): 0.0008513238863088191\n",
      "Batch 723\n",
      "Loss for Batch(723): 0.10301348567008972\n",
      "Batch 724\n",
      "Loss for Batch(724): 0.0005902716075070202\n",
      "Batch 725\n",
      "Loss for Batch(725): 0.02705565094947815\n",
      "Batch 726\n",
      "Loss for Batch(726): 0.48100218176841736\n",
      "Batch 727\n",
      "Loss for Batch(727): 0.014850307255983353\n",
      "Batch 728\n",
      "Loss for Batch(728): 0.17142616212368011\n",
      "Batch 729\n",
      "Loss for Batch(729): 0.012991460040211678\n",
      "Batch 730\n",
      "Loss for Batch(730): 0.06671687215566635\n",
      "Batch 731\n",
      "Loss for Batch(731): 0.0007176038343459368\n",
      "Batch 732\n",
      "Loss for Batch(732): 0.002225825795903802\n",
      "Batch 733\n",
      "Loss for Batch(733): 0.0014620970468968153\n",
      "Batch 734\n",
      "Loss for Batch(734): 0.0010916744358837605\n",
      "Batch 735\n",
      "Loss for Batch(735): 1.323207288805861e-05\n",
      "Batch 736\n",
      "Loss for Batch(736): 0.00012616255844477564\n",
      "Batch 737\n",
      "Loss for Batch(737): 0.09399078041315079\n",
      "Batch 738\n",
      "Loss for Batch(738): 0.1550718992948532\n",
      "Batch 739\n",
      "Loss for Batch(739): 0.1829935610294342\n",
      "Batch 740\n",
      "Loss for Batch(740): 0.00257321959361434\n",
      "Batch 741\n",
      "Loss for Batch(741): 0.03935034200549126\n",
      "Batch 742\n",
      "Loss for Batch(742): 0.0010209373431280255\n",
      "Batch 743\n",
      "Loss for Batch(743): 0.0186496302485466\n",
      "Batch 744\n",
      "Loss for Batch(744): 0.006218016147613525\n",
      "Batch 745\n",
      "Loss for Batch(745): 0.004046099726110697\n",
      "Batch 746\n",
      "Loss for Batch(746): 0.006531695835292339\n",
      "Batch 747\n",
      "Loss for Batch(747): 0.0002614020195323974\n",
      "Batch 748\n",
      "Loss for Batch(748): 0.0015061080921441317\n",
      "Batch 749\n",
      "Loss for Batch(749): 0.0074760932475328445\n",
      "Batch 750\n",
      "Loss for Batch(750): 0.00986087042838335\n",
      "Batch 751\n",
      "Loss for Batch(751): 0.00798123236745596\n",
      "Batch 752\n",
      "Loss for Batch(752): 0.04172593727707863\n",
      "Batch 753\n",
      "Loss for Batch(753): 0.00027295202016830444\n",
      "Avg Loss for 754 Batches0.022509022113866267\n",
      "Epoch(100) Finished\n",
      "**********************************************\n",
      "Avg Test Loss:\n",
      "0.1565912636412418\n",
      "Test Accuracy:\n",
      "0.950863213811421\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "train_loss, test_loss, test_acc=CNN_helper_model.Train_FC_CNN(CNN_model, train_loader,test_loader, optimizer, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L37FRM2RUUCS"
   },
   "source": [
    "# Plot Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "cR-oB5HEP53r",
    "outputId": "9e2b5576-2438-4b4e-9ee8-9a65aa35a262"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CNN_helper_model.plot_loss(train_loss,\"Training Loss\",100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0qdKOD1UbJf"
   },
   "source": [
    "# Plot Testing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "UBTXrZiBP56r",
    "outputId": "bde6bd76-a047-41af-e737-3f917cd789a3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CNN_helper_model.plot_loss(test_loss,\"Testing Loss\",100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnP5ktWyUyIF"
   },
   "source": [
    "# Plot Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "niS7brUBUm2L",
    "outputId": "085e27f3-176b-41af-c193-c8c8cf946ecb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CNN_helper_model.plot_loss(test_acc,\"Accuracy\",100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2GFnRK3U-eX"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "همانطور که از نتایج مشخص است شبکه ی کانوولوشنی نتایج بهتری از شبکه ی کاملا متصب گرفته است. مثلا در دقت شبکه ی کانوولوشنی به دقت 95 درصد و شبکه ی کاملا متصل به دقت 93 درصد رسیده است. همانطور که در نمودار دقت و تابع هزینه مشخص است شبکه ی کاملا متصل در آموزش خود بسیار نوسان دارد و این مسئله به خاطر این است که تمامی داده های به یک نورون متصل هستند نه داده های مرتبط و این مسئله می تواند در دقت و تایع هزینه ما تاثیر گذار باشد از طرفی همانطور که در شبکه ی کانوولوشنی دیده می شود این شبکه در ابتدای آموزش نوساناتی دارد اما رفته رفته دقت و تابع هزینه هموار تر می شود این مسئله به این خاطر است که چون تمامی داده ها به یک نورون متصل نیستند در ابتدای آموزش شبکه در حال تجربه و آزمون است و پس از چند بار آموزش مسیر هموار می شود.و این مسئله به خاطر مسائلی از جمله استخراج خوب ویژگی ها، parameter sharing ،  Sparse & local interactions ,  Equi-variant  شبکه های کانوولونشی است. \n",
    "</dir>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled25.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
